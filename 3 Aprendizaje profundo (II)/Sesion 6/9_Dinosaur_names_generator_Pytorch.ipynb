{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dinosaur_names_generator_Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vicentcamison/idal_ia3/blob/main/3%20Aprendizaje%20profundo%20(II)/Sesion%206/9_Dinosaur_names_generator_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSvaD0lMAtQu"
      },
      "source": [
        "# Dinosaur names generator using LSTMs\r\n",
        "\r\n",
        "Esto es un ejemplo de sequence to sequence learning. La idea es aprender nombres de dinosaurios y poder generar uno plausible dando una letra inicial como semilla."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zExspKMnAmeV"
      },
      "source": [
        "import os\r\n",
        "import time\r\n",
        "import math\r\n",
        "import string\r\n",
        "import random\r\n",
        "\r\n",
        "import collections\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "import torch\r\n",
        "from torch import nn\r\n",
        "from torch import optim\r\n",
        "from torch.functional import F\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "\r\n",
        "#imports de Juan\r\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "BxzOWzAZA6-t",
        "outputId": "6c93c970-e8ab-4afe-9e62-3d38eb5f4bbf"
      },
      "source": [
        "# Create sequences of chars, end all sequences with special char \"<EOS>\"\r\n",
        "def split_to_names(fname):\r\n",
        "  \r\n",
        "  # COMPLETAR Load file, split names to chars and append the End of Sequence (EOS) Token\r\n",
        "  # Load file\r\n",
        "  text = pd.read_csv(fname)\r\n",
        "  #text = f.read()\r\n",
        "\r\n",
        "  #Split names to chars\r\n",
        "  for i in range(text.shape[0]):\r\n",
        "    \r\n",
        "  for item in text:\r\n",
        "    item = [char for char in item]\r\n",
        "    item.append(['<EOS>'])\r\n",
        "  print(text)\r\n",
        "\r\n",
        "data_in_char = split_to_names(\"https://raw.githubusercontent.com/vicentcamison/idal_ia3/main/3%20Aprendizaje%20profundo%20(II)/Sesion%206/dinos.txt\")\r\n",
        "\r\n",
        "#test\r\n",
        "print(data_in_char[0])\r\n",
        "len(data_in_char)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       Aachenosaurus\n",
            "0           Aardonyx\n",
            "1     Abdallahsaurus\n",
            "2        Abelisaurus\n",
            "3      Abrictosaurus\n",
            "4         Abrosaurus\n",
            "...              ...\n",
            "1539    Zunityrannus\n",
            "1540         Zuolong\n",
            "1541      Zuoyunlong\n",
            "1542     Zupaysaurus\n",
            "1543            Zuul\n",
            "\n",
            "[1544 rows x 1 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-fca62b04ea41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_in_char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_in_char\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILiKLvoVRbNX",
        "outputId": "3ae42bc1-2ca9-431a-fd4b-dbaa4b440970"
      },
      "source": [
        "char_vocab = # COMPLETAR\r\n",
        "print(char_vocab)\r\n",
        "char_to_ix = #COMPLETAR\r\n",
        "ix_to_char = #COMPLETAR\r\n",
        "\r\n",
        "def keys_to_values(keys, char_to_ix_dict):\r\n",
        "    return #COMPLETAR\r\n",
        "# test\r\n",
        "keys_to_values('k',char_to_ix)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<EOS>', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[11]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwTIzIVGtfpM"
      },
      "source": [
        "class Dataset(torch.utils.data.Dataset):\r\n",
        "    def __init__(self, data_as_str, char_to_ix_dict):\r\n",
        "        self.data_as_int = [] #Lista que alojar√° el dataset convertido a enteros\r\n",
        "        \r\n",
        "        # COMPLETAR: Convert characters to integers for each sequence in the list\r\n",
        "\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return #COMPLETAR\r\n",
        "\r\n",
        "    def __getitem__(self, ix):\r\n",
        "        # Get data sample at index ix\r\n",
        "        item = #COMPLETAR\r\n",
        "        # Slice x and y from sample\r\n",
        "        x = item[#COMPLETAR]\r\n",
        "        y = item[#COMPLETAR]\r\n",
        "        return #COMPLETAR\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPLV9D67C_P4"
      },
      "source": [
        "dataset = Dataset(#COMPLETAR)\r\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZP4eqrnWvl9O",
        "outputId": "d45cee39-dd1d-42ac-a615-2d9ee29e8015"
      },
      "source": [
        "#test\r\n",
        "print(dataset[0])\r\n",
        "print(len(dataset))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([ 1,  1,  3,  8,  5, 14, 15, 19,  1, 21, 18, 21, 19]), tensor([ 1,  3,  8,  5, 14, 15, 19,  1, 21, 18, 21, 19,  0]))\n",
            "1545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gm6y4XMqwUMc"
      },
      "source": [
        "\r\n",
        "class Model(nn.Module):\r\n",
        "    def __init__(self, char_to_ix_dict):\r\n",
        "        super(Model, self).__init__()\r\n",
        "        \r\n",
        "        self.vocab_size  = len(char_to_ix_dict)\r\n",
        "        self.hidden_size = 64\r\n",
        "        self.emb_dim     = 8\r\n",
        "        self.n_layers    = 1\r\n",
        "        self.dropout_p   = 0.2\r\n",
        "        \r\n",
        "        self.embedding = nn.Embedding(\r\n",
        "            #COMPLETAR)\r\n",
        "        \r\n",
        "        self.lstm = nn.LSTM(\r\n",
        "            #COMPLETAR)\r\n",
        "        \r\n",
        "        self.dropout = nn.Dropout(#COMPLETAR)\r\n",
        "        \r\n",
        "        self.fc = nn.Linear(\r\n",
        "            #COMPLETAR)\r\n",
        "        \r\n",
        "    def forward(self, x, prev_state):\r\n",
        "        #COMPLETAR\r\n",
        "    \r\n",
        "    def init_state(self, b_size=1):\r\n",
        "        #COMPLETAR\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRUTlXutDYEC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "307b9c69-2cca-4a59-b970-e264fc688173"
      },
      "source": [
        "model = #COMPLETAR\r\n",
        "print(model) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model(\n",
            "  (embedding): Embedding(27, 8)\n",
            "  (lstm): LSTM(8, 64, batch_first=True)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (fc): Linear(in_features=64, out_features=27, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ6IKX5VDoYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bc398c4-f952-4e57-bce3-8c03f3bbe099"
      },
      "source": [
        "model.train()\r\n",
        "    \r\n",
        "loss_list = []\r\n",
        "running_loss = 0\r\n",
        "optimizer = #COMPLETAR\r\n",
        "criterion = #COMPLETAR\r\n",
        "num_epochs=#COMPLETAR\r\n",
        "\r\n",
        "epoch=1\r\n",
        "while(epoch<num_epochs):\r\n",
        "  for x, y in dataloader:\r\n",
        "    \r\n",
        "    #COMPLETAR\r\n",
        "\r\n",
        "    epoch+=1\r\n",
        "\r\n",
        "    if epoch%1000==0:\r\n",
        "      print(\"Epoch: {}/{}, Loss: {:8.4f}\".format(\r\n",
        "          epoch, num_epochs, running_loss/1000))\r\n",
        "      running_loss = 0\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1000/50000, Loss:   2.2623\n",
            "Epoch: 2000/50000, Loss:   1.9410\n",
            "Epoch: 3000/50000, Loss:   1.8248\n",
            "Epoch: 4000/50000, Loss:   1.7441\n",
            "Epoch: 5000/50000, Loss:   1.7167\n",
            "Epoch: 6000/50000, Loss:   1.6962\n",
            "Epoch: 7000/50000, Loss:   1.6648\n",
            "Epoch: 8000/50000, Loss:   1.6051\n",
            "Epoch: 9000/50000, Loss:   1.6171\n",
            "Epoch: 10000/50000, Loss:   1.5886\n",
            "Epoch: 11000/50000, Loss:   1.5541\n",
            "Epoch: 12000/50000, Loss:   1.5426\n",
            "Epoch: 13000/50000, Loss:   1.5471\n",
            "Epoch: 14000/50000, Loss:   1.5047\n",
            "Epoch: 15000/50000, Loss:   1.4972\n",
            "Epoch: 16000/50000, Loss:   1.4695\n",
            "Epoch: 17000/50000, Loss:   1.4796\n",
            "Epoch: 18000/50000, Loss:   1.4509\n",
            "Epoch: 19000/50000, Loss:   1.4464\n",
            "Epoch: 20000/50000, Loss:   1.4317\n",
            "Epoch: 21000/50000, Loss:   1.4259\n",
            "Epoch: 22000/50000, Loss:   1.4057\n",
            "Epoch: 23000/50000, Loss:   1.4039\n",
            "Epoch: 24000/50000, Loss:   1.3751\n",
            "Epoch: 25000/50000, Loss:   1.3807\n",
            "Epoch: 26000/50000, Loss:   1.3482\n",
            "Epoch: 27000/50000, Loss:   1.3510\n",
            "Epoch: 28000/50000, Loss:   1.3605\n",
            "Epoch: 29000/50000, Loss:   1.3188\n",
            "Epoch: 30000/50000, Loss:   1.3412\n",
            "Epoch: 31000/50000, Loss:   1.3371\n",
            "Epoch: 32000/50000, Loss:   1.2989\n",
            "Epoch: 33000/50000, Loss:   1.2848\n",
            "Epoch: 34000/50000, Loss:   1.3186\n",
            "Epoch: 35000/50000, Loss:   1.2906\n",
            "Epoch: 36000/50000, Loss:   1.2476\n",
            "Epoch: 37000/50000, Loss:   1.2922\n",
            "Epoch: 38000/50000, Loss:   1.2549\n",
            "Epoch: 39000/50000, Loss:   1.2597\n",
            "Epoch: 40000/50000, Loss:   1.2595\n",
            "Epoch: 41000/50000, Loss:   1.2573\n",
            "Epoch: 42000/50000, Loss:   1.2078\n",
            "Epoch: 43000/50000, Loss:   1.2299\n",
            "Epoch: 44000/50000, Loss:   1.2063\n",
            "Epoch: 45000/50000, Loss:   1.2230\n",
            "Epoch: 46000/50000, Loss:   1.2002\n",
            "Epoch: 47000/50000, Loss:   1.1901\n",
            "Epoch: 48000/50000, Loss:   1.2182\n",
            "Epoch: 49000/50000, Loss:   1.1909\n",
            "Epoch: 50000/50000, Loss:   1.1846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTmPBHROGaIa"
      },
      "source": [
        "\r\n",
        "def sample_next(model, x, prev_state, topk=5, uniform=True):\r\n",
        "    # Perform forward-prop and get the output of the last time-step\r\n",
        "    out, state = model(x, prev_state)\r\n",
        "    last_out = out[0, -1, :]\r\n",
        "\r\n",
        "    # Get the top-k indexes and their values\r\n",
        "    topk = topk if topk else last_out.shape[0]\r\n",
        "    top_logit, top_ix = torch.topk(last_out, k=topk, dim=-1)\r\n",
        "    \r\n",
        "    # Get the softmax of the topk's and sample\r\n",
        "    p = None if uniform else F.softmax(top_logit.detach(), dim=-1).numpy()\r\n",
        "    sampled_ix = np.random.choice(top_ix, p=p)\r\n",
        "    return sampled_ix, state\r\n",
        "\r\n",
        "\r\n",
        "def sample(model, seed, topk=5, uniform=True, max_seqlen=18, stop_on=None):\r\n",
        "    seed = seed if isinstance(seed, (list, tuple)) else [seed]\r\n",
        "    \r\n",
        "    model.eval()\r\n",
        "    with torch.no_grad():\r\n",
        "        sampled_ix_list = seed[:]\r\n",
        "        x = torch.tensor([seed])\r\n",
        "        \r\n",
        "        prev_state = model.init_state(b_size=1)\r\n",
        "        for t in range(max_seqlen - len(seed)):\r\n",
        "            sampled_ix, prev_state = sample_next(model, x, prev_state, topk, uniform)\r\n",
        "\r\n",
        "            sampled_ix_list.append(sampled_ix)\r\n",
        "            x = torch.tensor([[sampled_ix]])\r\n",
        "            \r\n",
        "            if sampled_ix==stop_on:\r\n",
        "                break\r\n",
        "    \r\n",
        "    model.train()\r\n",
        "    return sampled_ix_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CSdT9DQGqHS",
        "outputId": "28d58fa8-e993-4894-9e94-1738c66bb0fc"
      },
      "source": [
        "\r\n",
        "print(\"Samples where seed is a randomly chosen character.\")\r\n",
        "# COMPLETAR llamando a sample(), para obtener 10 nombres de dinosaurios partiendo de una seed aleatoria  \r\n",
        "    \r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Samples where seed is a randomly chosen character.\n",
            "i => inornis<EOS>\n",
            "a => amalilong<EOS>\n",
            "f => fulusunasaurus<EOS>\n",
            "z => zingobaria<EOS>\n",
            "r => rachytitanes<EOS>\n",
            "t => teratosaurus<EOS>\n",
            "d => diceratoptes<EOS>\n",
            "j => jiamsaurus<EOS>\n",
            "s => styratosaurus<EOS>\n",
            "h => hypselosaurus<EOS>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwxkSU3iVtjJ"
      },
      "source": [
        "#COMPLETAR: Nombres de dinosaurios a partir de una secuencia de letras (Ej. tu nombre)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}