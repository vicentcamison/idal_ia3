{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "07-Pytorch-DL_regresion.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vicentcamison/idal_ia3/blob/main/3%20Aprendizaje%20profundo%20(II)/Sesion%201/07_Pytorch_DL_regresion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nqPW8adYjVJ"
      },
      "source": [
        "![IDAL](https://i.imgur.com/tIKXIG1.jpg)  \n",
        "\n",
        "#<strong>**Máster en Inteligencia Artificial Avanzada y Aplicada  IA^3**</strong>\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqTSfSSlcCeJ"
      },
      "source": [
        "##<center>**Deep learning aplicado a regresión**<center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLjAp0-BGBxz"
      },
      "source": [
        "## Red neuronal completa, problema de regresión\n",
        "\n",
        "En este notebook vamos a ver un ejemplo completo de aplicación de una red neuronal completa de varias capas. En concreto, combinaremos datos continuos y categóricos para realizar una regresión. El objetivo es estimar el costo de un viaje en taxi de la ciudad de Nueva York a partir de varios datos. La inspiración detrás de este código es una reciente <a href='https://www.kaggle.com/c/new-york-city-taxi-fare-prediction'>competición de kaggle</a>.\n",
        "\n",
        "**NOTA:** En este cuaderno realizaremos una regresión con un valor de salida. En el siguiente cuaderno revisaremos el ejemplo para realizar una clasificación binaria con dos valores de salida.\n",
        "\n",
        "En el notebook nos vamos a centrar en varios aspectos: \n",
        "\n",
        "*   Importación de los datos desde ficheros csv\n",
        "*   Abordaje de un problema real, con diferentes tipos de variables.\n",
        "*   Procesado de las variables y generación de nuevas\n",
        "*   Tratamiento de variables categóricas\n",
        "*   Preparación de un modelo con varias capas ocultas (_deep_)\n",
        "*   Entrenamiento, validación y testeo del modelo\n",
        "* Guardado del modelo\n",
        "* Realización de nuevas predicciones.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbbF7DpjcSgq"
      },
      "source": [
        "## Trabajando con datos tabulares\r\n",
        "El aprendizaje profundo con redes neuronales se asocia a menudo con el reconocimiento sofisticado de imágenes, con el fin de obtener modelos basados en propiedades como patrones de píxeles y colores. Sin embargo también es posible (y habitual) trabajar con conjuntos de datos tabulares. \r\n",
        "En este ejemplo trabajaremos con datos tabulares ( proceden de hojas de cálculo, tablas SQL, etc.) con columnas de valores que pueden o no ser relevantes. Como sucede, las redes neuronales pueden aprender a hacer conexiones que probablemente no hubiéramos desarrollado por nuestra cuenta. Sin embargo, para hacerlo tenemos que manejar los valores categóricos por **separado** de los continuos. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPzSwyOtGBx0"
      },
      "source": [
        "## Importaciones standard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "LJRIkmKxGBx0"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOBCsYrYGBx1"
      },
      "source": [
        "## Carga del dataset NYC Taxi Fares \n",
        "\n",
        "La  <a href='https://www.kaggle.com/c/new-york-city-taxi-fare-prediction'>competición de Kaggle</a> provee un conjunto de datos de cerca 55 millones de registros. Los datos solo contienen las fecha, hora, latitud, longitud de la recogida y del destino, el número de pasajeros y el coste del viaje, que es el objetivo a predecir. Queda a elección del participante obtener y emplear cualquier información adicional. Por ejemplo, ¿influye la hora del día? ¿el día de la semana? ¿como determinamos la distancia recorrida?\n",
        "Para este ejercicio vamos a limitar el dataset a (solo) 120000 registros, desde el 11 al 24 de Abril de 2010. Los registros se han ordenado aleatoriamente. Vamos a ver como podemos calcular distancias desde coordenadas GPS y como preparar un dataframe de pandas con los datos que consideremos necesarios, como aprovechar la información de fecha y hora, generar nuevas variables de interés , etc.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0r0gcKMckP6"
      },
      "source": [
        "Para cargar los datos del dataset que vamos a emplear tenemos diversas opciones. \r\n",
        "* Los datos originales podemos cargarlos del repositorio de Kaggle de la competición. Sin embargo son muchos datos y en el ejercicio únicamente vamos a emplear una parte de ellos. \r\n",
        "* Podemos cargarlos desde nuestra unidad Drive ejecutando los siguientes scripts y siguiendo las instrucciones. Para montar la unidad nos genera una clave particular que hemos de introducir. A oartir de ese momento, la estructura de carpetas de nuestro disco Drive es accesible para el Notebook dentro de /content/drive. Más detalles en la [doc de Google](https://colab.research.google.com/notebooks/io.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1N0wH5ELaqGr",
        "outputId": "2e9275fc-111b-4b20-c03d-ea7497234936"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Kn7DjM3GbcP1",
        "outputId": "3397aed3-2308-4ee9-9f1c-3f47d8c520c4"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/IA3_DL2_T2/NYCTaxiFares.csv')\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pickup_datetime</th>\n",
              "      <th>fare_amount</th>\n",
              "      <th>fare_class</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>passenger_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-04-19 08:17:56 UTC</td>\n",
              "      <td>6.5</td>\n",
              "      <td>0</td>\n",
              "      <td>-73.992365</td>\n",
              "      <td>40.730521</td>\n",
              "      <td>-73.975499</td>\n",
              "      <td>40.744746</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-04-17 15:43:53 UTC</td>\n",
              "      <td>6.9</td>\n",
              "      <td>0</td>\n",
              "      <td>-73.990078</td>\n",
              "      <td>40.740558</td>\n",
              "      <td>-73.974232</td>\n",
              "      <td>40.744114</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-04-17 11:23:26 UTC</td>\n",
              "      <td>10.1</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.994149</td>\n",
              "      <td>40.751118</td>\n",
              "      <td>-73.960064</td>\n",
              "      <td>40.766235</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010-04-11 21:25:03 UTC</td>\n",
              "      <td>8.9</td>\n",
              "      <td>0</td>\n",
              "      <td>-73.990485</td>\n",
              "      <td>40.756422</td>\n",
              "      <td>-73.971205</td>\n",
              "      <td>40.748192</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-04-17 02:19:01 UTC</td>\n",
              "      <td>19.7</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.990976</td>\n",
              "      <td>40.734202</td>\n",
              "      <td>-73.905956</td>\n",
              "      <td>40.743115</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           pickup_datetime  fare_amount  ...  dropoff_latitude  passenger_count\n",
              "0  2010-04-19 08:17:56 UTC          6.5  ...         40.744746                1\n",
              "1  2010-04-17 15:43:53 UTC          6.9  ...         40.744114                1\n",
              "2  2010-04-17 11:23:26 UTC         10.1  ...         40.766235                2\n",
              "3  2010-04-11 21:25:03 UTC          8.9  ...         40.748192                1\n",
              "4  2010-04-17 02:19:01 UTC         19.7  ...         40.743115                1\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9IAScb3GBx2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d644b0e3-4dc6-4402-bee9-81dd032c94fb"
      },
      "source": [
        "df['fare_amount'].describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    120000.000000\n",
              "mean         10.040326\n",
              "std           7.500134\n",
              "min           2.500000\n",
              "25%           5.700000\n",
              "50%           7.700000\n",
              "75%          11.300000\n",
              "max          49.900000\n",
              "Name: fare_amount, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQIR_HbSGBx2"
      },
      "source": [
        "Observamos qe en el conjunto del que disponemos, el rango de tarifa va de 2.50 a 49.90, con una media 10.04\\$ y una mediana de 7.70\\$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obTVf4IwGBx3"
      },
      "source": [
        "## Calculando la disancia recorrida\n",
        "\n",
        "La <a href='https://en.wikipedia.org/wiki/Haversine_formula'>fórmula haversine </a> calcula la distancia en una esfera, dados dos puntos en coordenadas GPS.\n",
        "\n",
        "Vamos a llamar a la latitud $\\varphi$ (phi) y a la longitud $\\lambda$ (lambda).\n",
        "\n",
        "La formula de esta distancia es:\n",
        "\n",
        "${\\displaystyle d=2r\\arcsin \\left({\\sqrt {\\sin ^{2}\\left({\\frac {\\varphi _{2}-\\varphi _{1}}{2}}\\right)+\\cos(\\varphi _{1})\\:\\cos(\\varphi _{2})\\:\\sin ^{2}\\left({\\frac {\\lambda _{2}-\\lambda _{1}}{2}}\\right)}}\\right)}$\n",
        "\n",
        "donde\n",
        "\n",
        "$\\begin{split} r&: \\textrm {radio de la esfera (el radio de la Tierra es de promedio 6371 km)}\\\\\n",
        "\\varphi_1, \\varphi_2&: \\textrm {latitudes de punto 1 a punto 2}\\\\\n",
        "\\lambda_1, \\lambda_2&: \\textrm {longitudes de punto 1 a punto 2}\\end{split}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "hT1_cI9HGBx3"
      },
      "source": [
        "def haversine_distance(df, lat1, long1, lat2, long2):\n",
        "    \"\"\"\n",
        "    Calculo de la distancia haversine entre 2 puntos GPS\n",
        "    \"\"\"\n",
        "    r = 6371  # radio de la Tierra en km\n",
        "       \n",
        "    phi1 = np.radians(df[lat1])\n",
        "    phi2 = np.radians(df[lat2])\n",
        "    \n",
        "    delta_phi = np.radians(df[lat2]-df[lat1])\n",
        "    delta_lambda = np.radians(df[long2]-df[long1])\n",
        "     \n",
        "    a = np.sin(delta_phi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda/2)**2\n",
        "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
        "    d = (r * c) # en km\n",
        "\n",
        "    return d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2SrCJP8K7CP"
      },
      "source": [
        "Creamos una nueva columna con las distancias calculadas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9R3_gtnGBx4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "93b3fd9b-6e11-4560-d2cd-d647558af68a"
      },
      "source": [
        "df['dist_km'] = haversine_distance(df,'pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pickup_datetime</th>\n",
              "      <th>fare_amount</th>\n",
              "      <th>fare_class</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>passenger_count</th>\n",
              "      <th>dist_km</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-04-19 08:17:56 UTC</td>\n",
              "      <td>6.5</td>\n",
              "      <td>0</td>\n",
              "      <td>-73.992365</td>\n",
              "      <td>40.730521</td>\n",
              "      <td>-73.975499</td>\n",
              "      <td>40.744746</td>\n",
              "      <td>1</td>\n",
              "      <td>2.126312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-04-17 15:43:53 UTC</td>\n",
              "      <td>6.9</td>\n",
              "      <td>0</td>\n",
              "      <td>-73.990078</td>\n",
              "      <td>40.740558</td>\n",
              "      <td>-73.974232</td>\n",
              "      <td>40.744114</td>\n",
              "      <td>1</td>\n",
              "      <td>1.392307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-04-17 11:23:26 UTC</td>\n",
              "      <td>10.1</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.994149</td>\n",
              "      <td>40.751118</td>\n",
              "      <td>-73.960064</td>\n",
              "      <td>40.766235</td>\n",
              "      <td>2</td>\n",
              "      <td>3.326763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010-04-11 21:25:03 UTC</td>\n",
              "      <td>8.9</td>\n",
              "      <td>0</td>\n",
              "      <td>-73.990485</td>\n",
              "      <td>40.756422</td>\n",
              "      <td>-73.971205</td>\n",
              "      <td>40.748192</td>\n",
              "      <td>1</td>\n",
              "      <td>1.864129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-04-17 02:19:01 UTC</td>\n",
              "      <td>19.7</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.990976</td>\n",
              "      <td>40.734202</td>\n",
              "      <td>-73.905956</td>\n",
              "      <td>40.743115</td>\n",
              "      <td>1</td>\n",
              "      <td>7.231321</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           pickup_datetime  fare_amount  ...  passenger_count   dist_km\n",
              "0  2010-04-19 08:17:56 UTC          6.5  ...                1  2.126312\n",
              "1  2010-04-17 15:43:53 UTC          6.9  ...                1  1.392307\n",
              "2  2010-04-17 11:23:26 UTC         10.1  ...                2  3.326763\n",
              "3  2010-04-11 21:25:03 UTC          8.9  ...                1  1.864129\n",
              "4  2010-04-17 02:19:01 UTC         19.7  ...                1  7.231321\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "is6MNfUiGBx4"
      },
      "source": [
        "## Columna FechaHora y valores derivados que pueden ser útiles\n",
        "\n",
        "La Fecha y hora nos vienen en un formato importado de texto. Pasar eso a un objete de fechahora nos permitirá extraer información como el día de la semana, momento del día am o pm, etc.\n",
        "\n",
        "_**Nota**: Los datos están grabados en formato UTC. Teniendo en cuenta la fecha y el horario que manejan en Nueva York en ese momento, la hora correcta EDT necesita un ajuste de 4 horas menos (UTC-4)_\n",
        "\n",
        "Generamos las nuevas columnas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4sTH9GtGBx4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "31252ee0-6933-458d-c36e-354115840852"
      },
      "source": [
        "df['EDTdate'] = pd.to_datetime(df['pickup_datetime'].str[:19]) - pd.Timedelta(hours=4)\n",
        "df['Hour'] = df['EDTdate'].dt.hour\n",
        "df['AMorPM'] = np.where(df['Hour']<12,'am','pm')\n",
        "df['Weekday'] = df['EDTdate'].dt.strftime(\"%a\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pickup_datetime</th>\n",
              "      <th>fare_amount</th>\n",
              "      <th>fare_class</th>\n",
              "      <th>pickup_longitude</th>\n",
              "      <th>pickup_latitude</th>\n",
              "      <th>dropoff_longitude</th>\n",
              "      <th>dropoff_latitude</th>\n",
              "      <th>passenger_count</th>\n",
              "      <th>dist_km</th>\n",
              "      <th>EDTdate</th>\n",
              "      <th>Hour</th>\n",
              "      <th>AMorPM</th>\n",
              "      <th>Weekday</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2010-04-19 08:17:56 UTC</td>\n",
              "      <td>6.5</td>\n",
              "      <td>0</td>\n",
              "      <td>-73.992365</td>\n",
              "      <td>40.730521</td>\n",
              "      <td>-73.975499</td>\n",
              "      <td>40.744746</td>\n",
              "      <td>1</td>\n",
              "      <td>2.126312</td>\n",
              "      <td>2010-04-19 04:17:56</td>\n",
              "      <td>4</td>\n",
              "      <td>am</td>\n",
              "      <td>Mon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2010-04-17 15:43:53 UTC</td>\n",
              "      <td>6.9</td>\n",
              "      <td>0</td>\n",
              "      <td>-73.990078</td>\n",
              "      <td>40.740558</td>\n",
              "      <td>-73.974232</td>\n",
              "      <td>40.744114</td>\n",
              "      <td>1</td>\n",
              "      <td>1.392307</td>\n",
              "      <td>2010-04-17 11:43:53</td>\n",
              "      <td>11</td>\n",
              "      <td>am</td>\n",
              "      <td>Sat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2010-04-17 11:23:26 UTC</td>\n",
              "      <td>10.1</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.994149</td>\n",
              "      <td>40.751118</td>\n",
              "      <td>-73.960064</td>\n",
              "      <td>40.766235</td>\n",
              "      <td>2</td>\n",
              "      <td>3.326763</td>\n",
              "      <td>2010-04-17 07:23:26</td>\n",
              "      <td>7</td>\n",
              "      <td>am</td>\n",
              "      <td>Sat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2010-04-11 21:25:03 UTC</td>\n",
              "      <td>8.9</td>\n",
              "      <td>0</td>\n",
              "      <td>-73.990485</td>\n",
              "      <td>40.756422</td>\n",
              "      <td>-73.971205</td>\n",
              "      <td>40.748192</td>\n",
              "      <td>1</td>\n",
              "      <td>1.864129</td>\n",
              "      <td>2010-04-11 17:25:03</td>\n",
              "      <td>17</td>\n",
              "      <td>pm</td>\n",
              "      <td>Sun</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2010-04-17 02:19:01 UTC</td>\n",
              "      <td>19.7</td>\n",
              "      <td>1</td>\n",
              "      <td>-73.990976</td>\n",
              "      <td>40.734202</td>\n",
              "      <td>-73.905956</td>\n",
              "      <td>40.743115</td>\n",
              "      <td>1</td>\n",
              "      <td>7.231321</td>\n",
              "      <td>2010-04-16 22:19:01</td>\n",
              "      <td>22</td>\n",
              "      <td>pm</td>\n",
              "      <td>Fri</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           pickup_datetime  fare_amount  fare_class  ...  Hour  AMorPM  Weekday\n",
              "0  2010-04-19 08:17:56 UTC          6.5           0  ...     4      am      Mon\n",
              "1  2010-04-17 15:43:53 UTC          6.9           0  ...    11      am      Sat\n",
              "2  2010-04-17 11:23:26 UTC         10.1           1  ...     7      am      Sat\n",
              "3  2010-04-11 21:25:03 UTC          8.9           0  ...    17      pm      Sun\n",
              "4  2010-04-17 02:19:01 UTC         19.7           1  ...    22      pm      Fri\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RypBuYZqGBx5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74138bda-8294-40e6-aa31-f0b50b42f1e1"
      },
      "source": [
        "df['EDTdate'].min()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Timestamp('2010-04-11 00:00:10')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-sDhZ5DGBx8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86d14ab7-059a-4157-f408-19df00027ae3"
      },
      "source": [
        "df['EDTdate'].max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Timestamp('2010-04-24 23:59:42')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQNvuunTGBx8"
      },
      "source": [
        "## Separamos variables categóricas y continuas\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92_5cSgrGBx9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f052e6e1-f968-47dc-c985-d1a9d9a65cff"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['pickup_datetime', 'fare_amount', 'fare_class', 'pickup_longitude',\n",
              "       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
              "       'passenger_count', 'dist_km', 'EDTdate', 'Hour', 'AMorPM', 'Weekday'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "_6sG0hpnGBx9"
      },
      "source": [
        "cat_cols = ['Hour', 'AMorPM', 'Weekday']\n",
        "cont_cols = ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude', 'passenger_count', 'dist_km']\n",
        "y_col = ['fare_amount']  # Esta columna es el objetivo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djx9TU6sGBx-"
      },
      "source": [
        "Hemos especificado las columnas que vamos a usar de cada tipo. Observemos que **no** vamos a emplear todas. Dejamos fuera pickup_datetime y EDTdate ya que en su lugar vamos a emplear las nuevas columnas categóricas que hemos prparado</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcdMZyYWGBx-"
      },
      "source": [
        "## Categorizar\n",
        "\n",
        "Panda nos permite emplear un tipo de dato <a href='https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html'><strong>category dtype</strong></a> para convertir valores categóricos a códigos numéricos. Así, un dataset con meses del año tendrá asignados 12 códigos, uno por mes (0-11). Lo que hace pandas es sustituir las columnas por códigos y retiene una lista índice de las categorías. En los siguientes pasos llamaremos a las categorías`categories` y a su codificación `codes`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ZJ3YlZgjGBx_"
      },
      "source": [
        "for cat in cat_cols:\n",
        "    df[cat] = df[cat].astype('category')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqTnMb6AGBx_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79f587bd-c6b9-41ef-a6ba-f4ee16bf1090"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pickup_datetime              object\n",
              "fare_amount                 float64\n",
              "fare_class                    int64\n",
              "pickup_longitude            float64\n",
              "pickup_latitude             float64\n",
              "dropoff_longitude           float64\n",
              "dropoff_latitude            float64\n",
              "passenger_count               int64\n",
              "dist_km                     float64\n",
              "EDTdate              datetime64[ns]\n",
              "Hour                       category\n",
              "AMorPM                     category\n",
              "Weekday                    category\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOe-9vErGBx_"
      },
      "source": [
        "Vamos a comprobar como `df['Hour']`es ahora una variable categórica codificada:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl8w71w2GByA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0ddc750-88ad-4882-e42d-3a7dbe205de0"
      },
      "source": [
        "df['Hour'].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     4\n",
              "1    11\n",
              "2     7\n",
              "3    17\n",
              "4    22\n",
              "Name: Hour, dtype: category\n",
              "Categories (24, int64): [0, 1, 2, 3, ..., 20, 21, 22, 23]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUKHfGV6fMF-",
        "outputId": "21432835-ba24-47b6-dd4c-4a3a984e1955"
      },
      "source": [
        "df['Hour'].head().cat.codes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     4\n",
              "1    11\n",
              "2     7\n",
              "3    17\n",
              "4    22\n",
              "dtype: int8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrIBJB64GByA"
      },
      "source": [
        "Aquí los nombres de categoría son enteros de 0 a 23, con un total de 24 categorías. Estos valores se corresponden con los valores asignados a cada nombre.\n",
        "\n",
        "Podemos acceder a los nombres con <tt>Series.cat.categories</tt> o a los códigos con <tt>Series.cat.codes</tt>. Vamos a verlo con <tt>df['AMorPM']</tt>:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6HirlgkGByB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5617b5ed-33ee-42bc-a716-c30c86cee71f"
      },
      "source": [
        "df['AMorPM'].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    am\n",
              "1    am\n",
              "2    am\n",
              "3    pm\n",
              "4    pm\n",
              "Name: AMorPM, dtype: category\n",
              "Categories (2, object): ['am', 'pm']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02HuKPNRGByB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "798f04f6-fd4f-488d-dbae-9c0371f7aca0"
      },
      "source": [
        "df['AMorPM'].cat.categories"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['am', 'pm'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CBN5EwWGByC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e89ae794-2929-4eb0-82e7-0c011c3637f9"
      },
      "source": [
        "df['AMorPM'].head().cat.codes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    0\n",
              "2    0\n",
              "3    1\n",
              "4    1\n",
              "dtype: int8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3L2hjrOGByC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87f3d553-11e8-49cc-8281-a2dfe91a2dc5"
      },
      "source": [
        "df['Weekday'].cat.categories"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Fri', 'Mon', 'Sat', 'Sun', 'Thu', 'Tue', 'Wed'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlmIHF6Ke4kF",
        "outputId": "f06f01dc-307d-4a3a-9358-21129b359f79"
      },
      "source": [
        "df['Weekday'].head()\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Mon\n",
              "1    Sat\n",
              "2    Sat\n",
              "3    Sun\n",
              "4    Fri\n",
              "Name: Weekday, dtype: category\n",
              "Categories (7, object): ['Fri', 'Mon', 'Sat', 'Sun', 'Thu', 'Tue', 'Wed']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX8aqlUcGByD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ab58ad7-5394-44aa-e145-4cb49be4030a"
      },
      "source": [
        "df['Weekday'].head().cat.codes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1\n",
              "1    2\n",
              "2    2\n",
              "3    3\n",
              "4    0\n",
              "dtype: int8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaLV1FmRGByD"
      },
      "source": [
        "**NOTA:** Observese que los días de la semana están codificados sin el orden \"normal\".\r\n",
        "\r\n",
        "**NOTA2:** Los valores NaN se codifican como -1. No tenemos ninguno en ese conjunto de datos en particular. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdLuKk-dGByE"
      },
      "source": [
        "Ahora podemos combinar los códigos de las tres columnas categóricas en un array de entrada con la función de Numpy <a href='https://docs.scipy.org/doc/numpy/reference/generated/numpy.stack.html'><tt>numpy.stack</tt></a>. No necesitamos los índices de las categorías, solo los valores. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uESkYD0RGByE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28a71239-5f8c-4893-9632-27271689f09f"
      },
      "source": [
        "hr = df['Hour'].cat.codes.values\n",
        "ampm = df['AMorPM'].cat.codes.values\n",
        "wkdy = df['Weekday'].cat.codes.values\n",
        "\n",
        "cats = np.stack([hr, ampm, wkdy], 1)\n",
        "\n",
        "cats[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4,  0,  1],\n",
              "       [11,  0,  2],\n",
              "       [ 7,  0,  2],\n",
              "       [17,  1,  3],\n",
              "       [22,  1,  0]], dtype=int8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-G9erjQGByF"
      },
      "source": [
        "**NOTA:** Esto se puede hacer en una sola línea empleando _list comprehension_:\n",
        "\n",
        "`cats = np.stack([df[col].cat.codes.values for col in cat_cols], 1)`\n",
        "\n",
        "De momento no nos preocuparemos por el tipo de datos `dtype`. Lo podremos convertir a int64 cuando pasemos el array a tensor.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUGJCA25GByF"
      },
      "source": [
        "## Conversión de numpy arrays a tensores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2OfxZBCGByF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af043d07-bc06-4712-abca-721bd23bda29"
      },
      "source": [
        "# Categoricas\n",
        "cats = torch.tensor(cats, dtype=torch.int64) \n",
        "\n",
        "cats[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4,  0,  1],\n",
              "        [11,  0,  2],\n",
              "        [ 7,  0,  2],\n",
              "        [17,  1,  3],\n",
              "        [22,  1,  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH5z05pNGByG"
      },
      "source": [
        "También pasaremos las continuas a tensor para el modelo. No las vamos a normalizar aquí, dejamos ese paso para realizarlo dentro del modelo. \n",
        "\n",
        "**NOTA:** Por cuestiones de la normalización que realizaremos posteriormente, vamos a dejar las variables continuas como `Float (float32)` en lugar de `Double (float64)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItjJiJoQGByG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34c334da-ce5a-4ebd-f143-66cedd546e3b"
      },
      "source": [
        "# Continuas a tensor\n",
        "conts = np.stack([df[col].values for col in cont_cols], 1)\n",
        "conts = torch.tensor(conts, dtype=torch.float)\n",
        "conts[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 40.7305, -73.9924,  40.7447, -73.9755,   1.0000,   2.1263],\n",
              "        [ 40.7406, -73.9901,  40.7441, -73.9742,   1.0000,   1.3923],\n",
              "        [ 40.7511, -73.9941,  40.7662, -73.9601,   2.0000,   3.3268],\n",
              "        [ 40.7564, -73.9905,  40.7482, -73.9712,   1.0000,   1.8641],\n",
              "        [ 40.7342, -73.9910,  40.7431, -73.9060,   1.0000,   7.2313]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lA_01zDwGByH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b8462d9f-cb68-4f77-dec9-489c5b4e8b3a"
      },
      "source": [
        "conts.type()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'torch.FloatTensor'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-vv4_ahGByH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a694af42-acc3-4d47-fbd5-030a415e6888"
      },
      "source": [
        "# Convertimos etiquetas a tensor\n",
        "y = torch.tensor(df[y_col].values, dtype=torch.float).reshape(-1,1)\n",
        "\n",
        "y[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 6.5000],\n",
              "        [ 6.9000],\n",
              "        [10.1000],\n",
              "        [ 8.9000],\n",
              "        [19.7000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2VyFQBGhBmi"
      },
      "source": [
        "Comprobamos dimensiones: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m90vYswGByI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b22d25e-b3bd-4ff1-f5bc-da3ed9092e92"
      },
      "source": [
        "cats.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([120000, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf5kQNpOGByI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e32ec10-96f4-4468-8934-e453e4a1039c"
      },
      "source": [
        "conts.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([120000, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koCJEEAQGByJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "291bb552-2883-4ebb-d62c-fb01fc7287bc"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([120000, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIfFNr6RGByJ"
      },
      "source": [
        "## Embedding para las variables categóricas\n",
        "\n",
        "Las variables categóricas proporcionan un mejor resultado si en lugar de tratarlas como un código numérico, realizamos un proceso llamado Embedding (se traduciría como Integración/incrustación). En el embedding cada código asignado se mapea a unas variables nuevas. Esto es así porque el embedding resuelve ciertos problemas que se dan al tratar variables categóricas, que representan categorías a menudo no ordinales, pero sí relacionadas en otros aspectos.\n",
        "\n",
        "Existen diversas formas de afrontar ese recodificado. Uno de los más simples y conocidos consiste en el OHE _One Hot Encoding_. Sin embargo, existen formas algo más evolucionadas como la que vamos a tratar en este ejercicio. \n",
        "El Embedding es una parte fundamental en el procesado de lenguaje natural, aunque su uso no se limita a dicha area. \n",
        "Encontramos [aquí](https://medium.com/@davidheffernan_99410/an-introduction-to-using-categorical-embeddings-ee686ed7e7f9) y [aquí](https://towardsdatascience.com/neural-network-embeddings-explained-4d028e6f0526) buenas explicaciones de los que es y porqué es conveniente. \n",
        "\n",
        "La regla del pulgar para determinar un tamaño de embedding es dividir el numero total de categorías únicas de la variable en cuestion entre 2, pero sin pasar de 50. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWEPWZTNGByK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8357997e-8ed4-4208-bd19-afb33e5e6ea5"
      },
      "source": [
        "# Determinamos los tamaños para embedding para Hours, AMvsPM y Weekdays\n",
        "cat_szs = [len(df[col].cat.categories) for col in cat_cols]\n",
        "emb_szs = [(size, min(50, (size+1)//2)) for size in cat_szs]\n",
        "emb_szs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(24, 12), (2, 1), (7, 4)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsEMIR-UGByK"
      },
      "source": [
        "## Definimos un modelo tabular (_TabularModel_)\n",
        "\n",
        "Este tipo de modelo está inspirado en los procedimientos de la librería <a href='https://docs.fast.ai/tabular.models.html'>fast.ai library</a>  El hecho de llamarlo modelo tabular viene de que los datos provienen de tablas, con tipos diferentes y que en mayor o menor medida se han procesado previamente. En ese preprocesado se generan o descartan variables si se considera y se hace una distinción entre variables continuas y categóricas. \n",
        "El objetivo final es definir un modelo basado en el número de variables continuas (dado por <tt>conts.shape[1]</tt>) más el número de variables categóricas y sus embeddings (dados por <tt>len(emb_szs)</tt> y <tt>emb_szs</tt> respectivamente).  La salida será una regresión (un valor único, tipo flotante), o una clasificación (un grupo de intervalos y sus valores softmax).\n",
        "\n",
        "En este ejercicio vamos a obtener la salida de regresión, que pretende predecir la cantidad que deben pagar los usuarios por el viaje realizado. También en este ejercicio vamos a trabajas con los dos tipos de datos, continuos y categóricos. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTQyts24GByK"
      },
      "source": [
        "**Vamos a estudiar en detalle los pasos que vamos a realizar a continuación**\n",
        "\n",
        "1. Extendemos la clase base Module indicandle los siguientes parámetros:\n",
        "   * <tt>emb_szs: </tt>lista de tuplas: el tamaño de cada variable categórica (número de categorías únicas) junto con el tamaño elegido para su _embedding_\n",
        "   * <tt>n_cont:  </tt>int: número de variables continuas\n",
        "   * <tt>out_sz:  </tt>int: tamaño de salida\n",
        "   * <tt>layers:  </tt>list of ints: tamaño de las capas intermedias que deseemos poner\n",
        "   * <tt>p:       </tt>float: factor de dropout para cada capa (por simplicidad usaremos el mismo en todas las capas)\n",
        "\n",
        "<tt><font color=black>class TabularModel(nn.Module):<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;def \\_\\_init\\_\\_(self, emb_szs, n_cont, out_sz, layers, p=0.5):<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;super().\\_\\_init\\_\\_()</font></tt><br>\n",
        "\n",
        "2. Generamos las capas embedded con  <a href='https://pytorch.org/docs/stable/nn.html#modulelist'><tt><strong>torch.nn.ModuleList()</strong></tt></a> y con  <a href='https://pytorch.org/docs/stable/nn.html#embedding'><tt><strong>torch.nn.Embedding()</strong></tt></a>\n",
        "Los datos categóricos serán filtrados a través del Embeddings en la sección forward de la clase con el siguiente código:<br>\n",
        "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])</font></tt><br><br>\n",
        "3. Incluidmos un factor dropout `p` en el embeddings con <a href='https://pytorch.org/docs/stable/nn.html#dropout'><tt><strong>torch.nn.Dropout()</strong></tt></a> Por defecto pondremos `p=0.5`<br>\n",
        "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.emb_drop = nn.Dropout(emb_drop)</font></tt><br><br>\n",
        "4. Realizaremos una normalización sobre las variables continuas con <a href='https://pytorch.org/docs/stable/nn.html#batchnorm1d'><tt><strong>torch.nn.BatchNorm1d()</strong></tt></a><br>\n",
        "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.bn_cont = nn.BatchNorm1d(n_cont)</font></tt><br><br>\n",
        "5. Definimos una secuencia de capas de red neuronal donde cada nivel incluirá una función lineal, una función de activación (en nuestro caso <a href='https://pytorch.org/docs/stable/nn.html#relu'><strong>ReLU</strong></a>),\n",
        "un paso de normalización y un factor de dropout. Para combinar la secuencia de capas usaremos <a href='https://pytorch.org/docs/stable/nn.html#sequential'><tt><strong>torch.nn.Sequential()</strong></tt></a>. Obsérvese que este código permite especificar **tantas capas ocultas** como especifiquemos en el argumento `layers`<br>\n",
        "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.bn_cont = nn.BatchNorm1d(n_cont)<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;layerlist = []<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;n_emb = sum((nf for ni,nf in emb_szs))<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;n_in = n_emb + n_cont<br>\n",
        "<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;for i in layers:<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;layerlist.append(nn.Linear(n_in,i)) <br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;layerlist.append(nn.ReLU(inplace=True))<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;layerlist.append(nn.BatchNorm1d(i))<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;layerlist.append(nn.Dropout(p))<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;n_in = i<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;layerlist.append(nn.Linear(layers[-1],out_sz))<br>\n",
        "<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;self.layers = nn.Sequential(*layerlist)</font></tt><br><br>\n",
        "6. Definimos el método `forward`. En este método se realiza el preprocesado de  embeddings sobre las categóricas y la normalización sobre las continuas antes de unirlas todas y pasarlas a través de las capas. <br>Usaremos <a href='https://pytorch.org/docs/stable/torch.html#torch.cat'><tt><strong>torch.cat()</strong></tt></a> para combinar los tensores en uno.<br>\n",
        "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;def forward(self, x_cat, x_cont):<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;embeddings = []<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;for i,e in enumerate(self.embeds):<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;embeddings.append(e(x_cat[:,i]))<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;x = torch.cat(embeddings, 1)<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;x = self.emb_drop(x)<br>\n",
        "<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;x_cont = self.bn_cont(x_cont)<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;x = torch.cat([x, x_cont], 1)<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;x = self.layers(x)<br>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;return x</font></tt>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiIRjISWGByL"
      },
      "source": [
        "### **Desglosando los pasos del Embedding** \r\n",
        "Las siguientes celdas de código están unicamente con fines explicativos sobre los detalles del embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rt9KEGpzGByL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7383b856-70f9-4179-fbd6-d13b617e9023"
      },
      "source": [
        "# Estos son nuestros datos origen, \n",
        "catz = cats[:4]\n",
        "catz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4,  0,  1],\n",
              "        [11,  0,  2],\n",
              "        [ 7,  0,  2],\n",
              "        [17,  1,  3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isafo0iXGByL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66b31483-efba-4627-827e-04f935da1aec"
      },
      "source": [
        "# Esto es lo que pasamos cuando el instanciamos el modelo\n",
        "emb_szs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(24, 12), (2, 1), (7, 4)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yerBPyszGByM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13e83a3e-3a25-4477-b704-c315327b15a0"
      },
      "source": [
        "# Esto se realiza en el metodo __init__\n",
        "selfembeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
        "selfembeds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModuleList(\n",
              "  (0): Embedding(24, 12)\n",
              "  (1): Embedding(2, 1)\n",
              "  (2): Embedding(7, 4)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyvGJX2SGByM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbbc0819-6c55-4af4-e631-2bf0060f1986"
      },
      "source": [
        "list(enumerate(selfembeds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, Embedding(24, 12)), (1, Embedding(2, 1)), (2, Embedding(7, 4))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCA1BQPXGByM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4eca3fd2-596c-4685-d956-38569c02ed37"
      },
      "source": [
        "# Esto es lo que ocurre en el metodo forward()\n",
        "embeddingz = []\n",
        "for i,e in enumerate(selfembeds):\n",
        "    embeddingz.append(e(catz[:,i]))\n",
        "embeddingz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[-0.0563,  0.4241,  1.6506, -0.5150, -0.3378,  0.9348,  0.2608, -1.0777,\n",
              "          -1.5376,  0.2331, -0.7155, -1.4765],\n",
              "         [-1.7659, -0.9757, -0.8239, -0.4667,  1.2974, -0.5484, -1.2628,  0.5373,\n",
              "          -0.7151,  0.7899, -0.4672,  0.5213],\n",
              "         [-1.1862, -0.3021, -1.3075,  1.1054,  0.8608,  0.7449, -0.0750,  0.3216,\n",
              "           0.4909,  0.9544,  0.3455,  0.3916],\n",
              "         [ 1.1528,  0.3192,  0.2732,  0.0737, -0.7572, -1.5875, -0.9409, -0.6160,\n",
              "          -0.3653,  0.8617,  0.2217, -1.4231]], grad_fn=<EmbeddingBackward>),\n",
              " tensor([[1.8933],\n",
              "         [1.8933],\n",
              "         [1.8933],\n",
              "         [1.0251]], grad_fn=<EmbeddingBackward>),\n",
              " tensor([[ 1.8671,  0.1844,  1.1752, -1.4316],\n",
              "         [ 0.2572, -2.6230,  0.2279,  1.3817],\n",
              "         [ 0.2572, -2.6230,  0.2279,  1.3817],\n",
              "         [ 1.0920,  0.6097,  1.0280,  0.1129]], grad_fn=<EmbeddingBackward>)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84uZTehDGByN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44b19e77-a4a8-4550-93f6-2c0f2ed28a31"
      },
      "source": [
        "# Concatenamos los tensores resultantes de cada variable, con dimensiones (12,1,4) en uno (17)\n",
        "z = torch.cat(embeddingz, 1)\n",
        "z"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0563,  0.4241,  1.6506, -0.5150, -0.3378,  0.9348,  0.2608, -1.0777,\n",
              "         -1.5376,  0.2331, -0.7155, -1.4765,  1.8933,  1.8671,  0.1844,  1.1752,\n",
              "         -1.4316],\n",
              "        [-1.7659, -0.9757, -0.8239, -0.4667,  1.2974, -0.5484, -1.2628,  0.5373,\n",
              "         -0.7151,  0.7899, -0.4672,  0.5213,  1.8933,  0.2572, -2.6230,  0.2279,\n",
              "          1.3817],\n",
              "        [-1.1862, -0.3021, -1.3075,  1.1054,  0.8608,  0.7449, -0.0750,  0.3216,\n",
              "          0.4909,  0.9544,  0.3455,  0.3916,  1.8933,  0.2572, -2.6230,  0.2279,\n",
              "          1.3817],\n",
              "        [ 1.1528,  0.3192,  0.2732,  0.0737, -0.7572, -1.5875, -0.9409, -0.6160,\n",
              "         -0.3653,  0.8617,  0.2217, -1.4231,  1.0251,  1.0920,  0.6097,  1.0280,\n",
              "          0.1129]], grad_fn=<CatBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "AlIGAgrOGByN"
      },
      "source": [
        "# Esto se ha definido en el metodo __init__()\n",
        "selfembdrop = nn.Dropout(.4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwawJWpkGByN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3becdd7b-5ee8-4fd9-e964-28272acb556a"
      },
      "source": [
        "z = selfembdrop(z)\n",
        "z"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0000,  0.0000,  0.0000, -0.8584, -0.5631,  1.5580,  0.4347, -0.0000,\n",
              "         -0.0000,  0.0000, -1.1925, -2.4608,  0.0000,  3.1118,  0.0000,  0.0000,\n",
              "         -0.0000],\n",
              "        [-2.9431, -0.0000, -1.3732, -0.0000,  0.0000, -0.9140, -2.1047,  0.0000,\n",
              "         -0.0000,  0.0000, -0.7786,  0.8688,  0.0000,  0.0000, -4.3717,  0.3798,\n",
              "          0.0000],\n",
              "        [-1.9770, -0.5036, -2.1792,  0.0000,  1.4346,  0.0000, -0.1249,  0.5360,\n",
              "          0.8182,  1.5906,  0.5759,  0.6526,  3.1555,  0.4287, -0.0000,  0.3798,\n",
              "          0.0000],\n",
              "        [ 0.0000,  0.0000,  0.4553,  0.0000, -1.2619, -2.6458, -0.0000, -1.0267,\n",
              "         -0.0000,  1.4362,  0.3695, -2.3718,  1.7085,  1.8200,  0.0000,  1.7133,\n",
              "          0.1882]], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZvpP7O5GByO"
      },
      "source": [
        "**Así es como proporcionamos las variables categóricas a las capas**, concatenandolas previamente con las continuas. \r\n",
        "\r\n",
        "Teniendo en cuenta todo esto, esta es la definición de la clase: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "NjftU1GIGByQ"
      },
      "source": [
        "class TabularModel(nn.Module):\n",
        "\n",
        "    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n",
        "        super().__init__()\n",
        "        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
        "        self.emb_drop = nn.Dropout(p)\n",
        "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
        "        \n",
        "        layerlist = []\n",
        "        n_emb = sum((nf for ni,nf in emb_szs))\n",
        "        n_in = n_emb + n_cont\n",
        "        \n",
        "        for i in layers:\n",
        "            layerlist.append(nn.Linear(n_in,i)) \n",
        "            layerlist.append(nn.ReLU(inplace=True))\n",
        "            layerlist.append(nn.BatchNorm1d(i))\n",
        "            layerlist.append(nn.Dropout(p))\n",
        "            n_in = i\n",
        "        layerlist.append(nn.Linear(layers[-1],out_sz))\n",
        "            \n",
        "        self.layers = nn.Sequential(*layerlist)\n",
        "    \n",
        "    def forward(self, x_cat, x_cont):\n",
        "        embeddings = []\n",
        "        for i,e in enumerate(self.embeds):\n",
        "            embeddings.append(e(x_cat[:,i]))\n",
        "        x = torch.cat(embeddings, 1)\n",
        "        x = self.emb_drop(x)\n",
        "        \n",
        "        x_cont = self.bn_cont(x_cont)\n",
        "        x = torch.cat([x, x_cont], 1)\n",
        "        x = self.layers(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "LmVK4ChNGByQ"
      },
      "source": [
        "torch.manual_seed(33)\n",
        "model = TabularModel(emb_szs, conts.shape[1], 1, [300,100], p=0.4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ivCSRU76bYg"
      },
      "source": [
        "Comprobemos que la arquitectura es la correcta: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_kjWxznGByR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "067d528d-3ebd-4f21-fb2c-3fbda72f38d0"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TabularModel(\n",
              "  (embeds): ModuleList(\n",
              "    (0): Embedding(24, 12)\n",
              "    (1): Embedding(2, 1)\n",
              "    (2): Embedding(7, 4)\n",
              "  )\n",
              "  (emb_drop): Dropout(p=0.4, inplace=False)\n",
              "  (bn_cont): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layers): Sequential(\n",
              "    (0): Linear(in_features=23, out_features=300, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Dropout(p=0.4, inplace=False)\n",
              "    (4): Linear(in_features=300, out_features=100, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): Dropout(p=0.4, inplace=False)\n",
              "    (8): Linear(in_features=100, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6RuEF59GByR"
      },
      "source": [
        "## Definimos función de coste y optimizador\n",
        "En ejercicios anteriores hemos usado la función de coste MSE. Sin embargo, resulta más interpretable (por estar en las mismas unidades que el target) emplear el RMSE. Dado que Pytorch no incorpora integrado la función <a href='https://en.wikipedia.org/wiki/Root-mean-square_deviation'>RMSE Loss</a> podemos calcularla simplemente aplicado la raiz cuadrada con <tt>torch.sqrt()</tt> al resultado de la función MSE durante el entrenamiento. \n",
        "\n",
        "Así pues definimos: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "2_QL4CF0GByR"
      },
      "source": [
        "criterion = nn.MSELoss()  # lo convertiremos a RMSE después\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SN81m27pGByS"
      },
      "source": [
        "## Preparamos conjuntos de train/test\n",
        "En este punto, nuestro conjunt es un único lote de 120000 registros.  Esto llevará un tiempo de entrenamiento, por lo que podemos plantearnos reducirlo. Vamos a emplear 60000. Recordemos que los tensores ya estaban ordenados aleatoriamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ORraM46BGByS"
      },
      "source": [
        "batch_size = 60000\n",
        "test_size = int(batch_size * .2)\n",
        "\n",
        "cat_train = cats[:batch_size-test_size]\n",
        "cat_test = cats[batch_size-test_size:batch_size]\n",
        "con_train = conts[:batch_size-test_size]\n",
        "con_test = conts[batch_size-test_size:batch_size]\n",
        "y_train = y[:batch_size-test_size]\n",
        "y_test = y[batch_size-test_size:batch_size]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-f0hIUHpGByS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fac6b6c3-89cf-40cc-83fc-8183f5798d60"
      },
      "source": [
        "len(cat_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKY3pW2zGByT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46d9a8af-8236-4def-8072-8be312f29079"
      },
      "source": [
        "len(cat_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDbGD4JOGByT"
      },
      "source": [
        "## Entrenando el modelo \n",
        "\n",
        "En ejercicios anteriores, el proceso de entrenamiento lo hemos definido en una función `fit` donde integramos el entrenamiento y la validación. Esto no es necesario realizarlo así siempre. Podemos simplemente realizar el bucle de entrenamiento para los epochs que queramos y después aplicar el modelo en el conjunto de test. Esta separación puede ser ineresante (o necesaria) cuando el modelo tarda mucho en la fase de entrenamiento. \n",
        "\n",
        "Es posible que nuestro modelo  tarde 30 min o más. Añadimos algunas líneas de código para observar al final la duración.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHuDDrRxGByT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "883d8165-20c7-432c-c11e-ee5b252dd5c1"
      },
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "epochs = 300\n",
        "losses = []\n",
        "\n",
        "for i in range(epochs):\n",
        "    i+=1\n",
        "\n",
        "    y_pred = model(cat_train, con_train)\n",
        "    loss = torch.sqrt(criterion(y_pred, y_train)) # RMSE\n",
        "    losses.append(loss)\n",
        "    \n",
        "    # Mostramos en pantalla cada 25 epochs:\n",
        "    if i%25 == 1:\n",
        "        print(f'epoch: {i:3}  loss: {loss.item():10.8f}')\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "print(f'epoch: {i:3}  loss: {loss.item():10.8f}') # print the last line\n",
        "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:   1  loss: 12.55656242\n",
            "epoch:  26  loss: 10.71524811\n",
            "epoch:  51  loss: 10.11211967\n",
            "epoch:  76  loss: 9.67676449\n",
            "epoch: 101  loss: 9.16138649\n",
            "epoch: 126  loss: 8.42829990\n",
            "epoch: 151  loss: 7.44493628\n",
            "epoch: 176  loss: 6.30381441\n",
            "epoch: 201  loss: 5.12436295\n",
            "epoch: 226  loss: 4.17876339\n",
            "epoch: 251  loss: 3.81657648\n",
            "epoch: 276  loss: 3.74913311\n",
            "epoch: 300  loss: 3.64693809\n",
            "\n",
            "Duration: 544 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PW6mAuK1GByU"
      },
      "source": [
        "## Visualizamos la función de error "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dAZvynkGByU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "4be5271a-b023-4321-c3d3-aab2a11d1b6b"
      },
      "source": [
        "plt.plot(range(epochs), losses)\n",
        "plt.ylabel('RMSE Loss')\n",
        "plt.xlabel('epoch');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgMLMPTPGByU"
      },
      "source": [
        "## Validamos el modelo\n",
        "Ahora vamos a lanzar el modelo con el conjunto de test y a comparar los resultados con las etiquetas conocidas. \n",
        "\n",
        "Dado que en este paso no es necesario actualizar pesos ni biases, no es necesario emplear la función autograd, por lo que ponemos <tt>torch.no_grad()</tt> y evitamos cálculos (y tiempo ) innecesario."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiWCWvvkGByV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2544a14-b64d-4e9c-8ae9-34be46f32ade"
      },
      "source": [
        "# (método validation_step en el ejemplo anterior)\n",
        "with torch.no_grad():\n",
        "    y_val = model(cat_test, con_test)\n",
        "    loss = torch.sqrt(criterion(y_val, y_test))\n",
        "print(f'RMSE: {loss:.8f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 3.58658552\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wa9wsFiZGByV"
      },
      "source": [
        "Esto quiere decir que como promedio, los valores predichos por el modelo difieren &plusmn;$3.58 del valor real.\n",
        "\n",
        "Observemos los primeros 50 valores y sus diferencias:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6swMpo0GByV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dea01f2c-5149-4fd8-8de3-bb14850ef88f"
      },
      "source": [
        "print(f'{\"PREDICTED\":>12} {\"ACTUAL\":>8} {\"DIFF\":>8}')\n",
        "for i in range(50):\n",
        "    diff = np.abs(y_val[i].item()-y_test[i].item())\n",
        "    print(f'{i+1:2}. {y_val[i].item():8.4f} {y_test[i].item():8.4f} {diff:8.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   PREDICTED   ACTUAL     DIFF\n",
            " 1.   3.3897   2.9000   0.4897\n",
            " 2.  21.4156   5.7000  15.7156\n",
            " 3.   6.8739   7.7000   0.8261\n",
            " 4.  14.0987  12.5000   1.5987\n",
            " 5.   4.9695   4.1000   0.8695\n",
            " 6.   2.9566   5.3000   2.3434\n",
            " 7.   4.9119   3.7000   1.2119\n",
            " 8.  12.5546  14.5000   1.9454\n",
            " 9.   4.2339   5.7000   1.4661\n",
            "10.  10.8443  10.1000   0.7443\n",
            "11.   3.7450   4.5000   0.7550\n",
            "12.   6.6382   6.1000   0.5382\n",
            "13.   6.3354   6.9000   0.5646\n",
            "14.   9.8351  14.1000   4.2649\n",
            "15.   6.4549   4.5000   1.9549\n",
            "16.  30.5704  34.1000   3.5296\n",
            "17.   3.6908  12.5000   8.8092\n",
            "18.   5.0881   4.1000   0.9881\n",
            "19.   8.7589   8.5000   0.2589\n",
            "20.   7.1429   5.3000   1.8429\n",
            "21.  14.3821  11.3000   3.0821\n",
            "22.  12.9264  10.5000   2.4264\n",
            "23.  16.1893  15.3000   0.8893\n",
            "24.  15.7248  14.9000   0.8248\n",
            "25.  56.2197  49.5700   6.6497\n",
            "26.   2.7321   5.3000   2.5679\n",
            "27.   6.2285   3.7000   2.5285\n",
            "28.   8.4603   6.5000   1.9603\n",
            "29.  15.0007  14.1000   0.9007\n",
            "30.   3.3144   4.9000   1.5856\n",
            "31.   5.7993   3.7000   2.0993\n",
            "32.  40.0278  38.6700   1.3578\n",
            "33.  10.9886  12.5000   1.5114\n",
            "34.  11.2400  16.5000   5.2600\n",
            "35.   5.9141   5.7000   0.2141\n",
            "36.   7.3084   8.9000   1.5916\n",
            "37.  14.6100  22.1000   7.4900\n",
            "38.   6.2303  12.1000   5.8697\n",
            "39.   5.7571  10.1000   4.3429\n",
            "40.   1.3975   3.3000   1.9025\n",
            "41.   9.2595   8.5000   0.7595\n",
            "42.   7.6639   8.1000   0.4361\n",
            "43.  10.1459  14.5000   4.3541\n",
            "44.   4.4585   4.9000   0.4415\n",
            "45.   9.2212   8.5000   0.7212\n",
            "46.  10.0519  12.1000   2.0481\n",
            "47.  25.1083  23.7000   1.4083\n",
            "48.   4.1917   3.7000   0.4917\n",
            "49.   9.7007   9.3000   0.4007\n",
            "50.   7.8999   8.1000   0.2001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hU72l49GByW"
      },
      "source": [
        "Como podemos ver, mientras algunas predicciones apenas difieren en unos céntimos, otras llegan a más de \\\\$15.00 de dferencia. Prueba a cambiar parámetros como el tamaño de lote, de test, el número de ciclos, la tasa de aprendizaje, etc. con el fin de conseguir un modelo mejor. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnWk8Vj4GByW"
      },
      "source": [
        "## Guardando el modelo the model\n",
        "Recordemos que podemos salvar un modelo entrenado como un fichero en disco de forma que podamos recuperarlo posterormente para realizar predicciones o continuar entrenandolo con más datos. \n",
        "Habitualmente lo que suele hacerse es salvar las matrices de pesos y biases y no toda la definición. Podemos encontrar más información sobre el proceso de guardado y sus recomendaciones en  <a href='https://pytorch.org/tutorials/beginner/saving_loading_models.html'>https://pytorch.org/tutorials/beginner/saving_loading_models.html</a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "BLRKEkTxGByW"
      },
      "source": [
        "# Aseguramos que lo guardao SOLO depués de haberlo entrenado!\n",
        "if len(losses) == epochs:\n",
        "    torch.save(model.state_dict(), 'TaxiFareRegrModel.pt')\n",
        "else:\n",
        "    print('Model has not been trained. Consider loading a trained model instead.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJlp6pILGByW"
      },
      "source": [
        "## Cargando el modelo (empezando de cero)\n",
        "Ahora podemos cargar el fichero con pesos y biases de nuestro modelo guardado. \n",
        "Si acabamos de iniciar el Notebook, tendremos que lanzar las funciones de importación de módulos y sobretodo, las definiciones de funciones y clases. \n",
        "\n",
        "Para ilustrar esto reinicia  el Kernel antes de continuar. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "bXr-OLYwGByX"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def haversine_distance(df, lat1, long1, lat2, long2):\n",
        "    r = 6371\n",
        "    phi1 = np.radians(df[lat1])\n",
        "    phi2 = np.radians(df[lat2])\n",
        "    delta_phi = np.radians(df[lat2]-df[lat1])\n",
        "    delta_lambda = np.radians(df[long2]-df[long1])\n",
        "    a = np.sin(delta_phi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda/2)**2\n",
        "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
        "    return r * c\n",
        "\n",
        "class TabularModel(nn.Module):\n",
        "    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n",
        "        super().__init__()\n",
        "        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
        "        self.emb_drop = nn.Dropout(p)\n",
        "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
        "        layerlist = []\n",
        "        n_emb = sum((nf for ni,nf in emb_szs))\n",
        "        n_in = n_emb + n_cont\n",
        "        for i in layers:\n",
        "            layerlist.append(nn.Linear(n_in,i)) \n",
        "            layerlist.append(nn.ReLU(inplace=True))\n",
        "            layerlist.append(nn.BatchNorm1d(i))\n",
        "            layerlist.append(nn.Dropout(p))\n",
        "            n_in = i\n",
        "        layerlist.append(nn.Linear(layers[-1],out_sz))\n",
        "        self.layers = nn.Sequential(*layerlist)\n",
        "    def forward(self, x_cat, x_cont):\n",
        "        embeddings = []\n",
        "        for i,e in enumerate(self.embeds):\n",
        "            embeddings.append(e(x_cat[:,i]))\n",
        "        x = torch.cat(embeddings, 1)\n",
        "        x = self.emb_drop(x)\n",
        "        x_cont = self.bn_cont(x_cont)\n",
        "        x = torch.cat([x, x_cont], 1)\n",
        "        return self.layers(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA4BslvHGByX"
      },
      "source": [
        "Hemos definido las importaciones, funciones y clases. Ahora, antes de cargar los valores salvados, tenemos que instanciar nuestro modelo TabularModel con los mismos parámetros que antes (tamaños de embedding, número de columnas continuas, tamaño de salida, tamaño de capas y factor de dropout). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Z6HLIOnwGByX"
      },
      "source": [
        "emb_szs = [(24, 12), (2, 1), (7, 4)]\n",
        "model2 = TabularModel(emb_szs, 6, 1, [300,100], p=0.4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkACG4oPGByX"
      },
      "source": [
        "Once the model is set up, loading the saved settings is a snap."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBnuhNPcGByY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ebc1161-e7e0-4629-a59c-9c67d800da5b"
      },
      "source": [
        "model2.load_state_dict(torch.load('/content/TaxiFareRegrModel.pt'));\n",
        "model2.eval() # No olvides realizar este paso"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TabularModel(\n",
              "  (embeds): ModuleList(\n",
              "    (0): Embedding(24, 12)\n",
              "    (1): Embedding(2, 1)\n",
              "    (2): Embedding(7, 4)\n",
              "  )\n",
              "  (emb_drop): Dropout(p=0.4, inplace=False)\n",
              "  (bn_cont): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (layers): Sequential(\n",
              "    (0): Linear(in_features=23, out_features=300, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (3): Dropout(p=0.4, inplace=False)\n",
              "    (4): Linear(in_features=300, out_features=100, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): Dropout(p=0.4, inplace=False)\n",
              "    (8): Linear(in_features=100, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcyMaXBYGByY"
      },
      "source": [
        "\r\n",
        "Ahora podemos definir una función que solicite los datos de entrada al usuario , realice todos los pasos de preprocesado definidos al principio del Notebook y los pase al modelo entrenado con el fin de obtener una predicción concreta. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "9DjDv2VoGByY"
      },
      "source": [
        "def test_data(mdl): # nombre del modelo que hemos instanciado\n",
        "    # Nuevos datos:\n",
        "    plat = float(input('Latitud de recogida: '))\n",
        "    plong = float(input('Longitud de recogida: '))\n",
        "    dlat = float(input('Latitud de entrega:  '))\n",
        "    dlong = float(input('Longitud de entrega: '))\n",
        "    psngr = int(input('Número de pasajeros '))\n",
        "    dt = input('Especifica la fecha y hora en formato YYYY-MM-DD HH:MM:SS     ')\n",
        "    \n",
        "    # Preprocesado de lso datos:\n",
        "    dfx_dict = {'pickup_latitude':plat,'pickup_longitude':plong,'dropoff_latitude':dlat,\n",
        "         'dropoff_longitude':dlong,'passenger_count':psngr,'EDTdate':dt}\n",
        "    dfx = pd.DataFrame(dfx_dict, index=[0])\n",
        "    dfx['dist_km'] = haversine_distance(dfx,'pickup_latitude', 'pickup_longitude',\n",
        "                                        'dropoff_latitude', 'dropoff_longitude')\n",
        "    dfx['EDTdate'] = pd.to_datetime(dfx['EDTdate'])\n",
        "    \n",
        "    # Recodificamos las categoricas:\n",
        "    dfx['Hour'] = dfx['EDTdate'].dt.hour\n",
        "    dfx['AMorPM'] = np.where(dfx['Hour']<12,0,1) \n",
        "    dfx['Weekday'] = dfx['EDTdate'].dt.strftime(\"%a\")\n",
        "    dfx['Weekday'] = dfx['Weekday'].replace(['Fri','Mon','Sat','Sun','Thu','Tue','Wed'],\n",
        "                                            [0,1,2,3,4,5,6]).astype('int64')\n",
        "    # Creamos y concatenamos tensores\n",
        "    cat_cols = ['Hour', 'AMorPM', 'Weekday']\n",
        "    cont_cols = ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude',\n",
        "                 'dropoff_longitude', 'passenger_count', 'dist_km']\n",
        "    xcats = np.stack([dfx[col].values for col in cat_cols], 1)\n",
        "    xcats = torch.tensor(xcats, dtype=torch.int64)\n",
        "    xconts = np.stack([dfx[col].values for col in cont_cols], 1)\n",
        "    xconts = torch.tensor(xconts, dtype=torch.float)\n",
        "    \n",
        "    # Pasamos los nuevos datos al modelo. Sin backpropagacion\n",
        "    with torch.no_grad():\n",
        "        z = mdl(xcats, xconts)\n",
        "    print(f'\\nLa cantidad resultante es ${z.item():.2f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EvAoEKYGByZ"
      },
      "source": [
        "## Introduciendo nuevos datos a través del modelo\n",
        "\n",
        "Como referencia, estos son los valores máximos y mínimos de las variables solicitadas:\n",
        "<table style=\"display: inline-block\">\n",
        "<tr><th>Column</th><th>Mínimo</th><th>Máximo</th></tr>\n",
        "<tr><td>pickup_latitude</td><td>40</td><td>41</td></tr>\n",
        "<tr><td>pickup_longitude</td><td>-74.5</td><td>-73.3</td></tr>\n",
        "<tr><td>dropoff_latitude</td><td>40</td><td>41</td></tr>\n",
        "<tr><td>dropoff_longitude</td><td>-74.5</td><td>-73.3</td></tr>\n",
        "<tr><td>passenger_count</td><td>1</td><td>5</td></tr>\n",
        "<tr><td>EDTdate</td><td>2010-04-11 00:00:00</td><td>2010-04-24 23:59:42</td></tr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RIcbndgGByZ"
      },
      "source": [
        "<strong>ATENCION!</strong> La distancia entre 1 grado de latitud (40 a 41) is 111km y en q grade de longitud (-73 a -74) is 85km. El viaje más largo en el dataset muestra una diferencia de solo 0.243 grados lat. y  0.284 de long. La iferencia media para ambos está en torno a 0.02. Para obtener una buena predicción hay que emplear valores cercanos. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wcp0_BvlGByZ"
      },
      "source": [
        "z = test_data(model2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2QOf-HEltUP"
      },
      "source": [
        "## Fin del Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZDr1zYmBkRV"
      },
      "source": [
        "Referencias y modelos empleados para el Notebook: \r\n",
        "\r\n",
        "*   Documentación de [Pytorch](https://pytorch.org/docs/stable/index.html) \r\n",
        "*   [PyTorch Tutorial for Deep Learning Researchers](https://github.com/yunjey/pytorch-tutorial) by Yunjey Choi\r\n",
        "*   [FastAI](https://www.fast.ai/) development notebooks by Jeremy Howard.\r\n",
        "*   Documentación y cursos en [Pierian Data](https://www.pieriandata.com/)\r\n",
        "*   Tutoriales y notebooks del curso \"Deep Learning with Pytorch: Zero to GANs\" de [Aakash N S](https://jovian.ai/aakashns)\r\n",
        "* [A visual proof that neural networks can compute any function](http://neuralnetworksanddeeplearning.com/chap4.html), también conocido como Teorema de Aproximación Universal\r\n",
        "* [But what *is* a neural network?](https://www.youtube.com/watch?v=aircAruvnKk) - Una introducción muy intuitiva a lo que son las redes neuronales y lo que implican las capas ocultas."
      ]
    }
  ]
}