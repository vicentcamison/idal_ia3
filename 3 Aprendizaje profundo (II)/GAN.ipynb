{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM+2aN+7WlGYJX4UyiuB3Zh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vicentcamison/idal_ia3/blob/main/3%20Aprendizaje%20profundo%20(II)/GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_zyeJVjPxzH"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2kiXnudPmyF"
      },
      "source": [
        "We are going to create a GAN to generate files that are similar to Bob Ross"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6DzjWi9Py-Y",
        "outputId": "d2616fc6-419b-45bd-8292-5f79e4364e55"
      },
      "source": [
        "# Access to the BOB ROSS images folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XE9urSNQRO2"
      },
      "source": [
        "#!ls gdrive/MyDrive/UNIVERSIDAD/Master\\ Propio\\ IA\\ UV/3\\ Aprendizaje\\ profundo\\ (II)/Datasets/Bob\\ Ross/train/images\n",
        "directory = 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Datasets/Bob Ross/train/images'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiqPg6aZkZ6Q"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "  transforms.ToTensor()\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epRJvIEal0F9"
      },
      "source": [
        "directory = \"gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Datasets/Bob Ross/train\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouR64zMJUOv9"
      },
      "source": [
        "folder = datasets.ImageFolder(root = directory, transform=transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bULShk2RnB-j",
        "outputId": "7f06448d-020b-4b5e-ff70-d663e083716f"
      },
      "source": [
        "folder"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset ImageFolder\n",
              "    Number of datapoints: 500\n",
              "    Root location: gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Datasets/Bob Ross/train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               ToTensor()\n",
              "           )"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J0nx2cWnPb6"
      },
      "source": [
        "batch_size = 20\n",
        "\n",
        "folder_loader = DataLoader(folder, batch_size=batch_size, shuffle=True, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7ZVNGgHpSYF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7QLYk12poRL"
      },
      "source": [
        "def train_val_dataset(dataset, val_split=0.25):\n",
        "  train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size=val_split, shuffle=True)\n",
        "  datasets = {}\n",
        "  datasets['train'] = Subset(dataset, train_idx)\n",
        "  datasets['val'] = Subset(dataset, val_idx)\n",
        "  return datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dccd9C5KtKIu"
      },
      "source": [
        "datasets = train_val_dataset(folder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy7DyQ5JldQo"
      },
      "source": [
        "### Small experiment to check how grad works in PyTorch tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Roc4V70eKPz"
      },
      "source": [
        "x = torch.randn(5)\n",
        "w = torch.randn(3,5).requires_grad_()\n",
        "b = torch.randn(3).requires_grad_()\n",
        "\n",
        "y = torch.randn(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CR6ZeZdfgcPo"
      },
      "source": [
        "def linear(x, w, b):\n",
        "  return x @ w.t() + b\n",
        "\n",
        "def mse(pred, real):\n",
        "  return (pred - real).pow(2).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkC82pgiggX7"
      },
      "source": [
        "result = linear(x, w, b)\n",
        "loss = mse(result, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTdbAgKZlGXU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ae5d083-636a-4ca8-fa23-f66683f7c280"
      },
      "source": [
        "loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5.4519, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaMdUEaLg7A_"
      },
      "source": [
        "loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwzSISXGg_tH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2948c403-5815-427f-b139-ca659f047d02"
      },
      "source": [
        "w.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.9431, -0.0135, -0.7908,  0.0409,  0.9231],\n",
              "        [ 1.6658, -0.0239, -1.3967,  0.0723,  1.6304],\n",
              "        [ 3.4015, -0.0488, -2.8520,  0.1475,  3.3292]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8IdSrxylWDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14f1d481-4c06-4c9d-ab2d-10e8fbc581a7"
      },
      "source": [
        "w.data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.2697, -0.6939,  0.1321, -0.1466, -0.3914],\n",
              "        [-1.2386, -1.8907, -1.8679, -1.9964,  0.7666],\n",
              "        [ 0.6081,  0.5699,  0.1135, -0.5932,  0.5787]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dcjZCNElXfy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c50e76d-5a98-409b-e66b-9456e2e0b15e"
      },
      "source": [
        "w"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.2697, -0.6939,  0.1321, -0.1466, -0.3914],\n",
              "        [-1.2386, -1.8907, -1.8679, -1.9964,  0.7666],\n",
              "        [ 0.6081,  0.5699,  0.1135, -0.5932,  0.5787]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jG8Q-kylZD0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59b2245c-91ae-44a7-a843-c7a6a75d9f03"
      },
      "source": [
        "b.data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.5760,  0.7353, -1.4715])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUo0Bn-Ala0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8d55fed-fca9-468e-9dae-871cdd398132"
      },
      "source": [
        "b.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.6515, -1.1507, -2.3496])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qrO6A0elbnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d7b82bc-a8fe-4f90-bc60-4da00e70fd68"
      },
      "source": [
        "a1 = torch.randn(1,3).requires_grad_()\n",
        "a1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TT3MuWl0soih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "573bf177-8c42-40bb-ceb3-8704528aff9e"
      },
      "source": [
        "aa1 = a1.squeeze()\n",
        "aa1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjoGU4iCsvf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4fb91b9-0472-48af-833f-5067a43e8b24"
      },
      "source": [
        "a2 = torch.randn(2,3).requires_grad_()\n",
        "a2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyBMGK7fs3x0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bb9cb3a-5426-40eb-be84-cecfca10cb6e"
      },
      "source": [
        "aa2 = a2.squeeze()\n",
        "aa2.shape #The squeeze function does nothing because there is no dimension to squeeze"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaVXHesWll3X"
      },
      "source": [
        "### Continuing with building the Bob Ross generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn78mMb5lpmN"
      },
      "source": [
        "##Right now, the generator only generates one image per execution,\n",
        "## maybe it should be readapted to generate a BATCH of images\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, noise_size, image_size):\n",
        "    super.__init__()\n",
        "\n",
        "    self.hidden_channels = 10\n",
        "    self.output_channels = 3\n",
        "    self.hidden_size = self.hidden_channels * image_size ** 2\n",
        "\n",
        "    self.linear = nn.Linear(noise_size, hidden_size)\n",
        "    self.conv1 = nn.ConvTranspose2d(self.hidden_channels, self.hidden_channels//2, (3,3))\n",
        "    self.conv2 = nn.ConvTranspose2d(self.hidden_channels//2, self.output_channels, (3,3))\n",
        "\n",
        "    self.learning_rate = 0.001\n",
        "\n",
        "    self.discriminator = None\n",
        "\n",
        "    # Optimizer\n",
        "    self.optimizer = torch.optim.Adam(self.parameters(), self.learning_rate)\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, z):\n",
        "    x = F.relu(self.linear(z))\n",
        "    z = z.view(image_size, image_size, -1)\n",
        "    z = F.relu(F.upsample_bilinear(self.conv1(self.conv1(z)))) ##THIS IS NOT GOING TO WORK. THE CHANNELS DON'T MATCH\n",
        "    z = F.relu(F.upsample_bilinear(self.conv2(self.conv2(z))))\n",
        "\n",
        "  # Set the reference to the DISCRIMINATOR that has been paired up with this generator\n",
        "  def set_discriminator(self, discr):\n",
        "    self.discriminator = discr\n",
        "\n",
        "  # LOSS FUNCTION of the generator\n",
        "  def criterion(self, z):\n",
        "    return torch.log(1-discriminator.forward(self.forward(z))).sum()/z.shape[1]\n",
        "\n",
        "  # TRAINING Of the generator\n",
        "  def gen_train(n_noise, n_epochs, batch_size, reset=False):\n",
        "\n",
        "    # generate the noise that's going to be used for training\n",
        "    Z = torch.randn(n_noise, noise_size)\n",
        "    train_gen_data = DataLoader(Z, batch_size, shuffle=True, num_workers=2) #this code is useful to generate iterables\n",
        "\n",
        "    for e in range(epochs):\n",
        "      #iterate through all batches\n",
        "      for batch in train_gen_data:\n",
        "        y = self(bacth)\n",
        "        loss = self.criterion(y)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        self.optimizer.zero_grad()\n",
        "    \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqGdW9FrjX9B"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, image_size):\n",
        "    super.__init__()\n",
        "\n",
        "    self.im_width, self.im_height, self.im_channels = image_size\n",
        "\n",
        "    self.conv1_1 = nn.Conv2d(self.im_channels, 16, (3,3))\n",
        "    self.conv1_2 = nn.Conv2d(16, 16, (3,3))\n",
        "    self.conv2_1 = nn.Conv2d(16, 32, (3,3))\n",
        "    self.conv2_2 = nn.Conv2d(32, 32, (3,3))\n",
        "    self.conv3_1 = nn.Conv2d(32, 64, (3,3))\n",
        "    self.conv3_2 = nn.Conv2d(64, 64, (3,3))\n",
        "    self.pool = nn.MaxPool2d(kernel_size=(2,2))\n",
        "\n",
        "    self.dense1 = nn.Linear(128, 32)\n",
        "    self.dense2 = nn.Linear(32, 2)\n",
        "\n",
        "    self.generator = None\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self_conv1_1(x))\n",
        "    x = F.relu(self_conv1_2(x))\n",
        "    x = F.batch_norm(self.pool(x))\n",
        "    x = F.relu(self.conv2_1(x))\n",
        "    x = F.relu(self.conv2_2(x))\n",
        "    x = F.batch_norm(self.pool(x))\n",
        "    x = F.relu(self.conv3_1(x))\n",
        "    x = F.relu(self.conv3_2(x))\n",
        "    x = F.batch_norm(self.pool(x))\n",
        "    x = nn.Flatten(x)\n",
        "    x = F.relu(self.dense1(x))\n",
        "    x = F.softmax(self.dense2(x))\n",
        "\n",
        "  #Set the reference to the GENERATOR that has been paired up with this discriminator\n",
        "  def set_generator(gen):\n",
        "    self.generator = gen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXnfa0I9FgK0"
      },
      "source": [
        "class Gen_Wrapper():\n",
        "  def __init__(self, generator):\n",
        "\n",
        "    self.generator = generator\n",
        "    self discriminator = None\n",
        "\n",
        "    # Generator loss function\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hV501H50zRc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "4eec324f-1041-4b6e-b357-ab1e87fee3b1"
      },
      "source": [
        "x = torch.randn(5, 32, 32, 3)\n",
        "m = F.avg_pool2d(kernel_size=)\n",
        "y = F.avg_pool2d(x)\n",
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b827ec35207b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: avg_pool2d() missing 1 required positional arguments: \"kernel_size\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmKSsNiM2py-"
      },
      "source": [
        "n_noise = 100\n",
        "noise_size = 3\n",
        "batch_size = 2\n",
        "\n",
        "Z = Z = torch.randn(n_noise, noise_size)\n",
        "train_gen_data = DataLoader(Z, batch_size, shuffle=True, num_workers=2)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkEBr1MC2ziS",
        "outputId": "a6631672-a607-42f8-aa8a-f3a52829ca57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for data in train_gen_data:\n",
        "  print(data)\n",
        "  print('hello')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.1432, -0.6276, -0.9969],\n",
            "        [ 0.0494, -0.6551,  1.4254]])\n",
            "hello\n",
            "tensor([[-1.0565,  0.1588, -0.2860],\n",
            "        [ 0.2134,  0.3671,  0.2513]])\n",
            "hello\n",
            "tensor([[ 2.0495, -1.4641, -0.9266],\n",
            "        [ 0.1609,  0.3143,  0.7446]])\n",
            "hello\n",
            "tensor([[ 1.5117, -1.0308, -0.6375],\n",
            "        [-0.8454, -0.3034,  1.1299]])\n",
            "hello\n",
            "tensor([[-0.3528,  0.6613, -0.0638],\n",
            "        [ 0.4955, -0.1741, -0.6801]])\n",
            "hello\n",
            "tensor([[-0.2835,  1.5443, -0.4452],\n",
            "        [-1.6577, -0.3096, -0.3955]])\n",
            "hello\n",
            "tensor([[-1.2681,  3.9732, -1.8714],\n",
            "        [-1.1014,  0.9171, -0.6988]])\n",
            "hello\n",
            "tensor([[ 0.0517,  0.3341, -1.1989],\n",
            "        [-1.0194,  0.0229, -0.8954]])\n",
            "hello\n",
            "tensor([[-0.5301,  0.1027,  1.3803],\n",
            "        [-0.0057, -0.9863, -0.1489]])\n",
            "hello\n",
            "tensor([[-1.5719, -0.5399, -0.6251],\n",
            "        [ 1.3910,  0.3542,  0.4601]])\n",
            "hello\n",
            "tensor([[ 0.5968, -0.5150,  0.2246],\n",
            "        [ 0.0505, -0.0546, -1.1739]])\n",
            "hello\n",
            "tensor([[ 1.6030, -1.1565,  0.9535],\n",
            "        [-1.2447,  0.7533,  0.4049]])\n",
            "hello\n",
            "tensor([[ 0.2255, -0.7892,  0.3410],\n",
            "        [ 0.9288, -0.2128, -0.3726]])\n",
            "hello\n",
            "tensor([[ 0.2225, -0.3241, -0.9875],\n",
            "        [ 0.6316,  1.7171,  0.6294]])\n",
            "hello\n",
            "tensor([[-1.7956, -0.0237,  0.8987],\n",
            "        [ 0.7676,  1.0487,  0.8458]])\n",
            "hello\n",
            "tensor([[-0.3853, -0.3907,  0.5871],\n",
            "        [ 1.1280,  0.9072, -0.4734]])\n",
            "hello\n",
            "tensor([[-2.2086,  0.5709,  0.0806],\n",
            "        [-0.0845, -0.2134,  0.2973]])\n",
            "hello\n",
            "tensor([[ 0.8716,  1.9820, -0.9624],\n",
            "        [ 0.5128,  0.9102, -1.1683]])\n",
            "hello\n",
            "tensor([[-0.5664, -2.0591, -0.7998],\n",
            "        [-0.1636,  1.0306, -0.2659]])\n",
            "hello\n",
            "tensor([[-0.7234, -0.2915, -0.8246],\n",
            "        [ 0.0491, -0.1797,  0.6715]])\n",
            "hello\n",
            "tensor([[ 1.0698,  0.5005, -0.7012],\n",
            "        [-1.0718, -1.2274, -1.2041]])\n",
            "hello\n",
            "tensor([[ 0.5933,  1.0586,  1.1203],\n",
            "        [-0.5865,  1.2014, -1.1148]])\n",
            "hello\n",
            "tensor([[ 0.6158,  0.2058, -1.2951],\n",
            "        [ 1.2956,  0.0425, -0.8204]])\n",
            "hello\n",
            "tensor([[ 1.8258, -0.8903,  0.7285],\n",
            "        [-1.2828, -0.7097, -0.7313]])\n",
            "hello\n",
            "tensor([[-0.8097, -0.4699,  0.7122],\n",
            "        [-0.7913,  0.2785,  0.7039]])\n",
            "hello\n",
            "tensor([[ 0.5928,  0.3305,  1.5892],\n",
            "        [-1.6341,  0.8225, -1.8357]])\n",
            "hello\n",
            "tensor([[-0.4180,  0.8801, -0.0517],\n",
            "        [-1.8352,  0.1143, -1.0431]])\n",
            "hello\n",
            "tensor([[-1.7070,  1.0364, -0.3889],\n",
            "        [ 1.2066, -0.5449,  0.3332]])\n",
            "hello\n",
            "tensor([[-0.5506,  2.3046, -0.2961],\n",
            "        [-1.2750,  0.9657,  2.5061]])\n",
            "hello\n",
            "tensor([[-0.2725,  1.2156, -1.7139],\n",
            "        [ 0.2574, -1.9086, -1.2220]])\n",
            "hello\n",
            "tensor([[-0.0580, -0.6975,  0.3001],\n",
            "        [ 1.7529, -0.6170, -0.0191]])\n",
            "hello\n",
            "tensor([[-0.9770,  0.8576,  2.3177],\n",
            "        [ 0.4004, -0.0657, -1.8371]])\n",
            "hello\n",
            "tensor([[-1.3183,  0.8439,  0.7193],\n",
            "        [-0.2073,  0.2630, -0.4261]])\n",
            "hello\n",
            "tensor([[-0.1964,  0.2280, -0.3401],\n",
            "        [-0.2176,  0.7116,  1.4930]])\n",
            "hello\n",
            "tensor([[ 0.1708,  0.9045, -0.1568],\n",
            "        [ 0.3057,  0.7319, -1.5341]])\n",
            "hello\n",
            "tensor([[-0.1565,  1.9438,  1.2820],\n",
            "        [ 1.5950,  0.1669,  1.1670]])\n",
            "hello\n",
            "tensor([[-2.1861, -1.1137, -0.1661],\n",
            "        [-0.5558,  0.5053,  0.1626]])\n",
            "hello\n",
            "tensor([[ 0.6816,  1.1891,  0.7338],\n",
            "        [-0.1870,  0.6467, -0.3501]])\n",
            "hello\n",
            "tensor([[ 1.0857, -0.4607,  0.4448],\n",
            "        [ 1.3814,  0.0750,  0.9032]])\n",
            "hello\n",
            "tensor([[-0.7642,  2.6922,  1.8112],\n",
            "        [ 0.2120,  1.7763,  0.8323]])\n",
            "hello\n",
            "tensor([[-1.9197, -2.2048,  1.1646],\n",
            "        [-0.3785, -0.1729,  0.5928]])\n",
            "hello\n",
            "tensor([[-0.3150, -1.1098, -0.3086],\n",
            "        [ 0.0837,  1.2762,  1.3838]])\n",
            "hello\n",
            "tensor([[-0.2174,  1.1899,  0.3490],\n",
            "        [ 2.3105, -0.6718,  0.5886]])\n",
            "hello\n",
            "tensor([[-0.2448,  1.1417,  0.3806],\n",
            "        [-0.5761,  0.4497, -1.1799]])\n",
            "hello\n",
            "tensor([[-0.4993, -1.4932, -0.8289],\n",
            "        [-1.2843, -0.0790,  2.3595]])\n",
            "hello\n",
            "tensor([[-1.1611,  0.5892, -0.4189],\n",
            "        [ 0.1142, -0.6975,  1.1201]])\n",
            "hello\n",
            "tensor([[ 1.1081, -1.3301,  0.0703],\n",
            "        [ 0.8208, -0.2267,  2.8191]])\n",
            "hello\n",
            "tensor([[ 1.3553, -0.6578,  0.1175],\n",
            "        [ 0.5110,  1.6492, -0.7048]])\n",
            "hello\n",
            "tensor([[-0.0907, -1.3813, -1.3387],\n",
            "        [-0.0917, -0.9338, -0.2044]])\n",
            "hello\n",
            "tensor([[-0.9249,  0.0869, -0.7299],\n",
            "        [ 1.2662,  0.2682, -0.8193]])\n",
            "hello\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}