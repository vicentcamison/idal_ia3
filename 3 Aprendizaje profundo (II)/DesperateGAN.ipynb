{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vicentcamison/idal_ia3/blob/main/3%20Aprendizaje%20profundo%20(II)/DesperateGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_zyeJVjPxzH"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, Subset, Dataset\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import glob\n",
        "\n",
        "from itertools import chain"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A7cX_TKXiNg"
      },
      "source": [
        "# CONTROL VARIABLES\n",
        "\n",
        "# GAN style\n",
        "# 0: InfoGAN\n",
        "# 1: AC-GAN (Auxiliary Conditional GAN)\n",
        "# 2: WASSERSTEIN-GAN\n",
        "GAN_STYLE = 1\n",
        "\n",
        "CATEGORIES = 10\n",
        "\n",
        "\n",
        "# lesser importance variables\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_SIZE = 64\n",
        "ORIGINAL_IMAGE_SIZE = 64\n",
        "LRELU_ALPHA = 0.2 #negative slope of leaky relu activation\n",
        "LR_G = 0.0002 #generator learning rate\n",
        "LR_D = 0.0002 #discriminator learning rate\n",
        "NOISE = True\n",
        "EPSILON = 0.15 #noise factor in images to discriminator\n",
        "EPSILON_EXPONENT = 0.5 #damping to the noise factor in images along different epochs\n",
        "GEN_PER_DISCR = 1 #times the generator is trained each time the discriminator is trained\n",
        "FLIP_LABELS = True\n",
        "DISCR_LABEL_INVERSION_FACTOR = 2 # label inversion for discriminator loss has a chance of 1 over 1/(2+epoch*DISCR_LABEL_INV_FACTOR) ** DISCR_lABEL_INVERSION_PWR\n",
        "DISCR_LABEL_INVERSION_PWR = 0.5"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2kiXnudPmyF"
      },
      "source": [
        "We are going to create a GAN to generate new fonts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6DzjWi9Py-Y",
        "outputId": "c7107f97-76c5-4c18-f6be-d79fb410bcde"
      },
      "source": [
        "# Access to the BOB ROSS images folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WHqiLelw80u",
        "outputId": "d882bfcb-2a39-463d-f301-ef492e790690"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfAkk8k97LBF"
      },
      "source": [
        "# Data load"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9VVcetR6d4L"
      },
      "source": [
        "### Original font dataset load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XE9urSNQRO2"
      },
      "source": [
        "#directory = \"gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Datasets/Bob Ross/train\"\n",
        "directory = \"gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts\""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2-COIKsvtCk"
      },
      "source": [
        "# get data file names (this code takes a while to retrieve all data and prepare all dataframes)\n",
        "filenames = glob.glob(directory + \"/*.csv\")\n",
        "dfs = [pd.read_csv(filename) for filename in filenames]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEyJO1YjD0Lz",
        "outputId": "237b3455-2263-4a0d-dffc-50c122f52a29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "filenames"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/BITSTREAMVERA.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/VIN.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/MONEY.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/NUMERICS.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/CREDITCARD.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/HANDPRINT.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/TIMES.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/PERPETUA.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/PALATINO.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/IMPRINT.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/CENTAUR.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/STENCIL.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/QUICKTYPE.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/HAETTENSCHWEILER.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/GLOUCESTER.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/BLACKADDER.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/VINER.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/PRISTINA.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/PANROMAN.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/MAIANDRA.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/KRISTEN.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/GILL.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/CASTELLAR.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/CAARD.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/BODONI.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/BERLIN.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/TW.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/TEMPUS.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/STYLUS.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/SHOWCARD.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/SANSSERIF.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/PMINGLIU-EXTB.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/MONOTXT.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/INFORMAL.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/CORBEL.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/BELL.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/AGENCY.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/WIDE.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/VIVALDI.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/GIGI.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/SUPERFRENCH.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/SKETCHFLOW.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/MV_BOLI.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/REFERENCE.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/MISTRAL.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/COUNTRYBLUEPRINT.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/OCRA.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/VERDANA.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/TREBUCHET.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/TECHNIC.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/NIRMALA.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/NIAGARA.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/MONOSPAC821.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/MATURA.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/IMPACT.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/GOTHICE.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/GEORGIA.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/FOOTLIGHT.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/ELEPHANT.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/COURIER.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/CONSOLAS.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/CANDARA.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/OCRB.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/BRADLEY.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/BAUHAUS.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/SEGOE.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/TAI.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/FORTE.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/BRUSH.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/BRITANNIC.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/BASKERVILLE.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/ROMAN.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/MONOTYPE.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/MINGLIU.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/SERIF.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/COMMERCIALSCRIPT.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/COMIC.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/CALIFORNIAN.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/CALIBRI.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/SIMPLEX.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/PLAYBILL.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/LEELAWADEE.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/JAVANESE.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/FRENCH.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/FRANKLIN.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/EUROROMAN.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/COOPER.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/COMPLEX.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/BOOK.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/BANKGOTHIC.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/VINETA.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/TAHOMA.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/SNAP.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/PROXY.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/PALACE.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/ENGLISH.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/HARRINGTON.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/GARAMOND.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/EBRIMA.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/CURLZ.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/CITYBLUEPRINT.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/CHILLER.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/BOOKMAN.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/SCRIPTB.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/PAPYRUS.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/YI BAITI.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/GUNPLAY.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/FREESTYLE.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/CONSTANTIA.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/BROADWAY.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/TXT.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/MYANMAR.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/BAITI.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/PHAGSPA.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/MAGNETO.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/LUCIDA.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/HARLOW.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/GABRIOLA.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/FELIX TITLING.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/CALISTO.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/E13B.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/SCRIPT.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/RICHARD.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/JUICE.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/GOUDY.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/GADUGI.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/CENTURY.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/VLADIMIR.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/ROMANTIC.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/RAVIE.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/JOKERMAN.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/ERAS.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/ENGRAVERS.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/BUXTON.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/SYLFAEN.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/SWIS721.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/RAGE.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/ONYX.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/KUNSTLER.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/ISOC.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/DUTCH801.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/BERNARD.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/SITKA.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/ROCKWELL.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/NINA.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/MODERN.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/HIMALAYA.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/ITALIC.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/HIGH TOWER.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/EDWARDIAN.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/COPPERPLATE.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/CAMBRIA.csv',\n",
              " 'gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts/ARIAL.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHz6XvH8Vd8c"
      },
      "source": [
        "# Characters have an index associated to them (m_label). The index is related to the character in the following dictionary\n",
        "index_to_char = {65:'A', 66:'B', 67:'C', 68:'D', 69:'E', 70:'F', 71:'G', 72:'H', 73:'I', 74:'J',\n",
        "                 75:'K', 76:'L', 77:'M', 78:'N', 79:'O', 80:'P', 81:'Q', 82:'R', 83:'S', 84:'T',\n",
        "                 85:'U', 86:'V', 87:'W', 88:'X', 89:'Y', 90:'Z', 97:'a', 98:'b', 99:'c', 100:'d',\n",
        "                 101:'e', 102:'f', 103:'g', 104:'h', 105:'i', 106:'j', 107:'k', 108:'l', 109:'m',\n",
        "                 110:'n', 111:'o', 112:'p', 113:'q', 114:'r', 115:'s', 116:'t', 117:'u', 118:'v',\n",
        "                 119:'w', 120:'x', 121:'y', 122:'z', 48:'0', 49:'1', 50:'2', 51:'3', 52:'4', 53:'5',\n",
        "                 54:'6', 55:'7', 56:'8', 57:'9'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USLE1ztGoADb"
      },
      "source": [
        "# Just number 2\n",
        "#number_min = 50\n",
        "#number_max = 50\n",
        "# From 0 to 9\n",
        "number_min = 48\n",
        "number_max = 57\n",
        "\n",
        "upper_min = 65\n",
        "upper_max = 90\n",
        "lower_min = 97\n",
        "lower_max = 122"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAVfnqrzfmxJ",
        "outputId": "e6408e6f-059a-48cc-814f-b6b106b6cad3"
      },
      "source": [
        "# We create the datasets. We are going to divide them in NUMBERS, UPPERCASE LETTERS and LOWERCASE LETTERS\n",
        "X_numbers = np.array([], ndmin=3)\n",
        "X_upper = np.array([], ndmin=3)\n",
        "X_lower = np.array([], ndmin=3)\n",
        "Y_numbers = np.array([], ndmin=2)\n",
        "Y_upper = np.array([], ndmin=2)\n",
        "Y_lower = np.array([], ndmin=2)\n",
        "\n",
        "i = 0\n",
        "for df in dfs:\n",
        "  #df = df[np.logical_and(df.loc[:,'strength'] < 0.5, df.loc[:,'italic'] == 0]\n",
        "  df_straight = df[np.logical_and(df.loc[:,'strength'] >= 0.5, df.loc[:,'italic'] == 0)] #remove the columns that are in bold or cursive\n",
        "  #BY SLIGHTLY MODIFYING THIS LINE OF CODE AND ADDING THE CORRESPONDING LABELS TO Y, CURSIVE AND BOLD CAN BE ADDED TO THE MODEL\n",
        "\n",
        "  # We get the elements of the dataframe that reference the images of characters (upper and lower letters, and numbers)\n",
        "  X_numbers_new = df_straight[np.logical_and(df_straight.loc[:,'m_label'] >= number_min, df_straight.loc[:, 'm_label'] <= number_max)].iloc[:, 12:]\n",
        "  X_upper_new = df_straight[np.logical_and(df_straight.loc[:,'m_label'] >= upper_min, df_straight.loc[:, 'm_label'] <= upper_max)].iloc[:, 12:]\n",
        "  X_lower_new = df_straight[np.logical_and(df_straight.loc[:,'m_label'] >= lower_min, df_straight.loc[:, 'm_label'] <= lower_max)].iloc[:, 12:]\n",
        "\n",
        "  Y_numbers_new = df_straight[np.logical_and(df_straight.loc[:,'m_label'] >= number_min, df_straight.loc[:, 'm_label'] <= number_max)].loc[:, ['m_label', 'font']]\n",
        "  Y_upper_new = df_straight[np.logical_and(df_straight.loc[:,'m_label'] >= upper_min, df_straight.loc[:, 'm_label'] <= upper_max)].loc[:, ['m_label', 'font']]\n",
        "  Y_lower_new = df_straight[np.logical_and(df_straight.loc[:,'m_label'] >= lower_min, df_straight.loc[:, 'm_label'] <= lower_max)].loc[:, ['m_label', 'font']]\n",
        "\n",
        "  # We transform each element from a 400x1 array into a 20x20 array\n",
        "  #X_numbers_new = np.reshape(X_numbers_new.values, (20,20,-1))\n",
        "  #X_upper_new = np.reshape(X_upper_new.values, (20,20,-1))\n",
        "  #X_lower_new = np.reshape(X_lower_new.values, (20,20,-1))\n",
        "\n",
        "  # We rearrange the indexes so that the first index refers to image index\n",
        "  #X_numbers_new = np.transpose(X_numbers_new, axes=[2, 0, 1])\n",
        "  #X_upper_new = np.transpose(X_upper_new, axes=[2, 0, 1])\n",
        "  #X_lower_new = np.transpose(X_lower_new, axes=[2, 0, 1])\n",
        "\n",
        "  X_numbers_new = np.array(np.reshape(X_numbers_new.values, (-1,20,20)))\n",
        "  X_upper_new = np.array(np.reshape(X_upper_new.values, (-1,20,20)))\n",
        "  X_lower_new = np.array(np.reshape(X_lower_new.values, (-1,20,20)))\n",
        "\n",
        "  X_numbers_new = X_numbers_new.astype('float64')\n",
        "  X_upper_new = X_upper_new.astype('float64')\n",
        "  X_lower_new = X_lower_new.astype('float64')\n",
        "\n",
        "  Y_numbers_new.iloc[:, 0] = Y_numbers_new.iloc[:, 0].astype('int')\n",
        "  Y_upper_new.iloc[:, 0] = Y_upper_new.iloc[:, 0].astype('int')\n",
        "  Y_lower_new.iloc[:, 0] = Y_lower_new.iloc[:, 0].astype('int')\n",
        "\n",
        "  # We append the _new vectors to the standard vectors\n",
        "  if i == 0: # IS THERE A WAY TO PROGRAM THIS BETTER?\n",
        "    X_numbers = X_numbers_new\n",
        "    X_upper = X_upper_new\n",
        "    X_lower = X_lower_new\n",
        "\n",
        "    Y_numbers = Y_numbers_new\n",
        "    Y_upper = Y_upper_new\n",
        "    Y_lower = Y_lower_new\n",
        "\n",
        "  else:\n",
        "    X_numbers = np.concatenate((X_numbers, X_numbers_new), axis=0)\n",
        "    X_upper = np.concatenate((X_upper, X_upper_new), axis=0)\n",
        "    X_lower = np.concatenate((X_lower, X_lower_new), axis=0)\n",
        "\n",
        "    Y_numbers = pd.concat([Y_numbers, Y_numbers_new], axis=0)\n",
        "    Y_upper = pd.concat([Y_upper, Y_upper_new], axis=0)\n",
        "    Y_lower = pd.concat([Y_lower, Y_lower_new], axis=0)\n",
        "\n",
        "    #Y_numbers = np.concatenate((Y_numbers, np.array(Y_numbers_new)), axis=0)\n",
        "    #Y_upper = np.concatenate((Y_upper, np.array(Y_upper_new)), axis=0)\n",
        "    #Y_lower = np.concatenate((Y_lower, np.array(Y_lower_new)), axis=0)\n",
        "\n",
        "    \n",
        "  #X_numbers.append(X_numbers_new)\n",
        "  #X_upper.append(X_upper_new)\n",
        "  #X_lower.append(X_lower)\n",
        "\n",
        "  #Y_numbers.append(Y_numbers_new)\n",
        "  #Y_upper.append(Y_upper_new)\n",
        "  #Y_lower.append(Y_lower_new)\n",
        "  \n",
        "  i += 1\n",
        "  if i % 10 == 0 or i==len(dfs):\n",
        "    print(str(i)+'/'+str(len(dfs)))\n",
        "\n",
        "  #for row in df[np.logical_and(df.loc[:,'strength'] < 0.5, df.loc[:,'italic'] == 0].iterrows():\n",
        "   # if row.strength < 0.5 and row.italic == 0:\n",
        "\n",
        "#Y_numbers.reset_index(inplace=True)\n",
        "#Y_lower.reset_index(inplace=True)\n",
        "#Y_upper.reset_index(inplace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/153\n",
            "20/153\n",
            "30/153\n",
            "40/153\n",
            "50/153\n",
            "60/153\n",
            "70/153\n",
            "80/153\n",
            "90/153\n",
            "100/153\n",
            "110/153\n",
            "120/153\n",
            "130/153\n",
            "140/153\n",
            "150/153\n",
            "153/153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0v-rzCiIdUZ",
        "outputId": "33a5eb89-e6e8-4107-deab-8c7bcb2a5120",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "a = pd.DataFrame()\n",
        "type(a)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LxQhTpj0zh9"
      },
      "source": [
        "# Generation of the transform for the DataLoader\n",
        "transform = transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Pad((IMAGE_SIZE-ORIGINAL_IMAGE_SIZE)//2,fill=0),\n",
        "  transforms.Normalize(0.5, 0.5)\n",
        "  #ToTanh()\n",
        "])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux0fsk9-7uDw"
      },
      "source": [
        "#We modify the dataset class to fit our needs: deliver an image and a label per example\n",
        "class FontsDataset(Dataset):\n",
        "\n",
        "    def __init__(self, X_images, Y_labels, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            X_images (np.array): np.array containing all the font images\n",
        "            Y_labels (np.array): np.array containing all the font labels\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.X_images = X_images\n",
        "        #self.X_images.type(torch.FloatTensor)\n",
        "        #for now, we only want to keep the column that indicates the character\n",
        "        if type(Y_labels) == pd.core.frame.DataFrame:\n",
        "          self.Y_labels = Y_labels.iloc[:,0]\n",
        "        else:\n",
        "          self.Y_labels = Y_labels\n",
        "        #we also apply one-hot encoding to the labels.\n",
        "        #USE EMBEDDING FOR BIGGER COLLECTIONS OF CHARACTERS\n",
        "        #self.Y_labels = np.array(pd.get_dummies(Y_labels.astype('str')))\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.Y_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        #img_name = os.path.join(self.root_dir,\n",
        "        #                        self.landmarks_frame.iloc[idx, 0])\n",
        "        #image = io.imread(img_name)\n",
        "        #landmarks = self.landmarks_frame.iloc[idx, 1:]\n",
        "        #landmarks = np.array([landmarks])\n",
        "        #landmarks = landmarks.astype('float').reshape(-1, 2)\n",
        "        #sample = {'image': image, 'landmarks': landmarks}\n",
        "\n",
        "        image = self.X_images[idx]\n",
        "        label = self.Y_labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            image.type(torch.FloatTensor)\n",
        "\n",
        "        return image, label"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTCDrE6y2DmZ"
      },
      "source": [
        "# We want the label to go from 0 to label_max. In order to do that,\n",
        "# the following operation needs to be performed:\n",
        "\n",
        "Y_numbers.iloc[:, 0] = Y_numbers.iloc[:, 0] - number_min\n",
        "Y_upper.iloc[:, 0] = Y_upper.iloc[:, 0] - upper_min\n",
        "Y_lower.iloc[:, 0] = Y_lower.iloc[:, 0] - lower_min\n",
        "\n",
        "Y_numbers.reset_index(drop=True, inplace=True)\n",
        "Y_upper.reset_index(drop=True, inplace=True)\n",
        "Y_lower.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbu6Nata_UTw"
      },
      "source": [
        "numbers_dataset = FontsDataset(X_numbers, Y_numbers, transform)\n",
        "upper_dataset = FontsDataset(X_upper, Y_upper, transform)\n",
        "lower_dataset = FontsDataset(X_lower, Y_lower, transform)\n",
        "\n",
        "numbers_loader = DataLoader(numbers_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "upper_loader = DataLoader(upper_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "lower_loader = DataLoader(lower_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2ZGqnuC-kFt",
        "outputId": "48f4c98e-d8f4-4fdb-eac3-ff31ad526d4d"
      },
      "source": [
        "Y_numbers.loc[:,'font'].value_counts().sort_values(ascending=False).head(50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SWIS721        120\n",
              "SEGOE          110\n",
              "PROXY           90\n",
              "LUCIDA          80\n",
              "ISOC            70\n",
              "FRANKLIN        60\n",
              "SITKA           60\n",
              "GILL            50\n",
              "BODONI          40\n",
              "ROMAN           40\n",
              "OCRB            40\n",
              "ARIAL           40\n",
              "OCRA            40\n",
              "ERAS            40\n",
              "TW              30\n",
              "ROCKWELL        30\n",
              "ITALIC          30\n",
              "CENTURY         30\n",
              "QUICKTYPE       30\n",
              "TECHNIC         30\n",
              "LEELAWADEE      20\n",
              "COPPERPLATE     20\n",
              "PERPETUA        20\n",
              "CAARD           20\n",
              "SCRIPT          20\n",
              "MINGLIU         20\n",
              "NIRMALA         20\n",
              "CALIBRI         20\n",
              "TAI             20\n",
              "GOUDY           20\n",
              "BERLIN          20\n",
              "NIAGARA         20\n",
              "BANKGOTHIC      20\n",
              "DUTCH801        20\n",
              "VINER           10\n",
              "PLAYBILL        10\n",
              "SNAP            10\n",
              "MATURA          10\n",
              "KUNSTLER        10\n",
              "BOOKMAN         10\n",
              "SKETCHFLOW      10\n",
              "CALIFORNIAN     10\n",
              "BAUHAUS         10\n",
              "ENGRAVERS       10\n",
              "VINETA          10\n",
              "ROMANTIC        10\n",
              "BRADLEY         10\n",
              "RICHARD         10\n",
              "SANSSERIF       10\n",
              "HIMALAYA        10\n",
              "Name: font, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEnksy8MVUjN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "f8577fa6-1887-4a29-c70d-56baab3cfb37"
      },
      "source": [
        "plt.imshow(next(iter(numbers_loader))[0][0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f4b7007cf90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONyJ098oUtTy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "68db3c5f-95a6-4e32-c7a2-b5903718e7a6"
      },
      "source": [
        "plt.imshow(numbers_dataset.X_images[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f4b70073550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD4CAYAAADl7fPiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAASSUlEQVR4nO3df7DVdZ3H8efLyy8FVMgFBElJiV3LBVsC28wwk0XWiX64BtsUtdY1N2Zttsbcdleddnam2mmtxFIq0rZQq41iJ1Zl2N1RR0PRBRXF+LEUXAhUSsQfyI/3/nG/NPdzOUc+93zPuefc6+sxw5zvj/f5fj9f7vDi++Nzvx9FBGZmhx3T7AaYWWtxKJhZwqFgZgmHgpklHApmlhjQ7AZUMkiDYwhDm92MbBoyOKtu//D8v+5Dww9l154x9Ons2r2HBmXX9sTwY/Zl1w5WW3btlleGZdc+v/fY/DbsPphVp5fyj6svPcl7mRd4Jfap0rqWDIUhDGW6Lmh2M7K1nTEpq27HjNdlb/PlGc9n1/542k3Ztfe/NCG7tifeeezm7NoJA/P/oX/s1+/Irr333jdn156xZE9WnZ7clL3NQy+/nF3bbKtiZdV1vnwws0SpUJA0S9JTkjZKurrC+sGS7ijWr5J0Wpn9mVnj1RwKktqAG4GLgDOBeZLO7FZ2GfDbiDgDuB74Uq37M7PeUeZMYRqwMSI2R8QrwO3AnG41c4Bbi+kfAxdIqnhzw8xaQ5lQGAds7TK/rVhWsSYiDgDPARXvtklql7Ra0ur95N/xNbP6apkbjRGxKCKmRsTUgeQ94jOz+isTCh3A+C7zpxTLKtZIGgCcADxbYp9m1mBlQuEhYKKkCZIGAXOBZd1qlgHzi+lLgP+KvtTDw+w1qObOSxFxQNIC4C6gDVgcEeskfQFYHRHLgO8A/yZpI7CbzuAwsxamVvyP+3iNjEb0aBxw8pjs2ieueX127aqLr8+qG9WW33V7zb78m62f++DHs2t58LH82h44dO6U7NpJ1z+ZXbtw3KpamlM3F//youza/VedlL/hBv0ccq2KleyJ3RWfBLbMjUYzaw0OBTNLOBTMLOFQMLOEQ8HMEg4FM0s4FMws4VAws4RDwcwSDgUzS/T5bs7Pf/Cc7O1+5p+WZNd+YFjeiz0b5ZyrPplde8L3f9HAltTf3r+Ynl37P1/9RnbtwB68JboRNu3fm1174X98Jrt24oL6d/V2N2czy+ZQMLOEQ8HMEg4FM0s4FMws4VAws4RDwcwSZUaIGi/pvyU9IWmdpCsr1MyQ9JykNcWfa8o118warcyo0weAz0TEI5KGAw9LWhERT3SruzciLi6xHzPrRTWfKUTEjoh4pJh+HniSI0eIMrM+psyZwu8Vo0mfDVTqj/k2SWuB7cBnI2JdlW20A+0AgwefwKHpZ2ft+6PXdR9qorpmd13uiaE79je7CQ0z7Ef53Xb/cE7+m6o3veu7tTSnbk4fOCy79uE5eW8AB5ix4bPZtWO+dn92bTWlQ0HSMODfgU9HRPd/dY8Ap0bEXkmzgZ8CEyttJyIWAYsAjh8+rvV+IcPsNaLU0wdJA+kMhB9ExE+6r4+IPRGxt5heDgyU1IOX45tZbyvz9EF0jgD1ZET8a5WaMYeHnpc0rdifx5I0a2FlLh/eDnwYeEzSmmLZ54HXA0TETXSOH3mFpAPAS8BcjyVp1trKjCV5H1Dx97G71CwEFta6DzPrfe7RaGYJh4KZJRwKZpZwKJhZwqFgZom6dHOut30jxca/HJhV237C9ga3xprpuEePza595p0vZNee1Da0lubUzYi247Jrb7gy/43W12z4RFZd3PdA1XU+UzCzhEPBzBIOBTNLOBTMLOFQMLOEQ8HMEg4FM0s4FMws4VAws0RL9mg868RneHDOomY3w1rA2C/nv4h07eXHZ9decOzBWprTFOcNya999hN5vToPrD9UdZ3PFMws4VAws0TpUJC0RdJjxbBwqyusl6SvS9oo6VFJbym7TzNrnHrdUzg/Ip6psu4iOsd6mAhMB75ZfJpZC+qNy4c5wPei0y+AEyWd3Av7NbMa1CMUArhb0sPF0G/djQO2dpnfRoUxJyW1S1otafXTz/adO8Nm/U09Lh/OjYgOSaOAFZLWR8Q9Pd1I12Hjpk4e4rEhzJqk9JlCRHQUn7uApcC0biUdwPgu86cUy8ysBZUdS3KopOGHp4GZwOPdypYBHymeQpwDPBcRO8rs18wap+zlw2hgaTFc5ABgSUTcKemT8Puh45YDs4GNwIvAx0ru08waqFQoRMRmYHKF5Td1mQ7gU2X2Y2Z5Hpu+JKtu2tDdVde5R6OZJRwKZpZwKJhZwqFgZgmHgpklHApmlnAomFnCoWBmCYeCmSUcCmaWaMm3ORtsf8fg7NrXr2xgQ+w1x2cKZpZwKJhZwqFgZgmHgpklHApmlnAomFnCoWBmiZpDQdKkYqi4w3/2SPp0t5oZkp7rUnNN+SabWSPV3HkpIp4CpgBIaqPzte1LK5TeGxEX17ofM+td9bp8uADYFBG/qtP2zKxJ6tXNeS5wW5V1b5O0FtgOfDYi1lUqKoacawcYOHwEk7/011k7Xvu5b/S8tX3Awg/fnF375evOamBL7LWmHkPRDwLeA/yowupHgFMjYjJwA/DTatuJiEURMTUiprYdO7Rss8ysRvW4fLgIeCQidnZfERF7ImJvMb0cGCjppDrs08wapB6hMI8qlw6SxqgYPkrStGJ/z9Zhn2bWIKXuKRTjR14IXN5lWdch4y4BrpB0AHgJmFuMGGVmLarssHEvAK/rtqzrkHELgYVl9mFmvcs9Gs0s4VAws4RDwcwSDgUzSzgUzCzRkm9zHvTcAcb95xF9oSp603kfyt7uI+fckl07WAOzaxvhrEF7smt/8+k/za4d89X7a2mOvYb4TMHMEg4FM0s4FMws4VAws4RDwcwSDgUzSzgUzCzhUDCzhEPBzBIOBTNLtGQ359i3j4O/3JRVe8oH8rd74V2XZtfec1alISx6z6i2/JfX3vw3N2TXfmTUguzaCZ9/ILu2UfbPnJpdO7atJ124j+t5Y/qASYuvyKrb+sz1Vdf5TMHMElmhIGmxpF2SHu+ybKSkFZI2FJ8jqnx3flGzQdL8ejXczBoj90zhFmBWt2VXAysjYiKwsphPSBoJXAtMB6YB11YLDzNrDVmhEBH3ALu7LZ4D3FpM3wq8t8JX/wxYERG7I+K3wAqODBczayFl7imMjogdxfRvgNEVasYBW7vMbyuWmVmLqsuNxmIsh1LjOUhql7Ra0ur97KtHs8ysBmVCYaekkwGKz10VajqA8V3mTymWHaHrWJIDGVyiWWZWRplQWAYcfpowH/hZhZq7gJmSRhQ3GGcWy8ysReU+krwNeACYJGmbpMuALwIXStoAvLuYR9JUSd8GiIjdwD8BDxV/vlAsM7MWldWjMSLmVVl1QYXa1cDHu8wvBhbX1Doz63Ut2c25UY77861HLyrMft3M7Not7Wdk1Y2bkb//f37DT7Jrj1F2Kd+bmz+05/r3n5y/4R740u2XZNeeN/t/s2v/aFD/7Lr8zMEXsmtHrsu737/95err3M3ZzBIOBTNLOBTMLOFQMLOEQ8HMEg4FM0s4FMws4VAws4RDwcwSDgUzS6jzVQit5XiNjOk64tcq7DVo4/fPzq7d9K7vNrAl9fXioVeyayd//8rs2jdcnfcG7lWxkj2xu2IHeZ8pmFnCoWBmCYeCmSUcCmaWcCiYWcKhYGYJh4KZJY4aClXGkfwXSeslPSppqaQTq3x3i6THJK2RtLqeDTezxsg5U7iFI4d6WwG8OSL+GPgl8Hev8v3zI2JKROSPKW5mTXPUUKg0jmRE3B0RB4rZX9A5yIuZ9QP1eJvzXwF3VFkXwN2SArg5IhZV24ikdqAdYAj986281umVWW/Nrv3h22/swZYH9bwxTfJ/Bw5m1+Z2Xa6XUqEg6e+BA8APqpScGxEdkkYBKyStL848jlAExiLo/N2HMu0ys9rV/PRB0keBi4EPRZXfqoqIjuJzF7AUmFbr/sysd9QUCpJmAVcB74mIF6vUDJU0/PA0neNIPl6p1sxaR84jyUrjSC4EhtN5SbBG0k1F7VhJy4uvjgbuk7QWeBD4eUTc2ZCjMLO6Oeo9hSrjSH6nSu12YHYxvRmYXKp1Ztbr3KPRzBIOBTNLOBTMLOFQMLOEQ8HMEvXo5mzGgDGjs2tvuPmr2bVvHDi0luY0xeXb3pZd++v2CT3Y8hM9b0wJPlMws4RDwcwSDgUzSzgUzCzhUDCzhEPBzBIOBTNLOBTMLOFQMLOEezRaVQNOHZ9dO+K257Nr+1IvxUs3X5Bd+7ur8l9qrjVra2lOr/CZgpklHApmlqh12LjrJHUU72dcI2l2le/OkvSUpI2Srq5nw82sMWodNg7g+mI4uCkRsbz7SkltwI3ARcCZwDxJZ5ZprJk1Xk3DxmWaBmyMiM0R8QpwOzCnhu2YWS8qc09hQTHq9GJJIyqsHwds7TK/rVhWkaR2Saslrd7PvhLNMrMyag2FbwKnA1OAHcBXyjYkIhZFxNSImDqQwWU3Z2Y1qikUImJnRByMiEPAt6g8HFwH0PVB9ynFMjNrYbUOG3dyl9n3UXk4uIeAiZImSBoEzAWW1bI/M+s9R+3RWAwbNwM4SdI24FpghqQpdA41vwW4vKgdC3w7ImZHxAFJC4C7gDZgcUSsa8hRmFndqMqA0U11vEbGdOV3L7V8v52f/3LRL/zj4uzaWcc1/+bwg/v2Z9d+4mtXZtWNXbQme5uHXqw41nJLWhUr2RO7VWmdezSaWcKhYGYJh4KZJRwKZpZwKJhZwqFgZgmHgpklHApmlnAomFnCoWBmCb/NuUXp7Ddl1w77+s7s2uVvuDG7tk2N+T/jpy8My679/Nr3ZteedkX+38OYp+/PqjuUvcX+w2cKZpZwKJhZwqFgZgmHgpklHApmlnAomFnCoWBmiZx3NC4GLgZ2RcSbi2V3AJOKkhOB30XElArf3QI8DxwEDkTE1Dq128waJKfz0i3AQuB7hxdExAcPT0v6CvDcq3z//Ih4ptYGmlnvOmooRMQ9kk6rtE6SgEuBd9W3WWbWLGW7Ob8D2BkRG6qsD+BuSQHcHBGLqm1IUjvQDjCE40o2qzz9SX43453TT8iqG33Jr7K3+fXTq/5VHeGNA4dm1/7DrsnZtUsefWt27ai7B2XXnrDkoeza8YcqDSlS2cHsSns1ZUNhHnDbq6w/NyI6JI0CVkhaXwxYe4QiMBZB5yveS7bLzGpU89MHSQOA9wN3VKuJiI7icxewlMrDy5lZCynzSPLdwPqI2FZppaShkoYfngZmUnl4OTNrIUcNhWLYuAeASZK2SbqsWDWXbpcOksZKWl7Mjgbuk7QWeBD4eUTcWb+mm1kj5Dx9mFdl+UcrLNsOzC6mNwP5d7XMrCW4R6OZJRwKZpZwKJhZwqFgZgmHgpklFNF6nQeHjB0fp338b7NqR7+zI3u788c/kF17W0d+P6sN20Zl1+Ya/6P8zqbHdryQXXvMpq3ZtQf37Mmutb5lVaxkT+xWpXU+UzCzhEPBzBIOBTNLOBTMLOFQMLOEQ8HMEg4FM0s4FMws4VAws4RDwcwSLdnNWdLTQPdXH58E9MfxI/rrcUH/Pbb+cFynRsQfVFrRkqFQiaTV/XGEqf56XNB/j62/Htdhvnwws4RDwcwSfSkU8odM6lv663FB/z22/npcQB+6p2BmvaMvnSmYWS9wKJhZok+EgqRZkp6StFHS1c1uT71I2iLpMUlrJK1udnvKkLRY0i5Jj3dZNlLSCkkbis8RzWxjLaoc13WSOoqf2xpJs5vZxnpr+VCQ1AbcCFwEnAnMk3Rmc1tVV+dHxJR+8Nz7FmBWt2VXAysjYiKwspjva27hyOMCuL74uU2JiOUV1vdZLR8KdI5UvTEiNkfEK8DtwJwmt8m6iYh7gN3dFs8Bbi2mbwXe26uNqoMqx9Wv9YVQGAd0fQXxtmJZfxDA3ZIeltTe7MY0wOiI2FFM/4bOQYf7iwWSHi0uL/rcZdGr6Quh0J+dGxFvofPS6FOSzmt2gxolOp9995fn398ETgemADuArzS3OfXVF0KhAxjfZf6UYlmfFxEdxecuYCmdl0r9yU5JJwMUn7ua3J66iIidEXEwIg4B36Kf/dz6Qig8BEyUNEHSIGAusKzJbSpN0lBJww9PAzOBx1/9W33OMmB+MT0f+FkT21I3h4Ou8D762c8tfxiiJomIA5IWAHcBbcDiiFjX5GbVw2hgqSTo/DksiYg7m9uk2km6DZgBnCRpG3At8EXgh5Iuo/NX4S9tXgtrU+W4ZkiaQufl0Bbg8qY1sAHczdnMEn3h8sHMepFDwcwSDgUzSzgUzCzhUDCzhEPBzBIOBTNL/D8aVeHS9VNS4AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcyWjTjCwewt",
        "outputId": "be0bfcda-6a38-4778-88f0-68b7c3c0e321"
      },
      "source": [
        "amount_per_font = 10\r\n",
        "indexes = Y_numbers.groupby('font').head(1).index\r\n",
        "indexes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([   0,   10,   30,   40,   50,   60,   70,  100,  110,  120,\n",
              "            ...\n",
              "            2290, 2320, 2330, 2340, 2350, 2380, 2390, 2400, 2420, 2430],\n",
              "           dtype='int64', length=147)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppLXRyPq8oxQ"
      },
      "source": [
        "i=0\r\n",
        "for i in range(len(indexes)):\r\n",
        "  print(Y_numbers.loc[indexes[i], 'font'])\r\n",
        "  plt.figure(figsize=(6,6))\r\n",
        "  j=0\r\n",
        "  for j in range(amount_per_font):\r\n",
        "    plt.subplot(1,amount_per_font,j+1)\r\n",
        "    plt.imshow(X_numbers[indexes[i]+j])\r\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "og_7jmTAAZl5",
        "outputId": "d16b2ab1-f9e8-487e-f553-312d96548404"
      },
      "source": [
        "numbers_dataset.Y_labels.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 8, 7, 6, 5, 4, 3, 2, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdvlpigF7RNK"
      },
      "source": [
        "### Font 2 load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLSOK5GD7Ulx"
      },
      "source": [
        "directory2 = \"gdrive/MyDrive/UNIVERSIDAD/Master Propio IA UV/3 Aprendizaje profundo (II)/Trabajo final/fonts2\""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eICAclDuDpqI",
        "outputId": "78226b72-2ddf-427c-f76c-5eb4e7c72261",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "filenames"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fKvrTLr838b"
      },
      "source": [
        "# get data file names (this code takes a while to retrieve all data and prepare all fonts)\n",
        "images_total = 1200\n",
        "\n",
        "filenames = glob.glob(directory2 + \"/*.png\")\n",
        "images = [np.array(Image.open(filenames[i])) for i in range(len(filenames)) if i < images_total]"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7LfahvgGWkz",
        "outputId": "3a8a169f-a96a-4e59-eed8-05428febd61c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(images)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUUFRl0k-W8w"
      },
      "source": [
        "# each image is just letters A-Z from the same font concatenated in 1664x64 format: each letter is 64x64\n",
        "# we need to split the data into individual pictures for each letter\n",
        "letter_size = 64\n",
        "letter_amount = 26\n",
        "using_amount = CATEGORIES\n",
        "\n",
        "letters = np.zeros(shape=(using_amount*len(images), letter_size, letter_size, 1))\n",
        "letters_label = np.zeros(shape=(using_amount*len(images), using_amount))\n",
        "for i in range(len(images)):\n",
        "  images[i] = 255-images[i]\n",
        "  j = 0\n",
        "  for j in range(using_amount):\n",
        "    letters[i*using_amount + j, :, :, 0] = images[i][:, j*letter_size : (j+1)*letter_size] #we will only use one of the channels\n",
        "    letters_label[i*using_amount + j] = j\n",
        "letters_label = letters_label.astype(np.int32)"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49a-LqccDe51",
        "outputId": "ee3815a3-ac5b-4661-c060-4a18667806d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "plt.imshow(letters[3,:,:,0])"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc970e28d50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TI4NuyEDBON"
      },
      "source": [
        "# Generation of the transform for the DataLoader\n",
        "transform = transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Pad((IMAGE_SIZE-ORIGINAL_IMAGE_SIZE)//2,fill=0),\n",
        "  transforms.Normalize(0.5, 0.5)\n",
        "  #ToTanh()\n",
        "])"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf5YX0SpA3cJ"
      },
      "source": [
        "big_letters_dataset = FontsDataset(letters, letters_label, transform)\n",
        "big_letters_loader = DataLoader(big_letters_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuxFvLezK7Cq",
        "outputId": "5c4d3c0d-25bf-4337-a05e-b07be71dbc95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "next(iter(big_letters_loader))[0].shape"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 1, 64, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOlxiXPT6p8d"
      },
      "source": [
        "### Mnist dataset load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHtyXEmypPMa"
      },
      "source": [
        "## CARGAMOS TAMBIN EL MNIST POR SI LAS MOSCAS\r\n",
        "\r\n",
        "os.makedirs(\"../../data/mnist\", exist_ok=True)\r\n",
        "mnist_loader = torch.utils.data.DataLoader(\r\n",
        "    datasets.MNIST(\r\n",
        "        \"../../data/mnist\",\r\n",
        "        train=True,\r\n",
        "        download=True,\r\n",
        "        transform=transforms.Compose(\r\n",
        "            [transforms.Resize(IMAGE_SIZE), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\r\n",
        "        ),\r\n",
        "    ),\r\n",
        "    batch_size=BATCH_SIZE,\r\n",
        "    shuffle=True,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaVXHesWll3X"
      },
      "source": [
        "# Building the GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hJ5m2_juw0P"
      },
      "source": [
        "#this is the tensor used as 'error', or 'output not expected', as\n",
        "# using None is not possible because it raises some errors\n",
        "error_tensor = -1 * torch.ones(1)\n",
        "error_tensor = error_tensor.to(device)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgbJhvLG61dI"
      },
      "source": [
        "### Different Generators used in different iterations of the code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn78mMb5lpmN"
      },
      "source": [
        "##Right now, the generator only generates one image per execution,\n",
        "## maybe it should be readapted to generate a BATCH of images\n",
        "## EDIT: readapted!!\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, noise_dim=50, categorical_dim=10, categorical_noise_dim=30, image_size=20):\n",
        "    super(Generator, self).__init__()\n",
        "\n",
        "    self.noise_dim = noise_dim\n",
        "    self.categorical_dim = categorical_dim\n",
        "    self.categorical_noise_dim = categorical_noise_dim\n",
        "\n",
        "    self.image_size = image_size #size of one of the sides of the image (we are working with square images)\n",
        "    self.hidden_channels = 128 #channels of the first convolutional layer\n",
        "    self.output_channels = 1 #the images we work with are black & white\n",
        "\n",
        "    self.hidden_layer = self.hidden_channels * (self.image_size // 4) ** 2\n",
        "\n",
        "    self.linear = nn.Linear(self.noise_dim + self.categorical_dim + self.categorical_noise_dim, self.hidden_layer)\n",
        "    self.bn = nn.BatchNorm1d(self.hidden_layer)\n",
        "    self.bn2 = nn.BatchNorm2d(self.hidden_channels//2)\n",
        "    #self.upscale = F.upsample_bilinear(2)\n",
        "    #self.upscale = nn.PixelShuffle(upscale_factor=2) # Better than F.upsample_bilinear: training GANs means avoiding sparse gradients\n",
        "    self.conv1 = nn.Conv2d(self.hidden_channels, self.hidden_channels//2, (3,3), stride=1, padding=1)\n",
        "    self.conv2 = nn.Conv2d(self.hidden_channels//2, self.output_channels, (3,3), stride=1, padding=1)\n",
        "\n",
        "    #self.conv3 = nn.Conv2d(self.hidden_channels//4, self.hidden_channels//8, (3,3), stride=1, padding=1)\n",
        "\n",
        "\n",
        "  def forward(self, z, cat, z_cat):\n",
        "    if not len(z_cat) == len(error_tensor):\n",
        "      x = self.bn(F.leaky_relu(self.linear(torch.cat((z, cat, z_cat), axis=1)), negative_slope=LRELU_ALPHA))\n",
        "    else:\n",
        "      #x = self.bn(F.leaky_relu(self.linear(torch.cat((z, cat), axis=1)), negative_slope=LRELU_ALPHA))\n",
        "      x = self.bn(F.relu(self.linear(torch.cat((z, cat), axis=1))))\n",
        "    x = x.view(-1, self.hidden_channels, self.image_size // 4, self.image_size // 4)\n",
        "    x = F.interpolate(x, scale_factor=2)\n",
        "    # ITER 1:  x = self.bn2(F.leaky_relu(self.conv1(x), negative_slope=LRELU_ALPHA))\n",
        "    # ITER 2:  x = self.bn2(F.relu(self.conv1(x)))\n",
        "    # ITER 3:\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.interpolate(x, scale_factor=2)\n",
        "    x = torch.tanh(self.conv2(x))\n",
        "\n",
        "    return x"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGjpOHp1HF8x"
      },
      "source": [
        "class Generator2(nn.Module):\n",
        "  def __init__(self, noise_dim=50, categorical_dim=10, categorical_noise_dim=30, image_size=20):\n",
        "    super(Generator2, self).__init__()\n",
        "\n",
        "    self.noise_dim = noise_dim\n",
        "    self.categorical_dim = categorical_dim\n",
        "    self.categorical_noise_dim = categorical_noise_dim\n",
        "\n",
        "    self.image_size = image_size #size of one of the sides of the image (we are working with square images)\n",
        "    self.hidden_channels = 128 #channels of the first convolutional layer\n",
        "    self.output_channels = 1 #the images we work with are black & white\n",
        "\n",
        "    self.hidden_layer = self.hidden_channels * (self.image_size // 4) ** 2\n",
        "\n",
        "    self.linear = nn.Linear(self.noise_dim + self.categorical_dim + self.categorical_noise_dim, self.hidden_layer)\n",
        "    self.bn = nn.BatchNorm1d(self.hidden_layer)\n",
        "    self.bn2 = nn.BatchNorm2d(self.hidden_channels//2)\n",
        "    self.bn3 = nn.BatchNorm2d(self.hidden_channels//4)\n",
        "    #self.upscale = F.upsample_bilinear(2)\n",
        "    #self.upscale = nn.PixelShuffle(upscale_factor=2) # Better than F.upsample_bilinear: training GANs means avoiding sparse gradients\n",
        "    self.conv0 = nn.Conv2d(self.hidden_channels, self.hidden_channels//2, (5,5), stride=1, padding=2)\n",
        "    self.conv1 = nn.Conv2d(self.hidden_channels//2, self.hidden_channels//4, (5,5), stride=1, padding=2)\n",
        "    self.conv2 = nn.Conv2d(self.hidden_channels//4, self.output_channels, (5,5), stride=1, padding=2)\n",
        "\n",
        "    #self.conv3 = nn.Conv2d(self.hidden_channels//4, self.hidden_channels//8, (3,3), stride=1, padding=1)\n",
        "\n",
        "\n",
        "  def forward(self, z, cat, z_cat):\n",
        "    if not len(z_cat) == len(error_tensor):\n",
        "      x = self.bn(F.relu(self.linear(torch.cat((z, cat, z_cat), axis=1))))\n",
        "    else:\n",
        "      #x = self.bn(F.leaky_relu(self.linear(torch.cat((z, cat), axis=1)), negative_slope=LRELU_ALPHA))\n",
        "      x = self.bn(F.relu(self.linear(torch.cat((z, cat), axis=1))))\n",
        "    x = x.view(-1, self.hidden_channels, self.image_size // 4, self.image_size // 4)\n",
        "    x = F.relu(self.conv0(x))\n",
        "    x = self.bn2(F.interpolate(x, scale_factor=2))\n",
        "    # ITER 1:  x = self.bn2(F.leaky_relu(self.conv1(x), negative_slope=LRELU_ALPHA))\n",
        "    # ITER 2:  x = self.bn2(F.relu(self.conv1(x)))\n",
        "    # ITER 3:\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.interpolate(x, scale_factor=2)\n",
        "    x = self.bn3(x)\n",
        "    x = torch.tanh(self.conv2(x))\n",
        "\n",
        "    return x"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nr7dDw8NmOPn"
      },
      "source": [
        "class Generator3(nn.Module):\r\n",
        "  def __init__(self, noise_dim=50, categorical_dim=10, categorical_noise_dim=30, image_size=20):\r\n",
        "    super(Generator3, self).__init__()\r\n",
        "\r\n",
        "    self.noise_dim = noise_dim\r\n",
        "    self.categorical_dim = categorical_dim\r\n",
        "    self.categorical_noise_dim = categorical_noise_dim\r\n",
        "\r\n",
        "    self.image_size = image_size #size of one of the sides of the image (we are working with square images)\r\n",
        "    self.hidden_channels = 128 #channels of the first convolutional layer\r\n",
        "    self.output_channels = 1 #the images we work with are black & white\r\n",
        "\r\n",
        "    self.hidden_layer = self.hidden_channels * (self.image_size // 4) ** 2\r\n",
        "\r\n",
        "    self.linear = nn.Linear(self.noise_dim + self.categorical_dim + self.categorical_noise_dim, self.hidden_layer)\r\n",
        "    self.bn = nn.BatchNorm1d(self.hidden_layer)\r\n",
        "    self.bn2 = nn.BatchNorm2d(self.hidden_channels//2)\r\n",
        "    self.bn3 = nn.BatchNorm2d(self.hidden_channels//4)\r\n",
        "    #self.upscale = F.upsample_bilinear(2)\r\n",
        "    #self.upscale = nn.PixelShuffle(upscale_factor=2) # Better than F.upsample_bilinear: training GANs means avoiding sparse gradients\r\n",
        "    self.conv0 = nn.ConvTranspose2d(self.hidden_channels, self.hidden_channels//2, (3,3), stride=2, padding=1)\r\n",
        "    self.conv1 = nn.ConvTranspose2d(self.hidden_channels//2, self.hidden_channels//4, (3,3), stride=2, padding=1)\r\n",
        "    self.conv2 = nn.ConvTranspose2d(self.hidden_channels//4, self.output_channels, (3,3), stride=2, padding=1)\r\n",
        "\r\n",
        "    #self.conv3 = nn.Conv2d(self.hidden_channels//4, self.hidden_channels//8, (3,3), stride=1, padding=1)\r\n",
        "\r\n",
        "\r\n",
        "  def forward(self, z, cat, z_cat):\r\n",
        "    if not len(z_cat) == len(error_tensor):\r\n",
        "      x = self.bn(F.relu(self.linear(torch.cat((z, cat, z_cat), axis=1))))\r\n",
        "    else:\r\n",
        "      #x = self.bn(F.leaky_relu(self.linear(torch.cat((z, cat), axis=1)), negative_slope=LRELU_ALPHA))\r\n",
        "      x = self.bn(F.relu(self.linear(torch.cat((z, cat), axis=1))))\r\n",
        "    x = x.view(-1, self.hidden_channels, self.image_size // 8, self.image_size // 8)\r\n",
        "    x = F.relu(self.conv0(x))\r\n",
        "    x = self.bn2(x)\r\n",
        "    x = F.relu(self.conv1(x))\r\n",
        "    x = self.bn3(x)\r\n",
        "    x = torch.tanh(self.conv2(x))\r\n",
        "\r\n",
        "    return x"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vk5J7AFJ65wo"
      },
      "source": [
        "### Different discriminators used in different iterations of the code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqGdW9FrjX9B"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, noise_dim=50, categorical_dim=10, categorical_noise_dim=30, image_size=20):\n",
        "    super(Discriminator, self).__init__()\n",
        "\n",
        "    self.noise_dim = noise_dim\n",
        "    self.categorical_dim = categorical_dim\n",
        "    self.categorical_noise_dim = categorical_noise_dim\n",
        "\n",
        "    self.image_size = image_size #size of one of the sides of the image (we are working with square images)\n",
        "    self.hidden_channels = 128 #channels of the last convolutional layer\n",
        "    self.input_channels = 1 #the images we work with are black & white\n",
        "\n",
        "    self.hidden_layer = self.hidden_channels * (self.image_size // 4) ** 2\n",
        "\n",
        "    self.conv1 = nn.Conv2d(self.input_channels, self.hidden_channels//2, (5,5), stride=1, padding=2)\n",
        "    self.conv2 = nn.Conv2d(self.hidden_channels//2, self.hidden_channels, (5,5), stride=1, padding=2)\n",
        "\n",
        "    self.bn = nn.BatchNorm2d(self.hidden_channels//2)\n",
        "    self.bn2 = nn.BatchNorm2d(self.hidden_channels)\n",
        "    self.avgpool = nn.AvgPool2d(kernel_size=2)\n",
        "    self.flatten = nn.Flatten()\n",
        "\n",
        "    self.true_dense = nn.Linear(self.hidden_layer, 1)\n",
        "    self.cat_dense = nn.Linear(self.hidden_layer, self.categorical_dim)\n",
        "    if categorical_noise_dim > 0:\n",
        "      self.noise_dense = nn.Linear(self.hidden_layer, self.categorical_noise_dim)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.bn(self.avgpool(F.leaky_relu(self.conv1(x), negative_slope=LRELU_ALPHA)))\n",
        "    x = self.bn2(self.avgpool(F.leaky_relu(self.conv2(x), negative_slope=LRELU_ALPHA)))\n",
        "    x = self.flatten(x)\n",
        "\n",
        "    if GAN_STYLE == 2:\n",
        "      true = self.true_dense(x)\n",
        "    else:\n",
        "      true = torch.sigmoid(self.true_dense(x))\n",
        "    cat = F.softmax(self.cat_dense(x))\n",
        "    if self.categorical_noise_dim > 0:\n",
        "      cat_noise = self.noise_dense(x)\n",
        "    else:\n",
        "      cat_noise = error_tensor\n",
        "\n",
        "    return true, cat, cat_noise\n"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxtYQTXifZeR"
      },
      "source": [
        "class Discriminator2(nn.Module):\n",
        "  def __init__(self, noise_dim=50, categorical_dim=10, categorical_noise_dim=30, image_size=20):\n",
        "    super(Discriminator2, self).__init__()\n",
        "\n",
        "    self.noise_dim = noise_dim\n",
        "    self.categorical_dim = categorical_dim\n",
        "    self.categorical_noise_dim = categorical_noise_dim\n",
        "\n",
        "    self.image_size = image_size #size of one of the sides of the image (we are working with square images)\n",
        "    self.hidden_channels = 128 #channels of the last convolutional layer\n",
        "    self.input_channels = 1 #the images we work with are black & white\n",
        "\n",
        "    self.hidden_layer = self.hidden_channels * (self.image_size // 4) ** 2\n",
        "\n",
        "    self.conv1 = nn.Conv2d(self.input_channels, self.hidden_channels, (5,5), stride=1, padding=2)\n",
        "    #self.conv2 = nn.Conv2d(self.hidden_channels//2, self.hidden_channels, (3,3), stride=1, padding=1)\n",
        "\n",
        "    self.bn = nn.BatchNorm2d(self.hidden_channels)\n",
        "    #self.bn2 = nn.BatchNorm2d(self.hidden_channels)\n",
        "    self.avgpool = nn.AvgPool2d(kernel_size=4)\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.dropout = nn.Dropout(p=0.4)\n",
        "    \n",
        "    self.true_dense = nn.Linear(self.hidden_layer, 1)\n",
        "    self.cat_dense = nn.Linear(self.hidden_layer, self.categorical_dim)\n",
        "    if categorical_noise_dim > 0:\n",
        "      self.noise_dense = nn.Linear(self.hidden_layer, self.categorical_noise_dim)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.bn(self.avgpool(F.leaky_relu(self.conv1(x), negative_slope=LRELU_ALPHA)))\n",
        "    print(x.shape)\n",
        "    #x = self.dropout(x)\n",
        "    #x = self.bn2(self.avgpool(F.leaky_relu(self.conv2(x), negative_slope=LRELU_ALPHA)))\n",
        "    x = self.flatten(x)\n",
        "    print(x.shape)\n",
        "    if GAN_STYLE == 2:\n",
        "      true = self.true_dense(x)\n",
        "    else:\n",
        "      true = torch.sigmoid(self.true_dense(x))\n",
        "      print(true.shape)\n",
        "    cat = F.softmax(self.cat_dense(x))\n",
        "    if self.categorical_noise_dim > 0:\n",
        "      cat_noise = self.noise_dense(x)\n",
        "    else:\n",
        "      cat_noise = error_tensor\n",
        "\n",
        "    return true, cat, cat_noise\n"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzw9KA9ygW2v"
      },
      "source": [
        "class Discriminator3(nn.Module):\r\n",
        "  def __init__(self, noise_dim=50, categorical_dim=10, categorical_noise_dim=30, image_size=20):\r\n",
        "    super(Discriminator3, self).__init__()\r\n",
        "\r\n",
        "    self.noise_dim = noise_dim\r\n",
        "    self.categorical_dim = categorical_dim\r\n",
        "    self.categorical_noise_dim = categorical_noise_dim\r\n",
        "\r\n",
        "    self.image_size = image_size #size of one of the sides of the image (we are working with square images)\r\n",
        "    self.hidden_channels = 128 #channels of the last convolutional layer\r\n",
        "    self.input_channels = 1 #the images we work with are black & white\r\n",
        "\r\n",
        "    self.hidden_layer = self.hidden_channels * (self.image_size // 16) ** 2\r\n",
        "\r\n",
        "    self.conv1 = nn.Conv2d(self.input_channels, self.hidden_channels//8, (3,3), stride=2, padding=1)\r\n",
        "    self.conv2 = nn.Conv2d(self.hidden_channels//8, self.hidden_channels//4, (3,3), stride=2, padding=1)\r\n",
        "    self.conv3 = nn.Conv2d(self.hidden_channels//4, self.hidden_channels//2, (3,3), stride=2, padding=1)\r\n",
        "    self.conv4 = nn.Conv2d(self.hidden_channels//2, self.hidden_channels, (3,3), stride=2, padding=1)\r\n",
        "\r\n",
        "    #self.bn = nn.BatchNorm2d(self.hidden_channels)\r\n",
        "    #self.bn2 = nn.BatchNorm2d(self.hidden_channels)\r\n",
        "    self.avgpool = nn.AvgPool2d(kernel_size=4)\r\n",
        "    self.flatten = nn.Flatten()\r\n",
        "    self.dropout = nn.Dropout(p=0.4)\r\n",
        "    \r\n",
        "    self.true_dense = nn.Linear(self.hidden_layer, 1)\r\n",
        "    self.cat_dense = nn.Linear(self.hidden_layer, self.categorical_dim)\r\n",
        "    if categorical_noise_dim > 0:\r\n",
        "      self.noise_dense = nn.Linear(self.hidden_layer, self.categorical_noise_dim)\r\n",
        "\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    x = F.leaky_relu(self.conv1(x), negative_slope=LRELU_ALPHA)\r\n",
        "    x = F.leaky_relu(self.conv2(x), negative_slope=LRELU_ALPHA)\r\n",
        "    x = F.leaky_relu(self.conv3(x), negative_slope=LRELU_ALPHA)\r\n",
        "    x = F.leaky_relu(self.conv4(x), negative_slope=LRELU_ALPHA)\r\n",
        "    x = self.flatten(x)\r\n",
        "    #true = torch.sigmoid(self.true_dense(x))\r\n",
        "    if GAN_STYLE == 2:\r\n",
        "      true = self.true_dense(x)\r\n",
        "    else:\r\n",
        "      true = torch.sigmoid(self.true_dense(x))\r\n",
        "    cat = F.softmax(self.cat_dense(x))\r\n",
        "    if self.categorical_noise_dim > 0:\r\n",
        "      cat_noise = self.noise_dense(x)\r\n",
        "    else:\r\n",
        "      cat_noise = error_tensor\r\n",
        "\r\n",
        "    return true, cat, cat_noise\r\n"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5X3F2kn6-vg"
      },
      "source": [
        "### Other functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw-GQzfVFULs"
      },
      "source": [
        "#Generation of the different datasets that we're going to send to the generator\n",
        "def generate_generator_data(batch_size, noise_dim=50, cat_dim=10, noise_cat_dim=30, same_class=True):\n",
        "\n",
        "  noise = torch.normal(mean=0, std=1, size=(batch_size, noise_dim))\n",
        "\n",
        "  #The categorical variable has to be one-hot encoded. This process does exactly that\n",
        "  cat = torch.zeros(size=(batch_size, cat_dim))\n",
        "  \n",
        "  #Generate all the data from the same class?\n",
        "  #TRUE\n",
        "  if same_class:\n",
        "    cat_result = torch.randint(low=0, high=cat_dim, size=(1,))\n",
        "    for i in range(batch_size):\n",
        "      cat[i, cat_result[0]] = 1\n",
        "  #FALSE\n",
        "  else:\n",
        "    cat_vector = torch.randint(low=0, high=cat_dim, size=(batch_size,))\n",
        "    for i in range(batch_size):\n",
        "      cat[i, cat_vector[i]] = 1\n",
        "\n",
        "  if noise_cat_dim > 0:\n",
        "    noise_cat = torch.normal(mean=0, std=0.2, size=(batch_size, noise_cat_dim))\n",
        "  else:\n",
        "    noise_cat = error_tensor\n",
        "\n",
        "  return noise, cat, noise_cat"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_dOcxBKx2yR"
      },
      "source": [
        "# Dummification in torch\n",
        "def torch_dummies(variable, dim):\n",
        "  cat = torch.zeros(size=(len(variable), dim))\n",
        "  for i in range(len(variable)):\n",
        "    cat[i, (variable[i]).long()] = 1\n",
        "  return cat"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rifj4u5v3ack"
      },
      "source": [
        "# Noise in images\r\n",
        "def noisy_image(image_batch, epsilon):\r\n",
        "  #In this problem, images are normalised in the [-1, 1] range\r\n",
        "  noise = torch.rand_like(image_batch) * epsilon\r\n",
        "  noisy_image_batch = torch.clamp(image_batch + noise, min=-1, max=1)\r\n",
        "  return noisy_image_batch"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVJR7zG0TZCV"
      },
      "source": [
        "# Noise strength decay\r\n",
        "def epsilon_decay(epoch, epsilon_decay_factor, epsilon_decay_exponent):\r\n",
        "  return epsilon_decay_factor / (epoch + 3) ** epsilon_decay_exponent\r\n"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6l4bkyuCS1D"
      },
      "source": [
        "# Discriminator label inversion frequency\r\n",
        "# This is done to fool the discriminator and let the generator learn\r\n",
        "def label_inversion(epoch, inversion_factor, inversion_exponent):\r\n",
        "  inversion_weight = 1 / (inversion_factor * epoch + 3) ** inversion_exponent\r\n",
        "  inversion = random.choices([0,1], weights=[1-inversion_weight, inversion_weight])\r\n",
        "  return inversion[0]"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgWJT4NT7Fy-"
      },
      "source": [
        "### Set-up and train loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgGk2WhCLwWl"
      },
      "source": [
        "# MODEL SETUP (Gen, Discr, Loss, Optimizer)\n",
        "\n",
        "# After defining the generator and discriminator classes, we define the rest of elements\n",
        "# that are necessary for the training: loss functions and optimizers\n",
        "\n",
        "mse = nn.MSELoss()\n",
        "cross_entropy = nn.CrossEntropyLoss()\n",
        "\n",
        "mse, cross_entropy = mse.to(device), cross_entropy.to(device)\n",
        "\n",
        "# Functions for the calculation of the loss function\n",
        "def rand_ones_like(tensor):\n",
        "  return torch.rand_like(tensor)*0.2 + 0.9\n",
        "\n",
        "def rand_zeros_like(tensor):\n",
        "  return torch.rand_like(tensor)*0.2\n",
        "\n",
        "### Info-GAN ###\n",
        "if GAN_STYLE == 0:\n",
        "\n",
        "  lambda_cat = 1\n",
        "  lambda_con = 0.1\n",
        "\n",
        "  noise_dim = 50\n",
        "  cat_dim = CATEGORIES\n",
        "  noise_cat_dim = 30\n",
        "\n",
        "  generator = Generator(noise_dim=noise_dim, categorical_dim=cat_dim, categorical_noise_dim=noise_cat_dim, image_size=IMAGE_SIZE)\n",
        "  discriminator = Discriminator(noise_dim=noise_dim, categorical_dim=cat_dim, categorical_noise_dim=noise_cat_dim, image_size=IMAGE_SIZE)\n",
        "\n",
        "  generator = generator.to(device)\n",
        "  discriminator = discriminator.to(device)\n",
        "\n",
        "\n",
        "  # -- Definition for each of the losses\n",
        "  # Generator loss: MSE Loss\n",
        "  def gen_loss(pred):\n",
        "    #print(max(pred))\n",
        "    return mse(pred, rand_ones_like(pred))\n",
        "\n",
        "  # Discriminator loss: two batches of MSE loss: one for each batch (true images and )\n",
        "  def discr_loss(real_pred, fake_pred):\n",
        "    #print(max(real_pred), max(fake_pred))\n",
        "    real_loss = mse(real_pred, rand_ones_like(real_pred))\n",
        "    fake_loss = mse(fake_pred, rand_zeros_like(fake_pred))\n",
        "    return (real_loss + fake_loss) / 2\n",
        "\n",
        "  # Features loss: batch of noise and categories predicted by the discr.\n",
        "  #  noise is continuous (MSE loss) and categories are not (cross entropy loss)\n",
        "  def features_loss(cat_input, cat_pred, noise_input, noise_pred):\n",
        "    return lambda_cat * cross_entropy(cat_input, torch.argmax(cat_pred, axis=1)) + lambda_con * mse(noise_input, noise_pred)\n",
        "\n",
        "  # Optimizer definition\n",
        "  gen_optim = torch.optim.Adam(generator.parameters(), lr=0.001)\n",
        "  discr_optim = torch.optim.SGD(discriminator.parameters(), lr=0.001)\n",
        "  features_optim = torch.optim.Adam(chain(generator.parameters(), discriminator.parameters()))\n",
        "\n",
        "### AC-GAN ###\n",
        "elif GAN_STYLE == 1:\n",
        "\n",
        "  noise_dim = 50\n",
        "  cat_dim = CATEGORIES\n",
        "  noise_cat_dim = 0 \n",
        "\n",
        "  generator = Generator2(noise_dim=noise_dim, categorical_dim=cat_dim, categorical_noise_dim=noise_cat_dim, image_size=IMAGE_SIZE)\n",
        "  discriminator = Discriminator(noise_dim=noise_dim, categorical_dim=cat_dim, categorical_noise_dim=noise_cat_dim, image_size=IMAGE_SIZE)\n",
        "\n",
        "  generator = generator.to(device)\n",
        "  discriminator = discriminator.to(device)\n",
        "\n",
        "  # -- Definition for each of the losses\n",
        "  # Generator loss: MSE Loss\n",
        "  def gen_loss(pred, cat_input, cat_pred):\n",
        "    #return 0.5 * (mse(pred, rand_ones_like(pred)) + cross_entropy(cat_input, torch.argmax(cat_pred, axis=1))/2.5)\n",
        "    #print('gen loss: ', mse(pred, rand_ones_like(pred)))\n",
        "    return (mse(pred, rand_ones_like(pred)))\n",
        "    #return cross_entropy(cat_input, torch.argmax(cat_pred, axis=1))/2.5\n",
        "\n",
        "  # Discriminator loss: two batches of MSE loss: one for each batch (true images and )\n",
        "  def discr_loss(real_pred, fake_pred, real_cat_input, real_cat_labels, fake_cat_input, fake_cat_labels, invert=False):\n",
        "    #print(real_cat_input.shape, real_cat_labels.shape)\n",
        "    #print(real_cat_input[0,:], real_cat_labels[0,:])\n",
        "    #real_loss = 0.5 * (mse(real_pred, rand_ones_like(real_pred)) + cross_entropy(real_cat_input, torch.argmax(real_cat_labels, axis=1))/2.5)\n",
        "    #fake_loss = 0.5 * (mse(fake_pred, rand_zeros_like(fake_pred)) + cross_entropy(fake_cat_input, torch.argmax(fake_cat_labels, axis=1))/2.5)\n",
        "    if not invert or not FLIP_LABELS:\n",
        "      real_loss = (mse(real_pred, rand_ones_like(real_pred)))\n",
        "      fake_loss = (mse(fake_pred, rand_zeros_like(fake_pred)))\n",
        "    else:\n",
        "      real_loss = (mse(real_pred, rand_zeros_like(real_pred)))\n",
        "      fake_loss = (mse(fake_pred, rand_ones_like(fake_pred)))\n",
        "    #print('real loss: ', real_loss, '   fake loss: ', fake_loss)\n",
        "\n",
        "    return (real_loss + fake_loss) / 2\n",
        "\n",
        "\n",
        "  # Optimizer definition\n",
        "  gen_optim = torch.optim.Adam(generator.parameters(), lr=LR_G)\n",
        "  #discr_optim = torch.optim.SGD(discriminator.parameters(), lr=LR_D)\n",
        "  discr_optim = torch.optim.Adam(discriminator.parameters(), lr=LR_D)\n",
        "\n",
        "### WASSERSTEIN-GAN ###\n",
        "elif GAN_STYLE == 2:\n",
        "\n",
        "  noise_dim = 100\n",
        "  cat_dim = CATEGORIES\n",
        "  noise_cat_dim = 0 \n",
        "\n",
        "  generator = Generator3(noise_dim=noise_dim, categorical_dim=cat_dim, categorical_noise_dim=noise_cat_dim, image_size=IMAGE_SIZE)\n",
        "  discriminator = Discriminator3(noise_dim=noise_dim, categorical_dim=cat_dim, categorical_noise_dim=noise_cat_dim, image_size=IMAGE_SIZE)\n",
        "\n",
        "  generator = generator.to(device)\n",
        "  discriminator = discriminator.to(device)\n",
        "\n",
        "  # -- Definition for each of the losses\n",
        "  # Generator loss: MSE Loss\n",
        "  def gen_loss(pred, cat_input, cat_pred):\n",
        "    #return 0.5 * (mse(pred, rand_ones_like(pred)) + cross_entropy(cat_input, torch.argmax(cat_pred, axis=1))/2.5)\n",
        "    #print('gen loss: ', mse(pred, rand_ones_like(pred)))\n",
        "    return -(torch.mean(pred))\n",
        "    #return cross_entropy(cat_input, torch.argmax(cat_pred, axis=1))/2.5\n",
        "\n",
        "  # Discriminator loss: two batches of MSE loss: one for each batch (true images and )\n",
        "  def discr_loss(real_pred, fake_pred, real_cat_input, real_cat_labels, fake_cat_input, fake_cat_labels, invert=False):\n",
        "    if not invert or not FLIP_LABELS:\n",
        "      real_loss = torch.mean(real_pred)\n",
        "      fake_loss = torch.mean(fake_pred)\n",
        "    else:\n",
        "      real_loss = torch.mean(fake_pred)\n",
        "      fake_loss = torch_mean(real_pred)\n",
        "\n",
        "    return -(real_loss - fake_loss)\n",
        "\n",
        "\n",
        "  # Optimizer definition\n",
        "  gen_optim = torch.optim.Adam(generator.parameters(), lr=LR_G)\n",
        "  #discr_optim = torch.optim.SGD(discriminator.parameters(), lr=LR_D)\n",
        "  discr_optim = torch.optim.Adam(discriminator.parameters(), lr=LR_D)"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmww8RUaQKim",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "44f74437-08ef-46c9-fa73-effb703db1eb"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "# --------\n",
        "# TRAINING\n",
        "# --------\n",
        "\n",
        "n_epochs = 5000\n",
        "dataloader = big_letters_loader\n",
        "inversion_total = 0\n",
        "inversion_all = 0\n",
        "\n",
        "#images that we're going to use to see the performance of the Generator\n",
        "# at different epochs\n",
        "data_show = 36\n",
        "check_noise, check_cat, check_noise_cat = generate_generator_data(data_show, noise_dim=noise_dim, cat_dim=cat_dim, noise_cat_dim=noise_cat_dim, same_class=False)\n",
        "check_noise, check_cat, check_noise_cat = check_noise.to(device), check_cat.to(device), check_noise_cat.to(device)\n",
        "\n",
        "# We set up these variables that are designed for plotting\n",
        "gen_loss_acum = []\n",
        "discr_loss_acum = []\n",
        "features_loss_acum = []\n",
        "\n",
        "# This training is only performed on the numbers dataset\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "\n",
        "  gen_loss_epoch = 0\n",
        "  discr_loss_epoch = 0\n",
        "  features_loss_epoch = 0\n",
        "\n",
        "  for batch_idx, (real_img_batch, real_img_label) in enumerate(dataloader):\n",
        "\n",
        "    #print(real_img_label.shape, real_img_label)\n",
        "    real_img_batch = real_img_batch.to(device)\n",
        "    real_img_label = torch_dummies(real_img_label, cat_dim).to(device)\n",
        "    \n",
        "    #real_img_real_img_batch.type(torch.cuda.FloatTensor)\n",
        "\n",
        "    ## ------------------\n",
        "    ## GENERATOR TRAINING\n",
        "    ## ------------------\n",
        "    \n",
        "    gen_optim.zero_grad()\n",
        "    #if GAN_STYLE == 0: #InfoGAN\n",
        "    noise, cat, noise_cat = generate_generator_data(BATCH_SIZE, noise_dim, cat_dim, noise_cat_dim, same_class=False)\n",
        "    noise, cat, noise_cat = noise.to(device), cat.to(device), noise_cat.to(device)\n",
        "    #elif GAN_STYLE == 1: #AC-GAN\n",
        "    img_batch = generator(noise, cat, noise_cat)\n",
        "    img_batch = img_batch.to(device)\n",
        "    #plt.figure()\n",
        "    #ax = plt.subplot(2, 1, 1)\n",
        "    #plt.imshow(img_batch[0][0,:,:].cpu().detach().numpy())\n",
        "    with torch.no_grad():\n",
        "      if NOISE:\n",
        "        img_batch = noisy_image(img_batch, epsilon_decay(epoch, EPSILON, EPSILON_EXPONENT)) ##NOISE\n",
        "    #ax = plt.subplot(2, 1, 2)\n",
        "    #plt.imshow(img_batch[0][0,:,:].cpu().detach().numpy())\n",
        "    #plt.show()\n",
        "    veracity, cat_pred, _ = discriminator(img_batch)\n",
        "    veracity, cat_pred = veracity.to(device), cat_pred.to(device)\n",
        "    if GAN_STYLE == 0: #InfoGAN\n",
        "      generator_loss = gen_loss(veracity)\n",
        "    elif GAN_STYLE == 1 or GAN_STYLE == 2: #AC-GAN\n",
        "      generator_loss = gen_loss(veracity, cat, cat_pred)\n",
        "    generator_loss.backward()\n",
        "    gen_optim.step()\n",
        "\n",
        "\n",
        "    ## ----------------------\n",
        "    ## DISCRIMINATOR TRAINING\n",
        "    ## ----------------------\n",
        "    if batch_idx % GEN_PER_DISCR == 0:\n",
        "      discr_optim.zero_grad()\n",
        "\n",
        "      # First, we send a batch that has been created from the generator\n",
        "      noise, cat, noise_cat = generate_generator_data(BATCH_SIZE, noise_dim, cat_dim, noise_cat_dim, same_class=False)\n",
        "      noise, cat, noise_cat = noise.to(device), cat.to(device), noise_cat.to(device)\n",
        "      img_batch = generator(noise, cat, noise_cat).detach()\n",
        "      img_batch = img_batch.to(device)\n",
        "      with torch.no_grad():\n",
        "        if NOISE:\n",
        "          img_batch = noisy_image(img_batch, epsilon_decay(epoch, EPSILON, EPSILON_EXPONENT)) ##NOISE\n",
        "      veracity_gen, cat_gen, _ = discriminator(img_batch)\n",
        "\n",
        "      # Then, we send a batch from the real images\n",
        "      real_img_batch = real_img_batch.type(torch.cuda.FloatTensor)\n",
        "      with torch.no_grad():\n",
        "        if NOISE:\n",
        "          real_img_batch = noisy_image(real_img_batch, epsilon_decay(epoch, EPSILON, EPSILON_EXPONENT)) ##NOISE\n",
        "      veracity_real, cat_real_pred, _ = discriminator(real_img_batch)\n",
        "\n",
        "      # We calculate the loss and apply backpropagation\n",
        "      #print(noise_cat.shape, cat_gen.shape)\n",
        "\n",
        "      inversion = label_inversion(epoch, DISCR_LABEL_INVERSION_FACTOR, DISCR_LABEL_INVERSION_PWR)\n",
        "      # variables that track the total inversions that have been performed (bad code)\n",
        "      inversion_total += inversion\n",
        "      inversion_all += 1\n",
        "      \n",
        "      #inversion = False ## COMMENT THIS LINE WHEN YOU WANT TO PRODUCE REAL LOSS LABEL INVERSION TO THE DISCRMINATOR\n",
        "      if GAN_STYLE == 0: #InfoGAN\n",
        "        discriminator_loss = discr_loss(veracity_real, veracity_gen)\n",
        "      else: #AC-GAN\n",
        "        discriminator_loss = discr_loss(veracity_real, veracity_gen, real_img_label, cat_real_pred, cat, cat_gen, inversion)\n",
        "      discriminator_loss.backward()\n",
        "      discr_optim.step()\n",
        "\n",
        "      #clamp parameters if in WASSERSTEIN-GAN:\n",
        "      if GAN_STYLE == 2:\n",
        "        for p in discriminator.parameters():\n",
        "          p.data.clamp_(-0.01, 0.01)\n",
        "\n",
        "\n",
        "    ## ----------------\n",
        "    ## FEATURE TRAINING\n",
        "    ## ----------------\n",
        "\n",
        "    if GAN_STYLE == 0: #InfoGAN\n",
        "      features_optim.zero_grad()\n",
        "\n",
        "      noise, cat, noise_cat = generate_generator_data(BATCH_SIZE, noise_dim, cat_dim, noise_cat_dim)\n",
        "      noise, cat, noise_cat = noise.to(device), cat.to(device), noise_cat.to(device)\n",
        "      img_batch = generator(noise, cat, noise_cat)\n",
        "      img_batch = img_batch.to(device)\n",
        "      _, cat_pred, noise_cat_pred = discriminator(img_batch)\n",
        "      loss = features_loss(cat, cat_pred, noise_cat, noise_cat_pred)\n",
        "      loss.backward()\n",
        "      features_optim.step()\n",
        "\n",
        "    #print(generator_loss, generator_loss.item(), gen_loss_epoch + generator_loss.item())\n",
        "\n",
        "    gen_loss_epoch = gen_loss_epoch + generator_loss.item()\n",
        "    discr_loss_epoch = discr_loss_epoch + discriminator_loss.item()\n",
        "    if GAN_STYLE == 0: #InfoGAN\n",
        "      features_loss_epoch = features_loss_epoch + loss.item()\n",
        "\n",
        "\n",
        "    #END OF BATCH TEXT\n",
        "    if batch_idx % 300 == 0:\n",
        "      print(\n",
        "          f'Train Epoch: {epoch+1}/{n_epochs} [{batch_idx*len(real_img_batch)}/{len(dataloader.dataset)} ({round(100. * batch_idx / len(dataloader), 1)}%)]')\n",
        "      if FLIP_LABELS:\n",
        "        print('discr label inversions:',inversion_total, ' total batches:', inversion_all, ' inversion frequency:', inversion_total/inversion_all)\n",
        "      #print(generator_loss, discriminator_loss, gen_loss_epoch, discr_loss_epoch)\n",
        "\n",
        "  # LOSS PLOT\n",
        "  with torch.no_grad():\n",
        "    gen_loss_epoch = gen_loss_epoch / (batch_idx+1)\n",
        "    discr_loss_epoch = discr_loss_epoch / (batch_idx+1)\n",
        "    if GAN_STYLE == 0: #InfoGAN\n",
        "      features_loss_epoch = features_loss_epoch / (batch_idx+1)\n",
        "    #gen_loss_acum.append(gen_loss_epoch.detach())\n",
        "    #discr_loss_acum.append(discr_loss_epoch.detach())\n",
        "    gen_loss_acum.append(gen_loss_epoch)\n",
        "    discr_loss_acum.append(discr_loss_epoch)\n",
        "    if GAN_STYLE == 0: #InfoGAN\n",
        "      #features_loss_acum.append(features_loss_epoch.detach())\n",
        "      features_loss_acum.append(features_loss_epoch)\n",
        "\n",
        "  clear_output(wait=True)\n",
        "  print('GENERATOR loss: ',gen_loss_epoch, '\\nDISCRIMINATOR loss: ', discr_loss_epoch)\n",
        "  if GAN_STYLE == 0: #InfoGAN\n",
        "    plt.figure(figsize=(12,12))\n",
        "    ax = plt.subplot(2, 1, 1)\n",
        "    plt.plot(gen_loss_acum, 'r', label='gen loss')\n",
        "    plt.plot(discr_loss_acum, 'g', label='discr loss')\n",
        "    plt.legend()\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.plot(features_loss_acum, 'b', label='features loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "  elif GAN_STYLE == 1: #AC_GAN\n",
        "    plt.figure(figsize=(12,6))\n",
        "    axes = plt.gca()\n",
        "    axes.set_ylim([0,1])\n",
        "    plt.plot(gen_loss_acum, 'r', label='gen loss')\n",
        "    plt.plot(discr_loss_acum, 'g', label='discr_loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "  elif GAN_STYLE == 2: #WASSERSTEIN-GAN\n",
        "    plt.figure(figsize=(12,6))\n",
        "    axes = plt.gca()\n",
        "    plt.plot(gen_loss_acum, 'r', label='gen loss')\n",
        "    plt.plot(discr_loss_acum, 'g', label='discr_loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "  # SHOW THE GENERATOR'S INNER WORKINGS\n",
        "  #data_show = 6\n",
        "  #noise, cat, noise_cat = generate_generator_data(data_show, noise_cat_dim=0)\n",
        "  #noise, cat, noise_cat = noise.to(device), cat.to(device), noise_cat.to(device)\n",
        "  img_batch = generator(check_noise, check_cat, check_noise_cat)\n",
        "  plt.figure(figsize=(8,8))\n",
        "  for i in range(data_show):\n",
        "    plt.subplot(data_show // 6, 6, i+1)\n",
        "    plt.imshow(img_batch[i,0,:,:].cpu().detach().numpy(), cmap='gray', vmin=-1, vmax=1)\n",
        "  \n",
        "\n",
        "  ##GENERAR EL MISMO RUIDO AL PRINCIPIO DEL ENTRENAMIENTO PARA LOS PLOTS DEL GENERADOR\n",
        "  # AS SE VE LA EVOLUCIN DE LAS MIMSAS MUESTRAS DE RUIDO"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GENERATOR loss:  0.6651481442451477 \n",
            "DISCRIMINATOR loss:  0.11011029210562508\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-141-8840aa7067cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscr_loss_acum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'g'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'discr_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mGAN_STYLE\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#WASSERSTEIN-GAN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \"\"\"\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(*objs, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-2>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2101\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n\u001b[0;32m-> 2103\u001b[0;31m                             bbox_extra_artists=bbox_artists)\n\u001b[0m\u001b[1;32m   2104\u001b[0m                     \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pad_inches\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mpad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer, bbox_extra_artists)\u001b[0m\n\u001b[1;32m   2383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2384\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2385\u001b[0;31m             \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2386\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2387\u001b[0m                 \u001b[0mbb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1186\u001b[0m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_label_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;31m# go back to just this axis's tick labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_update_label_position\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2019\u001b[0m         \u001b[0;31m# get bounding boxes for this axis and any siblings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2020\u001b[0m         \u001b[0;31m# that have been set by `fig.align_xlabels()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2021\u001b[0;31m         \u001b[0mbboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbboxes2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick_boxes_siblings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick_boxes_siblings\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2003\u001b[0m         \u001b[0;31m# if we want to align labels from other axes:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2004\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_siblings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2005\u001b[0;31m             \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2006\u001b[0m             \u001b[0mtlb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtlb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick_bboxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticks_to_draw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m             \u001b[0mbboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtlb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_update_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mticks\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mdrawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \"\"\"\n\u001b[0;32m-> 1103\u001b[0;31m         \u001b[0mmajor_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_majorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m         \u001b[0mmajor_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[0mmajor_ticks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_major_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_majorticklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1346\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_majorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m         \u001b[0;34m\"\"\"Get the array of major tick locations in data coordinates.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_minorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_view_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2203\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtick_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36mtick_values\u001b[0;34m(self, vmin, vmax)\u001b[0m\n\u001b[1;32m   2209\u001b[0m         vmin, vmax = mtransforms.nonsingular(\n\u001b[1;32m   2210\u001b[0m             vmin, vmax, expander=1e-13, tiny=1e-14)\n\u001b[0;32m-> 2211\u001b[0;31m         \u001b[0mlocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2213\u001b[0m         \u001b[0mprune\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36m_raw_ticks\u001b[0;34m(self, vmin, vmax)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nbins\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m                 nbins = np.clip(self.axis.get_tick_space(),\n\u001b[0m\u001b[1;32m   2151\u001b[0m                                 max(1, self._min_n_ticks - 1), 9)\n\u001b[1;32m   2152\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_tick_space\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2188\u001b[0m         \u001b[0mends\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2189\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mends\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mends\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m72\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2190\u001b[0;31m         \u001b[0mtick\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2191\u001b[0m         \u001b[0;31m# There is a heuristic here that the aspect ratio of tick text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2192\u001b[0m         \u001b[0;31m# is no more than 3:1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick\u001b[0;34m(self, major)\u001b[0m\n\u001b[1;32m   1941\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m             \u001b[0mtick_kw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_minor_tick_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1943\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mXTick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmajor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtick_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1945\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, axes, loc, label, size, width, color, tickdir, pad, labelsize, labelcolor, zorder, gridOn, tick1On, tick2On, label1On, label2On, major, labelrotation, grid_color, grid_linestyle, grid_linewidth, grid_alpha, **kw)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick2line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick2line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgridline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_gridline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_text1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_text2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_text1\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;31m# get the affine as an a, b, c, d, tx, ty list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;31m# x in data coords, y in axes coords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhoriz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_text1_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         t = mtext.Text(\n\u001b[1;32m    434\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_text1_transform\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_text1_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_xaxis_text1_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_text2_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mget_xaxis_text1_transform\u001b[0;34m(self, pad_points)\u001b[0m\n\u001b[1;32m    693\u001b[0m         return (self.get_xaxis_transform(which='tick1') +\n\u001b[1;32m    694\u001b[0m                 mtransforms.ScaledTranslation(0, -1 * pad_points / 72,\n\u001b[0;32m--> 695\u001b[0;31m                                               self.figure.dpi_scale_trans),\n\u001b[0m\u001b[1;32m    696\u001b[0m                 \"top\", labels_align)\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viQNJcmFEMUO"
      },
      "source": [
        "noise, cat, noise_cat = generate_generator_data(20)\n",
        "noise, cat, noise_cat = noise.to(device), cat.to(device), noise_cat.to(device)\n",
        "img_batch = generator(noise, cat, noise_cat)\n",
        "plt.imshow(img_batch[14,0,:,:].cpu().detach().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}