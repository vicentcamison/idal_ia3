{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "2-RNN-chars_PT.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_i15SMd7BrhK"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vicentcamison/idal_ia3/blob/main/3%20Aprendizaje%20profundo%20(II)/Sesion%205/2_RNN_chars_PT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uU_DvWg-NDV"
      },
      "source": [
        "![IDAL](https://i.imgur.com/tIKXIG1.jpg)  \r\n",
        "\r\n",
        "#**Máster en Inteligencia Artificial Avanzada y Aplicada:  IA^3**\r\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX-jL_gi-Rz4"
      },
      "source": [
        "#<strong><center>Predicción de caracteres con RNNs y PyTorch</center></strong>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZhxzVJNq0BB"
      },
      "source": [
        "En este cuaderno implementaremos un sencillo modelo de predicción de carácteres con RNN para familiarizarnos con las funciones de PyTorch para estas redes e iniciarnos en las RNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lf7X1SSGq0BP"
      },
      "source": [
        "En esta implementación, construiremos un modelo que pueda completar su frase basándose en unos pocos caracteres o en una palabra utilizada como entrada.\n",
        "![Ejemplo](https://i.imgur.com/yA5xVhn.jpg)\n",
        "\n",
        "Para mantener esto corto y simple, no usaremos ningún conjunto de datos grande o externo. En su lugar, nos limitaremos a definir unas pocas frases para ver cómo el modelo aprende de estas frases. El proceso que seguirá esta implementación es el siguiente:\n",
        "\n",
        "![Resumen](https://i.imgur.com/KfvOIt5.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3MaoIzCq0BQ"
      },
      "source": [
        "Empezaremos importando el paquete principal de PyTorch junto con la clase *Variable* utilizada para almacenar nuestros tensores de datos y el paquete *nn* que utilizaremos al construir el modelo. Además, sólo usaremos numpy para preprocesar nuestros datos ya que Torch funciona muy bien con numpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDUlX6Gbq0BR"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytx41hNQq0BS"
      },
      "source": [
        "En primer lugar, definiremos las frases que queremos que nuestro modelo produzca cuando se alimente con la primera palabra o los primeros caracteres.\n",
        "\n",
        "Luego crearemos un diccionario con todos los caracteres que tenemos en las frases y los mapearemos a un entero. Esto nos permitirá convertir nuestros caracteres de entrada a sus respectivos enteros (*char2int*) y viceversa (*int2char*)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7G3zmGwAq0BT"
      },
      "source": [
        "text = ['hola que tal','bueno estoy bien','que tengas un buen día', 'espero que lo pases bien']\n",
        "#text = ['hey how are you','good i am fine','have a nice day']\n",
        "\n",
        "# Join all the sentences together and extract the unique characters from the combined sentences\n",
        "chars = set(''.join(text))\n",
        "\n",
        "# Creating a dictionary that maps integers to the characters\n",
        "int2char = dict(enumerate(chars))\n",
        "\n",
        "# Creating another dictionary that maps characters to integers\n",
        "char2int = {char: ind for ind, char in int2char.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzSu9Y8Bq0BT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a69c3a8a-f814-4c64-d9a3-096c05fb78db"
      },
      "source": [
        "print(char2int)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'g': 0, 'b': 1, 'a': 2, 't': 3, 'l': 4, 'p': 5, 'r': 6, 'í': 7, ' ': 8, 's': 9, 'd': 10, 'n': 11, 'y': 12, 'i': 13, 'q': 14, 'h': 15, 'e': 16, 'u': 17, 'o': 18}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d-7btqKq0BV"
      },
      "source": [
        "A continuación, rellenaremos nuestras frases de entrada para asegurarnos de que todas las frases tienen la longitud de la muestra. Aunque las RNN suelen ser capaces de aceptar entradas de tamaño variable, normalmente querremos alimentar los datos de entrenamiento en lotes para acelerar el proceso de entrenamiento. Para poder utilizar lotes para entrenar con nuestros datos, tendremos que asegurarnos de que cada secuencia dentro de los datos de entrada tenga el mismo tamaño.\n",
        "\n",
        "Por lo tanto, en la mayoría de los casos, el relleno puede hacerse rellenando las secuencias que son demasiado cortas con valores **0** y recortando las secuencias que son demasiado largas. En nuestro caso, encontraremos la longitud de la secuencia más larga y rellenaremos el resto de las frases con espacios en blanco para que coincidan con esa longitud."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHrcz9YSq0BW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5751c1d-8516-41b0-f36f-02187b702333"
      },
      "source": [
        "maxlen = len(max(text, key=len))+1\n",
        "print(\"The longest string has {} characters\".format(maxlen))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The longest string has 25 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r91_wI5xq0BX"
      },
      "source": [
        "# Padding\n",
        "\n",
        "# A simple loop that loops through the list of sentences and adds a ' ' whitespace until the length of the sentence matches\n",
        "# the length of the longest sentence\n",
        "for i in range(len(text)):\n",
        "    while len(text[i])<maxlen:\n",
        "        text[i] += ' '"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQqd-ap5q0BX"
      },
      "source": [
        "Como vamos a predecir el siguiente carácter de la secuencia en cada paso de tiempo, tendremos que dividir cada frase en\n",
        "\n",
        "- Datos de entrada\n",
        "    - El último carácter de entrada debe excluirse, ya que no es necesario introducirlo en el modelo\n",
        "- Etiqueta objetivo/de verdad\n",
        "    - Un paso de tiempo por delante de los datos de entrada, ya que será la \"respuesta correcta\" para el modelo en cada paso de tiempo correspondiente a los datos de entrada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehGvXNWbq0BY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "951ca91f-bcce-4d3b-a28d-ac928af3d6ec"
      },
      "source": [
        "# Creating lists that will hold our input and target sequences\n",
        "input_seq = []\n",
        "target_seq = []\n",
        "\n",
        "for i in range(len(text)):\n",
        "    # Remove last character for input sequence\n",
        "    input_seq.append(text[i][:-1])\n",
        "    \n",
        "    # Remove firsts character for target sequence\n",
        "    target_seq.append(text[i][1:])\n",
        "    print(\"Input Sequence: {}\\nTarget Sequence: {}\".format(input_seq[i], target_seq[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Sequence: hola que tal            \n",
            "Target Sequence: ola que tal             \n",
            "Input Sequence: bueno estoy bien        \n",
            "Target Sequence: ueno estoy bien         \n",
            "Input Sequence: que tengas un buen día  \n",
            "Target Sequence: ue tengas un buen día   \n",
            "Input Sequence: espero que lo pases bien\n",
            "Target Sequence: spero que lo pases bien \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Svdsn1KSq0BZ"
      },
      "source": [
        "Ahora podemos convertir nuestras secuencias de entrada y de destino en secuencias de enteros en lugar de caracteres, mapeándolas con los diccionarios que creamos anteriormente. Esto nos permitirá codificar de una sola vez nuestra secuencia de entrada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8GCoeKVq0BZ"
      },
      "source": [
        "for i in range(len(text)):\n",
        "    input_seq[i] = [char2int[character] for character in input_seq[i]]\n",
        "    target_seq[i] = [char2int[character] for character in target_seq[i]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPmVgDkKq0Ba"
      },
      "source": [
        "Antes de codificar nuestra secuencia de entrada en vectores de un solo golpe, definiremos 3 variables clave:\n",
        "\n",
        "- *dict_size*: El número de caracteres únicos que tenemos en nuestro texto.\n",
        "    - Esto determinará el tamaño del vector de un solo paso, ya que cada carácter tendrá un índice asignado en ese vector.\n",
        "- *seq_len*: La longitud de las secuencias que estamos introduciendo en el modelo\n",
        "    - Como hemos estandarizado la longitud de todas nuestras frases para que sean iguales a las frases más largas, este valor será la longitud máxima - 1 ya que también hemos eliminado el último carácter introducido\n",
        "- *tamaño_del_lote*: El número de frases que hemos definido y que vamos a introducir en el modelo como un lote"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFveM4_Zq0Bb"
      },
      "source": [
        "dict_size = len(char2int)\n",
        "seq_len = maxlen - 1\n",
        "batch_size = len(text)\n",
        "\n",
        "def one_hot_encode(sequence, dict_size, seq_len, batch_size):\n",
        "    # Creating a multi-dimensional array of zeros with the desired output shape\n",
        "    features = np.zeros((batch_size, seq_len, dict_size), dtype=np.float32)\n",
        "    \n",
        "    # Replacing the 0 at the relevant character index with a 1 to represent that character\n",
        "    for i in range(batch_size):\n",
        "        for u in range(seq_len):\n",
        "            features[i, u, sequence[i][u]] = 1\n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIfZeF-Aq0Bb"
      },
      "source": [
        "También definimos una función de ayuda que crea matrices de ceros para cada carácter y sustituye el índice del carácter correspondiente por un **1**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muJjErUjq0Bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f526d54-3e16-4b0f-f6b8-c7fdccbf75ad"
      },
      "source": [
        "input_seq = one_hot_encode(input_seq, dict_size, seq_len, batch_size)\n",
        "print(\"Input shape: {} --> (Batch Size, Sequence Length, One-Hot Encoding Size)\".format(input_seq.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input shape: (4, 24, 19) --> (Batch Size, Sequence Length, One-Hot Encoding Size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yn2NS_uUq0Bc"
      },
      "source": [
        "Ya que hemos terminado con todo el preprocesamiento de datos, ahora podemos mover los datos de los arrays de numpy a la propia estructura de datos de PyTorch - **Torch Tensors**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSPlzMS-q0Bd"
      },
      "source": [
        "input_seq = torch.from_numpy(input_seq)\n",
        "target_seq = torch.Tensor(target_seq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmcP63Veq0Be"
      },
      "source": [
        "Vamos ahora a la parte interesante. Después de preparar los datos, pasamos a definir el modelo. Definiremos el modelo usando la librería Torch, y aquí es donde puedes añadir o quitar capas, ya sean capas totalmente conectadas, capas convolucionales, capas RNN vainilla, capas LSTM, ¡y muchas más! En este ejercicio, utilizaremos el modelo básico nn.rnn para demostrar un ejemplo sencillo de cómo se pueden utilizar las RNN.\n",
        "\n",
        "Antes de empezar a construir el modelo, vamos a utilizar una función incorporada en PyTorch para comprobar el dispositivo en el que estamos ejecutando (CPU o GPU). Esta implementación no requerirá de la GPU ya que el entrenamiento es realmente sencillo. Sin embargo, a medida que avancemos hacia grandes conjuntos de datos y modelos con millones de parámetros entrenables, el uso de la GPU será muy importante para acelerar el entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIYQYGpiq0Be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1c6707c-b7e2-4268-d2f4-81dc9256c0fe"
      },
      "source": [
        "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU not available, CPU used\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgpzUB8Hq0Bf"
      },
      "source": [
        "Para empezar a construir nuestro propio modelo de red neuronal, podemos definir una clase que herede la clase base de PyTorch (nn.module) para todos los módulos de red neuronal. Después de hacerlo, podemos empezar a definir algunas variables y también las capas para nuestro modelo bajo el constructor. Para este modelo, sólo utilizaremos una capa de RNN seguida de una capa totalmente conectada. La capa totalmente conectada se encargará de convertir la salida de la RNN a nuestra forma de salida deseada.\n",
        "\n",
        "También tendremos que definir la función forward pass bajo forward() como un método de clase. El orden en que se ejecuta la función forward es secuencial, por lo que tendremos que pasar las entradas y el estado oculto inicializado a cero a través de la capa RNN primero, antes de pasar las salidas de la RNN a la capa totalmente conectada. Ten en cuenta que estamos utilizando las capas que definimos en el constructor.\n",
        "\n",
        "El último método que tenemos que definir es el método que hemos llamado antes para inicializar el estado oculto - init_hidden(). Esto básicamente crea un tensor de ceros con la forma de nuestros estados ocultos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nquRnuczq0Bg"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        # Defining some parameters\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        #Defining the layers\n",
        "        # RNN Layer\n",
        "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        #Initializing hidden state for first input using method defined below\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "\n",
        "        # Passing in the input and hidden state into the model and obtaining outputs\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        \n",
        "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
        "        out = out.contiguous().view(-1, self.hidden_dim)\n",
        "        out = self.fc(out)\n",
        "        \n",
        "        return out, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
        "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
        "         # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
        "        return hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU8moyaHq0Bh"
      },
      "source": [
        "Después de definir el modelo anterior, tendremos que instanciar el modelo con los parámetros pertinentes y definir también nuestros hiperparámetros. Los hiperparámetros que definimos a continuación son\n",
        "\n",
        "- *n_epochs*: Número de épocas --> Se refiere al número de veces que nuestro modelo pasará por todo el conjunto de datos de entrenamiento\n",
        "- *lr*: Tasa de Aprendizaje --> Esto afecta a la tasa en la que nuestro modelo actualiza los pesos en las celdas cada vez que se realiza la retropropagación\n",
        "    - Una tasa de aprendizaje menor significa que el modelo cambia los valores de los pesos con una magnitud menor\n",
        "    - Una tasa de aprendizaje mayor significa que los pesos se actualizan en mayor medida en cada paso de tiempo\n",
        "\n",
        "Al igual que en otras redes neuronales, tenemos que definir también el optimizador y la función de pérdida. Utilizaremos CrossEntropyLoss ya que el resultado final es básicamente una tarea de clasificación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BKEoPTkq0Bi"
      },
      "source": [
        "# Instantiate the model with hyperparameters\n",
        "model = Model(input_size=dict_size, output_size=dict_size, hidden_dim=12, n_layers=1)\n",
        "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
        "model = model.to(device)\n",
        "\n",
        "# Define hyperparameters\n",
        "n_epochs = 200\n",
        "lr=0.01\n",
        "\n",
        "# Define Loss, Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GerE3ZxOq0Bi"
      },
      "source": [
        "Ahora ya podemos empezar el entrenamiento. Como sólo tenemos unas pocas frases, este proceso de entrenamiento es muy rápido. Sin embargo, a medida que avanzemos, los conjuntos de datos más grandes y los modelos más profundos significan que los datos de entrada son mucho más grandes y el número de parámetros dentro del modelo que tenemos que calcular es mucho mayor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "pe8-ZarOq0Bi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f5a60d3-774a-47d6-ac54-6787e5fa2501"
      },
      "source": [
        "# Training Run\n",
        "input_seq = input_seq.to(device)\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    optimizer.zero_grad() # Clears existing gradients from previous epoch\n",
        "    #input_seq = input_seq.to(device)\n",
        "    output, hidden = model(input_seq)\n",
        "    output = output.to(device)\n",
        "    target_seq = target_seq.to(device)\n",
        "    loss = criterion(output, target_seq.view(-1).long())\n",
        "    loss.backward() # Does backpropagation and calculates gradients\n",
        "    optimizer.step() # Updates the weights accordingly\n",
        "    \n",
        "    if epoch%10 == 0:\n",
        "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
        "        print(\"Loss: {:.4f}\".format(loss.item()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 10/200............. Loss: 2.3255\n",
            "Epoch: 20/200............. Loss: 2.0853\n",
            "Epoch: 30/200............. Loss: 1.8379\n",
            "Epoch: 40/200............. Loss: 1.5644\n",
            "Epoch: 50/200............. Loss: 1.2931\n",
            "Epoch: 60/200............. Loss: 1.0367\n",
            "Epoch: 70/200............. Loss: 0.8085\n",
            "Epoch: 80/200............. Loss: 0.6231\n",
            "Epoch: 90/200............. Loss: 0.4855\n",
            "Epoch: 100/200............. Loss: 0.3744\n",
            "Epoch: 110/200............. Loss: 0.2921\n",
            "Epoch: 120/200............. Loss: 0.2333\n",
            "Epoch: 130/200............. Loss: 0.1911\n",
            "Epoch: 140/200............. Loss: 0.1637\n",
            "Epoch: 150/200............. Loss: 0.1419\n",
            "Epoch: 160/200............. Loss: 0.1227\n",
            "Epoch: 170/200............. Loss: 0.1075\n",
            "Epoch: 180/200............. Loss: 0.0957\n",
            "Epoch: 190/200............. Loss: 0.0863\n",
            "Epoch: 200/200............. Loss: 0.0786\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC81uBELq0Bj"
      },
      "source": [
        "Probemos ahora nuestro modelo y veamos qué tipo de salida obtendremos. Antes de eso, vamos a definir una función de ayuda para convertir la salida de nuestro modelo en texto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjW5DARUq0Bk"
      },
      "source": [
        "def predict(model, character):\n",
        "    # One-hot encoding our input to fit into the model\n",
        "    character = np.array([[char2int[c] for c in character]])\n",
        "    character = one_hot_encode(character, dict_size, character.shape[1], 1)\n",
        "    character = torch.from_numpy(character)\n",
        "    character = character.to(device)\n",
        "    \n",
        "    out, hidden = model(character)\n",
        "\n",
        "    prob = nn.functional.softmax(out[-1], dim=0).data\n",
        "    # Taking the class with the highest probability score from the output\n",
        "    char_ind = torch.max(prob, dim=0)[1].item()\n",
        "\n",
        "    return int2char[char_ind], hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjL2ad_7q0Bk"
      },
      "source": [
        "def sample(model, out_len, start='hey'):\n",
        "    model.eval() # eval mode\n",
        "    start = start.lower()\n",
        "    # First off, run through the starting characters\n",
        "    chars = [ch for ch in start]\n",
        "    size = out_len - len(chars)\n",
        "    # Now pass in the previous characters and get a new one\n",
        "    for ii in range(size):\n",
        "        char, h = predict(model, chars)\n",
        "        chars.append(char)\n",
        "\n",
        "    return ''.join(chars)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYyzHV3Iq0Bk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5c3baac-89bc-4732-dcb5-4c1236ae8c6b"
      },
      "source": [
        "print(sample(model, 25, 'hola'))\r\n",
        "print(sample(model, 25, 'espero que tengas'))\r\n",
        "print(sample(model, 25, 'esto'))\r\n",
        "print(sample(model, 25, 'dí'))\r\n",
        "print(sample(model, 25, 'bueno'))\r\n",
        "print(sample(model, 25, 'que tal'))\r\n",
        "print(sample(model, 25, 'esp'))\r\n",
        "print(sample(model, 25, 'bien'))\r\n",
        "print(sample(model, 25, 'que ten'))\r\n",
        "print(sample(model, 25, 'pases'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hola que tal             \n",
            "espero que tengas un buen\n",
            "estoy bien buen día      \n",
            "día                      \n",
            "bueno estoy bien         \n",
            "que tal                  \n",
            "espero que tengas un buen\n",
            "bien                     \n",
            "que tengas un buen día   \n",
            "pases bien buen día      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K57PFBjjq0Bl"
      },
      "source": [
        "Como podemos ver, el modelo es capaz de crear frases dentro de una coherencia: \"bueno, estoy bien\" si lo alimentamos con las palabras \"bueno\", acercandose bastante a lo que pretendíamos que hiciera.\r\n",
        "Prueba a incluir ahora más frases, más palabras y pon a prueba el modelo con diferentes parámetros. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_i15SMd7BrhK"
      },
      "source": [
        "##Referencias: \r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8lsUL25CsAq"
      },
      "source": [
        "\r\n",
        "*   Documento inspirado en los articulos y ejemplos del blog https://blog.floydhub.com/\r\n",
        "* Doc oficial Pytorch https://pytorch.org/docs/stable/generated/torch.nn.RNN.html\r\n",
        "* https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html\r\n",
        "*   [A Simple Neural Network from Scratch with PyTorch and Google Colab](https://github.com/omarsar/pytorch_intro_neural_network/blob/master/nn.ipynb)\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0Sf9VBbCyRq"
      },
      "source": [
        "##Fin del cuaderno"
      ]
    }
  ]
}