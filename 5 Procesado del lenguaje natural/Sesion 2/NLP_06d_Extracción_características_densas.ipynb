{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "NLP_06d-Extracción características densas.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vicentcamison/idal_ia3/blob/main/5%20Procesado%20del%20lenguaje%20natural/Sesion%202/NLP_06d_Extraccio%CC%81n_caracteri%CC%81sticas_densas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "first-reference"
      },
      "source": [
        "# Word embeddings\n",
        "## WE en spaCy\n",
        "Los word embeddings (o word vectors) son representaciones numéricas de las palabras, generadas con una reducción de dimensionalidad sobre una matriz de co-ocurrencia sobre un corpus enorme. Spacy utiliza los word vectors de GloVe, (*Stanford's Global Vectors for Word Representation*). Estos vectores se pueden utilizar para calcular la similaridad semántica entre palabras o documentos.\n",
        "\n",
        "El vocabulario por defecto en el modelo spaCy del idioma inglés (`en_core_web_sm`) es muy pequeño. Hay que cargar en_core_web_md (`python -m spacy download en_core_web_md`) para tener un conjunto de word vectors mayor. El modelo de tamaño medio en español (`python -m spacy download es_core_news_md`) contiene vectores también."
      ],
      "id": "first-reference"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pending-shark"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"es_core_news_md\")"
      ],
      "id": "pending-shark",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "changed-tradition"
      },
      "source": [
        "nlp.vocab.vectors"
      ],
      "id": "changed-tradition",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "checked-convention"
      },
      "source": [
        "len(nlp.vocab.vectors)"
      ],
      "id": "checked-convention",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "handed-initial"
      },
      "source": [
        "nlp.vocab.vectors_length"
      ],
      "id": "handed-initial",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "intense-album"
      },
      "source": [
        "madrid = nlp.vocab[\"Madrid\"]\n",
        "madrid.vector.shape"
      ],
      "id": "intense-album",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prescribed-seventh"
      },
      "source": [
        "type(madrid)"
      ],
      "id": "prescribed-seventh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "technological-shock"
      },
      "source": [
        "doc = nlp(\"me voy a Madrid\")"
      ],
      "id": "technological-shock",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mathematical-bracelet"
      },
      "source": [
        "doc[3]"
      ],
      "id": "mathematical-bracelet",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hundred-nelson"
      },
      "source": [
        "doc[3].vector #equivale a nlp.get_vector(\"Madrid\")"
      ],
      "id": "hundred-nelson",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amended-tower"
      },
      "source": [
        "nlp.vocab.get_vector(\"Madrid\")"
      ],
      "id": "amended-tower",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spanish-resistance"
      },
      "source": [
        "#los tokens tienen el mismo lexema\n",
        "madrid.vector == doc[3].vector"
      ],
      "id": "spanish-resistance",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "marked-glucose"
      },
      "source": [
        "### Similitud semántica\n",
        "Podemos calcular la similitud entre palabras mediante la *similitud coseno*"
      ],
      "id": "marked-glucose"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crazy-decrease"
      },
      "source": [
        "toledo = nlp.vocab[\"Toledo\"]\n",
        "madrid.similarity(toledo)"
      ],
      "id": "crazy-decrease",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "respected-contemporary"
      },
      "source": [
        "manzana = nlp.vocab[\"manzana\"]\n",
        "madrid.similarity(manzana)"
      ],
      "id": "respected-contemporary",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "growing-resident"
      },
      "source": [
        "pera = nlp.vocab[\"pera\"]\n",
        "pera.similarity(manzana)"
      ],
      "id": "growing-resident",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "religious-introduction"
      },
      "source": [
        "nlp_en = spacy.load('en_core_web_md')"
      ],
      "id": "religious-introduction",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "major-consensus"
      },
      "source": [
        "len(nlp_en.vocab.vectors)"
      ],
      "id": "major-consensus",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "subsequent-people"
      },
      "source": [
        "nlp_en.vocab.vectors"
      ],
      "id": "subsequent-people",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "concrete-ancient"
      },
      "source": [
        "`spaCy` no precarga el vocabulario para los modelos con vectores (a partir de la v2.3)"
      ],
      "id": "concrete-ancient"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aggressive-technique"
      },
      "source": [
        "nlp_en.vocab.vectors_length"
      ],
      "id": "aggressive-technique",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gorgeous-postcard"
      },
      "source": [
        "Los lexemas se cargan conforme se usan en el texto. Pero queremos cargar todos los lexemas podemos recorrer todo el vocabulario con:"
      ],
      "id": "gorgeous-postcard"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imperial-dominican"
      },
      "source": [
        "len(nlp_en.vocab)"
      ],
      "id": "imperial-dominican",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "manual-forum"
      },
      "source": [
        "for orth in nlp_en.vocab.vectors:\n",
        "    _ = nlp_en.vocab[orth]"
      ],
      "id": "manual-forum",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "automotive-connectivity"
      },
      "source": [
        "len(nlp_en.vocab)"
      ],
      "id": "automotive-connectivity",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "matched-weather"
      },
      "source": [
        "Podemos buscar términos similares/relacionados por similitud de sus vectores en el espacio vectorial:"
      ],
      "id": "matched-weather"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "contained-cuisine"
      },
      "source": [
        "nlp_en = spacy.load('en_core_web_md')\n",
        "\n",
        "nasa = nlp_en.vocab['NASA']\n",
        "\n",
        "# cogemos todas las palabras del vocabulario que tienen vector, en minúsculas\n",
        "# a partir de spaCy 2.3 no se puede recorrer el vocabulario con nlp.vocab sino nlp.vocab.vectors\n",
        "# https://spacy.io/usage/v2-3\n",
        "allWords = list({nlp_en.vocab[l] for l in nlp_en.vocab.vectors\n",
        "                 if nlp_en.vocab[l].has_vector\n",
        " #                and nlp_en.vocab[l].orth_.islower()\n",
        "                 and nlp_en.vocab[l].lower_ != \"nasa\"})\n",
        "\n",
        "\n",
        "print(\"longitud:\",len(allWords))\n",
        "    \n",
        "# ordenamos por similitud con NASA\n",
        "allWords.sort(key=lambda w: nasa.similarity(w))\n",
        "allWords.reverse()\n",
        "print(\"Top 20 palabras más similares a NASA:\")\n",
        "for word in allWords[:20]:   \n",
        "    print(word.orth_)"
      ],
      "id": "contained-cuisine",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qualified-capability"
      },
      "source": [
        "### Analogías entre palabras\n",
        "Podemos hacer operaciones aritméticas con los vectores para buscar palabras relacionadas:  "
      ],
      "id": "qualified-capability"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "matched-medline"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# definimos similitud mediante distancia coseno (la que usa spaCy)\n",
        "cosine = lambda v1, v2: np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
        "# Buscamos resolver la analogía:\n",
        "# Man is to King as Woman is to ??\n",
        "king = nlp_en.vocab['king']\n",
        "man = nlp_en.vocab['man']\n",
        "woman = nlp_en.vocab['woman']\n",
        "\n",
        "#calculamos vector resultado\n",
        "result = king.vector - man.vector + woman.vector\n",
        "\n",
        "# listamos todas las palabras\n",
        "allWords = list({w for w in nlp_en.vocab if w.has_vector and\n",
        "                 w.orth_.islower() and w.lower_ != \"king\" and\n",
        "                 w.lower_ != \"man\" and w.lower_ != \"woman\"})\n",
        "#sólo funciona después de haber inicializado \n",
        "\n",
        "# ordenamos por similitud con el vector resultado\n",
        "allWords.sort(key=lambda w: cosine(w.vector, result))\n",
        "allWords.reverse()\n",
        "print(\"\\n----------------------------\\nTop 3 resultados más similares para: king - man + woman:\")\n",
        "for word in allWords[:3]:   \n",
        "    print(word.orth_)"
      ],
      "id": "matched-medline",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "regional-intro"
      },
      "source": [
        "### Visualización de word embeddings\n",
        "Vamos a visualizar una proyección 2D de todo el espacio vectorial de *word embeddings*"
      ],
      "id": "regional-intro"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prerequisite-shopping"
      },
      "source": [
        "len(nlp.vocab)"
      ],
      "id": "prerequisite-shopping",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "portable-jersey"
      },
      "source": [
        "lexemas = [nlp.vocab[orth] for orth in nlp.vocab.vectors]"
      ],
      "id": "portable-jersey",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "integrated-department"
      },
      "source": [
        "len(lexemas)"
      ],
      "id": "integrated-department",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enclosed-glasgow"
      },
      "source": [
        "words = [t.text for t in np.random.choice(lexemas, 25, replace=False)]\n",
        "word_vectors = np.array([nlp(word).vector for word in words])\n",
        "\n",
        "words"
      ],
      "id": "enclosed-glasgow",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "historical-fifth"
      },
      "source": [
        "### Visualización t-SNE"
      ],
      "id": "historical-fifth"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acting-oriental"
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tsne = TSNE(n_components=2, random_state=0, n_iter=10000, perplexity=2)\n",
        "np.set_printoptions(suppress=True)\n",
        "T = tsne.fit_transform(word_vectors)\n",
        "labels = words\n",
        "plt.figure(figsize=(14, 8))\n",
        "plt.scatter(T[:, 0], T[:, 1], c='steelblue', edgecolors='k')\n",
        "for label, x, y in zip(labels, T[:, 0], T[:, 1]):\n",
        "    plt.annotate(label, xy=(x+1, y+1), xytext=(0, 0), textcoords='offset points')"
      ],
      "id": "acting-oriental",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "induced-fantasy"
      },
      "source": [
        "### Visualización PCA"
      ],
      "id": "induced-fantasy"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seeing-legislation"
      },
      "source": [
        "word_vectors = [t.vector for t in np.random.choice(lexemas, 10000, replace=False)]"
      ],
      "id": "seeing-legislation",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reasonable-principle"
      },
      "source": [
        "palabras = ['manzana', 'pera', 'Madrid', 'Toledo']"
      ],
      "id": "reasonable-principle",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opening-hamburg"
      },
      "source": [
        "palabras_vectors = np.array([nlp(word).vector for word in palabras])"
      ],
      "id": "opening-hamburg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "charming-yesterday"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "np.set_printoptions(suppress=True)\n",
        "T = pca.fit_transform(word_vectors)\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "plt.scatter(T[:, 0], T[:, 1], c='steelblue',alpha=0.05)\n",
        "\n",
        "labels = palabras\n",
        "T = pca.transform(palabras_vectors)\n",
        "plt.scatter(T[:, 0], T[:, 1], c='lime', edgecolors='darkgreen')\n",
        "\n",
        "for label, x, y in zip(labels, T[:, 0], T[:, 1]):\n",
        "    plt.annotate(label, xy=(x+1, y+1), xytext=(0, 0), textcoords='offset points')"
      ],
      "id": "charming-yesterday",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sunset-governor"
      },
      "source": [
        "### Visualización t-SNE extendida"
      ],
      "id": "sunset-governor"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foreign-vietnam"
      },
      "source": [
        "palabras_all = [t.text for t in np.random.choice(lexemas, 10000, replace=False)] + palabras"
      ],
      "id": "foreign-vietnam",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "serial-cleaners"
      },
      "source": [
        "palabras_vectors = np.array([nlp(word).vector for word in palabras_all])"
      ],
      "id": "serial-cleaners",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "numeric-faculty"
      },
      "source": [
        "tsne = TSNE(n_components=2, random_state=0, n_iter=250, perplexity=2)\n",
        "np.set_printoptions(suppress=True)\n",
        "T = tsne.fit_transform(palabras_vectors)\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "plt.scatter(T[:, 0], T[:, 1], c='steelblue', alpha=0.05)\n",
        "\n",
        "labels = palabras\n",
        "\n",
        "plt.scatter(T[-len(palabras):, 0], T[-len(palabras):, 1], c='lime', edgecolors='darkgreen')\n",
        "for label, x, y in zip(labels, T[-len(palabras):, 0], T[-len(palabras):, 1]):\n",
        "    plt.annotate(label, xy=(x+1, y+1), xytext=(0, 0), textcoords='offset points')"
      ],
      "id": "numeric-faculty",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "relevant-infection"
      },
      "source": [
        "# Word embeddings con Gensim\n",
        "Cargamos un conjunto de WE ya pre-entrenado con la API de Gensim:\\\n",
        "https://radimrehurek.com/gensim/downloader.html"
      ],
      "id": "relevant-infection"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arranged-samuel"
      },
      "source": [
        "import gensim.downloader as api\n",
        "print(list(api.info()['models'].keys()))"
      ],
      "id": "arranged-samuel",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "violent-porter"
      },
      "source": [
        "api.info('glove-twitter-50')"
      ],
      "id": "violent-porter",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "recreational-spoke"
      },
      "source": [
        "for model_name, model_data in sorted(api.info()['models'].items()):\n",
        "    print(\n",
        "        '{} ({} records):\\n{}\\n'.format(\n",
        "            model_name,\n",
        "            model_data.get('num_records', -1),\n",
        "            model_data['description'],\n",
        "        )\n",
        "    )"
      ],
      "id": "recreational-spoke",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loving-silicon"
      },
      "source": [
        "#cargamos el modelo deseado con\n",
        "model = api.load(\"glove-wiki-gigaword-50\")"
      ],
      "id": "loving-silicon",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aware-counter"
      },
      "source": [
        "model"
      ],
      "id": "aware-counter",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rising-haiti"
      },
      "source": [
        "Los vectores de cada palabra del vocabulario se acceden como elementos de un diccionario en `model`"
      ],
      "id": "rising-haiti"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "statutory-longer"
      },
      "source": [
        "dir(model)"
      ],
      "id": "statutory-longer",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enormous-interaction"
      },
      "source": [
        "model.vector_size"
      ],
      "id": "enormous-interaction",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "allied-publication"
      },
      "source": [
        "len(model.vocab)"
      ],
      "id": "allied-publication",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "existing-variance"
      },
      "source": [
        "model.similarity('apple','pear')"
      ],
      "id": "existing-variance",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smaller-federation"
      },
      "source": [
        "Podemos usar los modelos cargados para ver los vectores de una palabra, buscar palabras similares o calcular analogías.\\\n",
        "Los modelos cargados son objetos de la clase `models.keyedvectors` (https://radimrehurek.com/gensim/models/keyedvectors.html)"
      ],
      "id": "smaller-federation"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "russian-dinner"
      },
      "source": [
        "manzana = model[\"apple\"]\n",
        "type(manzana)"
      ],
      "id": "russian-dinner",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juvenile-dating"
      },
      "source": [
        "manzana.shape"
      ],
      "id": "juvenile-dating",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enabling-harbor"
      },
      "source": [
        "model.most_similar(\"apple\")"
      ],
      "id": "enabling-harbor",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "steady-parallel"
      },
      "source": [
        "palabra_rara = 'zamburiña'\n",
        "try:\n",
        "    vector = model[palabra_rara]\n",
        "except KeyError:\n",
        "    print(f\"La palabra '{palabra_rara}' no aparece en este modelo\")"
      ],
      "id": "steady-parallel",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eleven-tactics"
      },
      "source": [
        "### Analogías de word vectors con Gensim\n",
        "Si *palabra_a* es a *palabra_b*, entonces *palabra_c* es a *??*\\\n",
        "Se calcula como el vector más cercano a (a-c)+b"
      ],
      "id": "eleven-tactics"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "relative-edwards"
      },
      "source": [
        "# hombre es a rey como mujer es a XX\n",
        "# rey - hombre + mujer \n",
        "#https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.KeyedVectors.most_similar_cosmul\n",
        "model.most_similar_cosmul(positive=['king','woman'],negative=['man'])"
      ],
      "id": "relative-edwards",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "behind-representation"
      },
      "source": [
        "### Carga de otros modelos pre-entrenados en Gensim\n",
        "En lugar de usar su API cargamos los modelos en formato texto. Hay varios modelos en Español en https://github.com/dccuchile/spanish-word-embeddings"
      ],
      "id": "behind-representation"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dental-figure"
      },
      "source": [
        "#carga de vectores en formato TXT\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "wordvectors_file_vec = '~/Downloads/fasttext-sbwc.100k.vec' #https://github.com/mquezada/starsconf2018-word-embeddings\n",
        "cantidad = 100000\n",
        "wordvectors = KeyedVectors.load_word2vec_format(wordvectors_file_vec, limit=cantidad)"
      ],
      "id": "dental-figure",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "greek-tours"
      },
      "source": [
        "wordvectors"
      ],
      "id": "greek-tours",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "environmental-luxury"
      },
      "source": [
        "len(wordvectors.vocab)"
      ],
      "id": "environmental-luxury",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "professional-pepper"
      },
      "source": [
        "wordvectors['manzana'].shape"
      ],
      "id": "professional-pepper",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "worthy-missile"
      },
      "source": [
        "wordvectors.most_similar(['manzana'])"
      ],
      "id": "worthy-missile",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "strategic-israeli"
      },
      "source": [
        "wordvectors.most_similar(positive=['rey','mujer'],negative=['hombre'], topn=3)"
      ],
      "id": "strategic-israeli",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adequate-cycle"
      },
      "source": [
        "wordvectors.most_similar(positive=['yerno','mujer'],negative=['hombre'], topn=3)"
      ],
      "id": "adequate-cycle",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "relative-vacation"
      },
      "source": [
        "# correr -> corría como saltar -> XX\n",
        "wordvectors.most_similar(positive=['corrían','saltar'],negative=['correr'], topn=3)"
      ],
      "id": "relative-vacation",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cathedral-watts"
      },
      "source": [
        "# Francia -> París como España -> XX\n",
        "wordvectors.most_similar(positive=['parís','alemania'],negative=['francia'], topn=3)"
      ],
      "id": "cathedral-watts",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "excessive-egypt"
      },
      "source": [
        "wordvectors.most_similar(positive=['hombre','malo'], topn=3)"
      ],
      "id": "excessive-egypt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "corrected-traveler"
      },
      "source": [
        "### Modelos FastText\n",
        "Los modelos de FastText se pueden cargar en formato texto (sólo palabras pre-entrenadas) o como modelo binario (calcula nuevas palabras a partir de su n-grama de caracteres)"
      ],
      "id": "corrected-traveler"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bored-sussex"
      },
      "source": [
        "palabra_rara = 'pequeñín'\n",
        "try:\n",
        "    vector = wordvectors[palabra_rara]\n",
        "except KeyError:\n",
        "    print(f\"La palabra '{palabra_rara}' no aparece en este modelo\")"
      ],
      "id": "bored-sussex",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "improving-auckland"
      },
      "source": [
        "del(wordvectors)"
      ],
      "id": "improving-auckland",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liable-haiti"
      },
      "source": [
        "# vectores de FastText desde el formato binario (lento, requiere mucha memoria)\n",
        "        # descargado de https://fasttext.cc/docs/en/crawl-vectors.html\n",
        "# ¡ojo, ocupan 4,5 GB!\n",
        "from gensim.models.fasttext import load_facebook_vectors\n",
        "\n",
        "wordvectors_file = '/Users/jovifran/Downloads/cc.es.300.bin'\n",
        "wordvectors = load_facebook_vectors(wordvectors_file) #carga vectores pre-entrenados sólo"
      ],
      "id": "liable-haiti",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "infrared-estonia"
      },
      "source": [
        "wordvectors"
      ],
      "id": "infrared-estonia",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "severe-testing"
      },
      "source": [
        "dir(wordvectors)"
      ],
      "id": "severe-testing",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "integral-dinner"
      },
      "source": [
        "'neorevolucionario' in wordvectors.vocab"
      ],
      "id": "integral-dinner",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "short-particular"
      },
      "source": [
        "'pequeñín' in wordvectors.vocab"
      ],
      "id": "short-particular",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "educated-moral"
      },
      "source": [
        "wordvectors['neorevolucionario']"
      ],
      "id": "educated-moral",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "corresponding-lawrence"
      },
      "source": [
        "wordvectors.most_similar('neorevolucionario')"
      ],
      "id": "corresponding-lawrence",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "comparative-attraction"
      },
      "source": [
        "wordvectors.similarity('neorevolucionario', 'revolucionario')"
      ],
      "id": "comparative-attraction",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emerging-elizabeth"
      },
      "source": [
        "## Entrenamiento de vectores propios\n",
        "En lugar de usar vectores preentrenados los podemos entrenar con el modelo `word2vec` de Gensim"
      ],
      "id": "emerging-elizabeth"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moral-schema"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('es_core_news_md')"
      ],
      "id": "moral-schema",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "danish-equilibrium"
      },
      "source": [
        "def normalizar_doc_tokenize(doc):\n",
        "    '''Función que normaliza un texto cogiendo sólo\n",
        "    las palabras en minúsculas mayores de 3 caracteres'''\n",
        "    # separamos en tokens\n",
        "    tokens = nlp(doc)\n",
        "    # filtramos stopwords\n",
        "    filtered_tokens = [t.lower_ for t in tokens if\n",
        "                       len(t.text)>3 and\n",
        "                       not t.is_space and\n",
        "                       not t.is_punct]\n",
        "\n",
        "    return filtered_tokens"
      ],
      "id": "danish-equilibrium",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cellular-optimization"
      },
      "source": [
        "with open('cuento.txt', 'r', encoding = 'utf-8') as f:\n",
        "    texto = f.readlines()\n",
        "TOKENIZED_CORPUS = list(map(normalizar_doc_tokenize, texto))\n",
        "len(TOKENIZED_CORPUS)"
      ],
      "id": "cellular-optimization",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "steady-treaty"
      },
      "source": [
        "Calculamos los vectores de las palabras de nuestro corpus"
      ],
      "id": "steady-treaty"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "executed-prayer"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "model = Word2Vec(TOKENIZED_CORPUS, #lista de documentos como lista de tokens\n",
        "                               size=10,          #tamaño del vector\n",
        "                               window=5,         #nº de términos adyacentes que usamos para el cálculo\n",
        "                               min_count=2,      #nº mínimo de apariciones del término para contarlo\n",
        "                               iter=100\n",
        "                              )\n",
        "\n",
        "#una vez entrenado el modelo nos quedamos con los vectores calculados\n",
        "#si no se van a actualizar los vectores con nuevos documentos\n",
        "model = model.wv\n",
        "len(model.vocab)"
      ],
      "id": "executed-prayer",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "documentary-anaheim"
      },
      "source": [
        "Podemos listar todas las palabras del modelo"
      ],
      "id": "documentary-anaheim"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "promising-static"
      },
      "source": [
        "model.vocab"
      ],
      "id": "promising-static",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "several-genius"
      },
      "source": [
        "palabras = model.index2word\n",
        "sorted(palabras)"
      ],
      "id": "several-genius",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thirty-parameter"
      },
      "source": [
        "Podemos ver el vector correspondiente a cualquier palabra del vocabulario"
      ],
      "id": "thirty-parameter"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "textile-payday"
      },
      "source": [
        "print(model['personas'])"
      ],
      "id": "textile-payday",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "announced-correction"
      },
      "source": [
        "Podemos calcular la similitud entre palabras y buscar afinidades entre palabras"
      ],
      "id": "announced-correction"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "identical-curtis"
      },
      "source": [
        "print(model.similarity('cola', 'tripas'))"
      ],
      "id": "identical-curtis",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grateful-cemetery"
      },
      "source": [
        "print(model.similarity('ciudad', 'plaza'))"
      ],
      "id": "grateful-cemetery",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "overhead-cycling"
      },
      "source": [
        "print(model.similarity('cola', 'ciudad'))"
      ],
      "id": "overhead-cycling",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opposite-rehabilitation"
      },
      "source": [
        "print(model.doesnt_match(\"cielo problemas catedral ciudad\".split())) #palabra que no encaja en el contexto del resto"
      ],
      "id": "opposite-rehabilitation",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lonely-butler"
      },
      "source": [
        "Visualizamos los vectores de nuestro vocabulario en 2 dimensiones con el algoritmo t-SNE"
      ],
      "id": "lonely-butler"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bibliographic-basket"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "np.random.seed=123\n",
        "palabras_sm = np.random.choice(palabras, 25, replace=False)\n",
        "vectores = model[palabras_sm]\n",
        "\n",
        "tsne = TSNE(n_components=2, random_state=0, n_iter=1000, perplexity=2)\n",
        "np.set_printoptions(suppress=True)\n",
        "T = tsne.fit_transform(vectores)\n",
        "labels = palabras_sm\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "plt.scatter(T[:, 0], T[:, 1], c='orange', edgecolors='r')\n",
        "for label, x, y in zip(labels, T[:, 0], T[:, 1]):\n",
        "    plt.annotate(label, xy=(x+1, y+1), xytext=(0, 0), textcoords='offset points')"
      ],
      "id": "bibliographic-basket",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sitting-amsterdam"
      },
      "source": [
        "Ahora cargamos los vectores del modelo GloVe del módulo `spaCy` para nuestro corpus de prueba y representamos"
      ],
      "id": "sitting-amsterdam"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "korean-tournament"
      },
      "source": [
        "word_glove_vectors = np.array([nlp(word).vector for word in palabras])"
      ],
      "id": "korean-tournament",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chief-coating"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "tsne = PCA(n_components=2)\n",
        "np.set_printoptions(suppress=True)\n",
        "T = tsne.fit_transform(word_glove_vectors)\n",
        "labels = palabras\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.scatter(T[:, 0], T[:, 1], c='orange', edgecolors='r')\n",
        "for label, x, y in zip(labels, T[:, 0], T[:, 1]):\n",
        "    plt.annotate(label, xy=(x+1, y+1), xytext=(0, 0), textcoords='offset points')"
      ],
      "id": "chief-coating",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "split-waters"
      },
      "source": [
        "nlp.vocab['cola'].similarity(nlp.vocab['tripas'])"
      ],
      "id": "split-waters",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liberal-prototype"
      },
      "source": [
        "nlp.vocab['ciudad'].similarity(nlp.vocab['plaza'])"
      ],
      "id": "liberal-prototype",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "resistant-sight"
      },
      "source": [
        "nlp.vocab['ciudad'].similarity(nlp.vocab['cola'])"
      ],
      "id": "resistant-sight",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "advisory-finance"
      },
      "source": [
        "# Vectores de documento (modelos semánticos)\n",
        "Los vectores de documento recogen el sentido semántico de todo el documento como un vector de dimensines únicas.\n",
        "## Modelos basados en *word embeddings*\n",
        "Calcula el promedio de los *word embeddings* del documento para obtener un vector con sentido semántico de todo el documento."
      ],
      "id": "advisory-finance"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "synthetic-robinson"
      },
      "source": [
        "#Librería spaCy\n",
        "nlp_en = spacy.load(\"en_core_web_md\")\n",
        "#El atributo vector del Doc o Span calcula el promedio de sus vectores de palabra\n",
        "\n",
        "doc1 = nlp_en(\"I like salty fries and hamburgers.\")\n",
        "doc2 = nlp_en(\"Fast food tastes very good.\")"
      ],
      "id": "synthetic-robinson",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "extensive-morrison"
      },
      "source": [
        "doc1[0].vector.shape"
      ],
      "id": "extensive-morrison",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "impressive-landing"
      },
      "source": [
        "doc1.vector.shape"
      ],
      "id": "impressive-landing",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pretty-temperature"
      },
      "source": [
        "doc1[2:4].vector.shape"
      ],
      "id": "pretty-temperature",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "selected-programmer"
      },
      "source": [
        "# Similarity of two documents\n",
        "print(doc1, \"<->\", doc2, doc1.similarity(doc2))\n",
        "# Similarity of tokens and spans\n",
        "french_fries = doc1[2:4]\n",
        "burgers = doc1[5]\n",
        "print(french_fries, \"<->\", burgers, french_fries.similarity(burgers))"
      ],
      "id": "selected-programmer",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cultural-fourth"
      },
      "source": [
        "fast_food = doc2[0:2]\n",
        "print(french_fries, \"<->\", fast_food, french_fries.similarity(fast_food))"
      ],
      "id": "cultural-fourth",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "intensive-footage"
      },
      "source": [
        "#Librería spaCy\n",
        "#El atributo vector del Doc o Span calcula el promedio de sus vectores de palabra\n",
        "\n",
        "doc1 = nlp(\"Me gustan las patatas fritas y las hamburguesas.\")\n",
        "doc2 = nlp(\"La comida rápida sabe muy bien.\")\n",
        "\n",
        "# Similarity of two documents\n",
        "print(doc1, \"<->\", doc2, doc1.similarity(doc2))\n",
        "# Similarity of tokens and spans\n",
        "patatas_fritas = doc1[3:5]\n",
        "hamburguesas = doc1[7]\n",
        "print(patatas_fritas, \"<->\", hamburguesas, patatas_fritas.similarity(hamburguesas))"
      ],
      "id": "intensive-footage",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "automated-producer"
      },
      "source": [
        "comida_rapida = doc2[1:3]\n",
        "print(patatas_fritas, \"<->\", comida_rapida, patatas_fritas.similarity(comida_rapida))"
      ],
      "id": "automated-producer",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "horizontal-matter"
      },
      "source": [
        "#Librería Gensim\n",
        "#calculamos a mano el vector promedio\n",
        "import numpy as np\n",
        "from numpy.linalg import norm # para normalizar datos\n",
        "\n",
        "def to_vector(texto):\n",
        "    tokens = texto.split()\n",
        "    vec = np.zeros(300)\n",
        "    for word in tokens:\n",
        "        # si la palabra está la acumulamos\n",
        "        if word in wordvectors:\n",
        "            vec += wordvectors[word]\n",
        "    return vec / norm(vec)"
      ],
      "id": "horizontal-matter",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "permanent-tackle"
      },
      "source": [
        "#carga de vectores en formato TXT\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "wordvectors_file_vec = '~/Downloads/fasttext-sbwc.100k.vec'\n",
        "wordvectors = KeyedVectors.load_word2vec_format(wordvectors_file_vec)"
      ],
      "id": "permanent-tackle",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "higher-capability"
      },
      "source": [
        "texto = 'me gustan los gatos'\n",
        "to_vector(texto).shape"
      ],
      "id": "higher-capability",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "honey-birthday"
      },
      "source": [
        "#Calculamos similitud entre vectores de documentos\n",
        "def similarity(texto_1, texto_2):\n",
        "    vec_1 = to_vector(texto_1)\n",
        "    vec_2 = to_vector(texto_2)\n",
        "    sim = vec_1 @ vec_2 #producto punto de numpy\n",
        "    return sim"
      ],
      "id": "honey-birthday",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "organizational-accessory"
      },
      "source": [
        "texto_1 = 'los felinos son lindos'\n",
        "texto_2 = 'quiero comer pizza'\n",
        "\n",
        "print(similarity(texto, texto_1))\n",
        "print(similarity(texto, texto_2))"
      ],
      "id": "organizational-accessory",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "macro-chester"
      },
      "source": [
        "## Modelo basado en semántica de documentos\n",
        "Hay un modelo propio de vectores de documentos (modelo `doc2vec` de Gensim)"
      ],
      "id": "macro-chester"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pursuant-lodge"
      },
      "source": [
        "#doc2vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "\n",
        "\n",
        "#Creamos corpus de entrada\n",
        "all_docs = [TaggedDocument(tokens, [str(index)])\n",
        "                for index, tokens in enumerate(TOKENIZED_CORPUS)]"
      ],
      "id": "pursuant-lodge",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sublime-implementation"
      },
      "source": [
        "all_docs[0]"
      ],
      "id": "sublime-implementation",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "located-broadway"
      },
      "source": [
        "from gensim.models import Doc2Vec\n",
        "\n",
        "model_d2v = Doc2Vec(all_docs, vector_size=10,\n",
        "                                 window=5, min_count=2, workers=4,\n",
        "                                 alpha=0.025, \n",
        "                                 min_alpha=0.025,\n",
        "                                 dm=0, dbow_words=0, dm_concat=0)"
      ],
      "id": "located-broadway",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuzzy-harvey"
      },
      "source": [
        "model_d2v.train(all_docs, total_examples=len(all_docs), epochs=200)"
      ],
      "id": "fuzzy-harvey",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "finnish-thanksgiving"
      },
      "source": [
        "len(model_d2v.docvecs.doctags)"
      ],
      "id": "finnish-thanksgiving",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "precise-harvard"
      },
      "source": [
        "#Una vez entrenado podemos ver el vector de cada documento\n",
        "model_d2v.docvecs[2]"
      ],
      "id": "precise-harvard",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "modern-thunder"
      },
      "source": [
        "#El modelo word vectors que usa internamente Doc2vec es igual que el de Word2Vec:\n",
        "palabras = model_d2v.wv.index2word\n",
        "len(palabras)"
      ],
      "id": "modern-thunder",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "conventional-rolling"
      },
      "source": [
        "model_d2v.wv['catedral']"
      ],
      "id": "conventional-rolling",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enclosed-advisory"
      },
      "source": [
        "#Para calcular el docvec de un doc nuevo:\n",
        "new_doc = 'La muchacha vio humo en la pastelería de la calle frente a la catedral'\n",
        "new_d2v = model_d2v.infer_vector(normalizar_doc_tokenize(new_doc), steps=100)\n",
        "new_d2v"
      ],
      "id": "enclosed-advisory",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gorgeous-structure"
      },
      "source": [
        "Podemos relacionar el nuevo documento con el documento más parecido del corpus mediante su similitud coseno:"
      ],
      "id": "gorgeous-structure"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emotional-italic"
      },
      "source": [
        "model_d2v.docvecs.most_similar(positive=[new_d2v])"
      ],
      "id": "emotional-italic",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "colored-merchant"
      },
      "source": [
        "' '.join(TOKENIZED_CORPUS[2])"
      ],
      "id": "colored-merchant",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "incident-insulation"
      },
      "source": [
        "' '.join(TOKENIZED_CORPUS[4])"
      ],
      "id": "incident-insulation",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mysterious-offering"
      },
      "source": [
        ""
      ],
      "id": "mysterious-offering",
      "execution_count": null,
      "outputs": []
    }
  ]
}