{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "NLP_06c-Extracción características TFIDF.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vicentcamison/idal_ia3/blob/main/5%20Procesado%20del%20lenguaje%20natural/Sesion%202/NLP_06c_Extraccio%CC%81n_caracteri%CC%81sticas_TFIDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFj4ZwMmk_Dr"
      },
      "source": [
        "# Extracción de características TF-IDF\n",
        "\n",
        "Primero importamos todas las librerías necesarias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ot7mW1mk_D3"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import spacy\n",
        "import gensim\n",
        "\n",
        "pd.options.display.max_colwidth = None\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CWNOqvQk_D4"
      },
      "source": [
        "Usamos el mismo conjunto de textos de ejemplo *(CORPUS)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY_iUJJek_D5"
      },
      "source": [
        "corpus = ['El cielo es azul y bonito',\n",
        "          'Me encanta el cielo azul, pero no el cielo plomizo',\n",
        "          'Bonito cielo hacía ese día',\n",
        "          'Hoy he desayunado huevos con jamón y tostadas',\n",
        "          'Juan odia las tostadas y los huevos con jamón',\n",
        "          'las tostadas de jamón están muy buenas']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjrAr8UEk_D6"
      },
      "source": [
        "## Limpieza del texto\n",
        "Definimos una función simple de limpieza y normalización del texto y la aplicamos a nuestro corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3v6LTV5k_D8"
      },
      "source": [
        "nlp = spacy.load(\"es_core_news_sm\")\n",
        "def normalizar_doc(doc):\n",
        "    '''Función que normaliza un texto cogiendo sólo\n",
        "    las palabras en minúsculas mayores de 3 caracteres'''\n",
        "    # separamos en tokens\n",
        "    tokens = nlp(doc)\n",
        "    # filtramos stopwords\n",
        "    filtered_tokens = [t.lower_ for t in tokens if\n",
        "                       len(t.text)>3 and\n",
        "                       not t.is_space and\n",
        "                       not t.is_punct]\n",
        "    # juntamos de nuevo en una cadena\n",
        "    doc = ' '.join(filtered_tokens)\n",
        "    return doc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J59wATUWk_D-"
      },
      "source": [
        "norm_corpus = list(map(normalizar_doc, corpus))\n",
        "norm_corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItouJkSgk_EA"
      },
      "source": [
        "# Librería `scikit-learn`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TI1hVNHEk_EB"
      },
      "source": [
        "## Modelo TF-IDF\n",
        "Este modelo promedia la frecuencia de aparición de cada término (TF) por el número de documentos en los que aparece el término (IDF)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEseRRMxk_EB"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tv = TfidfVectorizer(norm=None, use_idf=True)\n",
        "tv_matrix = tv.fit_transform(norm_corpus)\n",
        "tv_matrix.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwgl4cuok_EC"
      },
      "source": [
        "#también es una matriz sparse\n",
        "tv_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TV8FKlDWk_EE"
      },
      "source": [
        "Tenemos los mismos atributos que en el CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ug4SJQSPk_EE"
      },
      "source": [
        "tv.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZV67dBFk_EF"
      },
      "source": [
        "El vocabulario que ha aprendido es el mismo que en el caso del BoW:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Czm1dTfEk_EF"
      },
      "source": [
        "tv.vocabulary_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMAGyXGzk_EF"
      },
      "source": [
        "Al calcular la matriz de vectores de documento se aplica un peso a cada término en función de su IDF:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1_zuzdOk_EG"
      },
      "source": [
        "tv_matrix = tv_matrix.toarray()\n",
        "vocab = tv.get_feature_names()\n",
        "pd.DataFrame(np.round(tv_matrix, 2), columns=vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPDr_LBkk_EG"
      },
      "source": [
        "#pesos para cada término (valor idf(t))\n",
        "tv.idf_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSjjiIJxk_EG"
      },
      "source": [
        "La frecuencia de documentos para cada término (valor tf(término, documento)) no se almacena directamente en el vectorizador pero se puede calcular:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-oSRq0Xk_EG"
      },
      "source": [
        "df = np.sum(tv_matrix>0, axis=0)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFCMMsfAk_EH"
      },
      "source": [
        "#Frec. de documentos y peso IDF para cada término\n",
        "[f\"{n} ({df}): {i:.2f}\" for n, i, df in zip(tv.get_feature_names(), tv.idf_, df)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhsIp0vQk_EI"
      },
      "source": [
        "#La matriz TF-IDF es la BoW multiplicada por los pesos IDF\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv = CountVectorizer()\n",
        "cv_matrix = cv.fit_transform(norm_corpus).toarray()\n",
        "cv_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-pWgaIVk_EI"
      },
      "source": [
        "pd.DataFrame(np.round(cv_matrix*tv.idf_, 2), columns=vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POizWl50k_EI"
      },
      "source": [
        "Cálculo de los pesos IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djszWpLzk_EI"
      },
      "source": [
        "#idf(t) = log [ (1 + n) / (1 + df(t)) ] + 1\n",
        "n = tv_matrix.shape[0]\n",
        "np.log((n+1)/(1+df))+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0sYRB7ik_EJ"
      },
      "source": [
        "#fórmula estándar para TF-IDF\n",
        "#idf(t) = log [ n / (df(t)] + 1 \n",
        "np.log(n/(df))+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo16eE5_k_EJ"
      },
      "source": [
        "Si normalizamos, se ajustan los valores tf-idf en cada documento según la norma 'l2' (suma de cuadrados) o 'l1' (suma de valores absolutos)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-G7KwjVck_EJ"
      },
      "source": [
        "tv_l2 = TfidfVectorizer(norm='l2', use_idf=True)\n",
        "tv_matrix_l2 = tv_l2.fit_transform(norm_corpus).toarray()\n",
        "pd.DataFrame(np.round(tv_matrix_l2, 2), columns=tv_l2.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbuvdTDUk_EK"
      },
      "source": [
        "np.sqrt(np.sum(tv_matrix_l2**2, axis=1)) #cada fila está normalizada a uno (norma 'L2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2mGD4cEk_EK"
      },
      "source": [
        "np.sqrt(np.sum(tv_matrix**2, axis=1)) #valores de cada documento sin normalizar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzN9GtM0k_EK"
      },
      "source": [
        "## Cálculo de la matriz en nuevos documentos\n",
        "Hay que aplicar el método `transform` siempre que queremos vectorizar un nuevo conjunto de documentos.\\\n",
        "Al calcular la matriz TF-IDF para el nuevo corpus, el peso de cada término (IDF) no se modifica"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHjI4Er8k_EL"
      },
      "source": [
        "nuevo_corpus = ['El Cielo amenaza lluvia', 'Pedro desayuna tostadas de jamón con tomate']\n",
        "norm_nuevo_corpus = list(map(normalizar_doc, nuevo_corpus))\n",
        "new_matrix=tv.transform(norm_nuevo_corpus).toarray()\n",
        "pd.DataFrame(np.round(new_matrix, 2), columns=vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StLva8n_k_EM"
      },
      "source": [
        "Si aplicamos una vectorización normalizada, se normaliza cada documento considerando sólo los términos del vocabulario.\n",
        "### Ejercicio 1\n",
        "Aplica la vectorización TF-IDF normalizada *l2* entrenada con el corpus de ejemplo al nuevo corpus y muestra la matriz TF-IDF generada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sqo_4Qp6k_EM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqTdZE-Rk_EN"
      },
      "source": [
        "### Modelo n-gramas\n",
        "Con el vectorizador `tfidfvectorizer` también podemos especificar el rango de n-gramas y el `min_df`.\n",
        "### Ejercicio 2\n",
        "Calcula la matriz TF-IDF para el corpus de ejemplo considerando unigramas y bigramas pero sólo para los términos que aparecen al menos en 2 documentos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0P0AMu6k_EN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-zyzRJVk_EN"
      },
      "source": [
        "# Librería `Gensim`\n",
        "Para trabajar con la librería `Gensim` es necesario transformar los documentos en una lista de tokens. El modelo TF-IDF se calcula a partir del BoW. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKyeDgUDk_EP"
      },
      "source": [
        "def normalizar_doc_tokenize(doc):\n",
        "    '''Función que normaliza un texto cogiendo sólo\n",
        "    las palabras en minúsculas mayores de 3 caracteres'''\n",
        "    # separamos en tokens\n",
        "    tokens = nlp(doc)\n",
        "    # filtramos stopwords\n",
        "    filtered_tokens = [t.lower_ for t in tokens if\n",
        "                       len(t.text)>3 and\n",
        "                       not t.is_space and\n",
        "                       not t.is_punct]\n",
        "\n",
        "    return filtered_tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4l1bj9nxk_EP"
      },
      "source": [
        "Convertimos nuestros texto de ejemplo en una lista de tokens y visualizamos el primer documento como ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIEBX_Hmk_EP"
      },
      "source": [
        "tokenized_corpus = list(map(normalizar_doc_tokenize, corpus))\n",
        "tokenized_corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KRMFeOwk_EQ"
      },
      "source": [
        "Para calcular la matriz TF-IDF primero hay que calcular el modelo BoW:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khJSZUAzk_EQ"
      },
      "source": [
        "Primero aprendemos las palabras y luego generamos la matriz sobre el `corpus` que queramos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpgCcSqOk_ER"
      },
      "source": [
        "from gensim.corpora import Dictionary\n",
        "\n",
        "diccionario = Dictionary(tokenized_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtP2Xtthk_ER"
      },
      "source": [
        "mapped_corpus = [diccionario.doc2bow(text)\n",
        "                 for text in tokenized_corpus]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P_n5Ijok_ER"
      },
      "source": [
        "mapped_corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbxThI_sk_ES"
      },
      "source": [
        "for (i, tf) in mapped_corpus[1]:\n",
        "    print(f\"{diccionario[i]}: {tf}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZx6eUU_k_ES"
      },
      "source": [
        "El objeto `Dictionary` guarda la frecuencia de documentos de cada término (núm. de documentos en los que aparece) en el atributo `dfs`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JG-ECscQk_ES"
      },
      "source": [
        "for i in diccionario.dfs:\n",
        "    print(f\"{diccionario[i]}: {diccionario.dfs[i]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhttFqR5k_ET"
      },
      "source": [
        "Además también guarda la frecuencia total de aparición de cada término en el atributo `cfs`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlaucfABk_ET"
      },
      "source": [
        "for i in diccionario.cfs:\n",
        "    print(f\"{diccionario[i]}: {diccionario.cfs[i]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oy0MeOsk_ET"
      },
      "source": [
        "## Modelo TF-IDF\n",
        "Hay que hacer una transformación sobre la matriz BoW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7BCD2Ohk_EU"
      },
      "source": [
        "from gensim.models import TfidfModel\n",
        "\n",
        "tfidf = TfidfModel(mapped_corpus)\n",
        "corpus_tfidf = tfidf[mapped_corpus]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8Oa25onk_EU"
      },
      "source": [
        "De nuevo, la librería `gensim` genera por cada documento una lista de tuplas (ID,frecuencia) donde ahora la frecuencia está normalizada por la inversa de la frecuencia de documentos que contienen el término:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZz_uGm-k_EU"
      },
      "source": [
        "corpus_tfidf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AxnaDeCk_EV"
      },
      "source": [
        "El modelo devuelve un objeto `TransformedCorpus` que se puede recorrer como un *iterable* o indexar directamente:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j48Qd87xk_EV"
      },
      "source": [
        "corpus_tfidf[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M6Qy_RKk_EV"
      },
      "source": [
        "for (i, v) in corpus_tfidf[1]:\n",
        "    print(f\"{diccionario[i]}: {v:.2f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8PUicbtk_EW"
      },
      "source": [
        "## Aplicación de los modelos a nuevos textos\n",
        "Para aplicar un modelo BoW o TF-IDF a un nuevo documento hay que utilizar los modelos ya entrenados en `gensim` sobre el corpus original. Hay que calcular el BoW del nuevo corpus con el objeto `Dictionary` original y sobre esta matriz calcular su TF-IDF con el modelo `TfidfModel` entrenado con el corpus original:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCtgqrNhk_EX"
      },
      "source": [
        "tokenized_nuevo_corpus = [normalizar_doc_tokenize(doc) for doc in nuevo_corpus]\n",
        "\n",
        "mapped_nuevo_corpus = [diccionario.doc2bow(text)\n",
        "                 for text in tokenized_nuevo_corpus]\n",
        "#BoW\n",
        "mapped_nuevo_corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxqKr7_sk_EX"
      },
      "source": [
        "#TF-IDF\n",
        "nuevo_corpus_tfidf = tfidf[mapped_nuevo_corpus]\n",
        "nuevo_corpus_tfidf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3zfrMXOk_EX"
      },
      "source": [
        "[v for v in nuevo_corpus_tfidf]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oqhH6q4k_EX"
      },
      "source": [
        "#Aplicando todo el proceso en un único paso\n",
        "list(tfidf[map(lambda x: diccionario.doc2bow(normalizar_doc_tokenize(x)), nuevo_corpus)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ro7hvnAk_EY"
      },
      "source": [
        "### Ejercicio 3\n",
        "Define una función que devuelva la matriz TF-IDF para una lista de nuevos textos (pasada como lista de *strings*) usando el diccionario y la función de normalización creadas anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkZ1_ijWk_EY"
      },
      "source": [
        "def calcula_tfidf(corpus, diccionario=diccionario, normalizacion=normalizar_doc_tokenize, vectorizador=tfidf):\n",
        "    \"\"\"Genera la matriz TF-IDF de la lista de texto en 'corpus'\n",
        "    usando el diccionario, la función de normalización y el\n",
        "    vectorizador TF-IDF pasados como argumentos\"\"\"\n",
        "    \n",
        "    #COMPLETAR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F_Kebqqk_EY"
      },
      "source": [
        "calcula_tfidf(nuevo_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}