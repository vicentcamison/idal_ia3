{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "NLP_05-Limpieza y preprocesado.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vicentcamison/idal_ia3/blob/main/5%20Procesado%20del%20lenguaje%20natural/Sesion%201/NLP_05_Limpieza_y_preprocesado.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "documented-resistance"
      },
      "source": [
        "### División de texto"
      ],
      "id": "documented-resistance"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "surgical-rhythm"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"es_core_news_sm\")"
      ],
      "id": "surgical-rhythm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "palestinian-raise"
      },
      "source": [
        "doc = nlp(\"La gata de Juan es blanca.\")"
      ],
      "id": "palestinian-raise",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unauthorized-infrastructure",
        "outputId": "42847014-b8d0-4652-9752-f11c952df47b"
      },
      "source": [
        "[t for t in doc]"
      ],
      "id": "unauthorized-infrastructure",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[La, gata, de, Juan, es, blanca, .]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iraqi-leone"
      },
      "source": [
        "División en *tokens*"
      ],
      "id": "iraqi-leone"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liable-process",
        "outputId": "4d4727e6-c54a-4826-d7c5-3e99ec6dd85e"
      },
      "source": [
        "[t.text for t in doc]"
      ],
      "id": "liable-process",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['La', 'gata', 'de', 'Juan', 'es', 'blanca', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "median-harassment"
      },
      "source": [
        "División en frases"
      ],
      "id": "median-harassment"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "immune-computer"
      },
      "source": [
        "doc = nlp(\"la vaca come hierba. El perro come longanizas.\")"
      ],
      "id": "immune-computer",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "standard-burst",
        "outputId": "e69141aa-e55f-4323-d0bf-f23401078e8f"
      },
      "source": [
        "[s for s in doc.sents]"
      ],
      "id": "standard-burst",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[la vaca come hierba., El perro come longanizas.]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "periodic-defendant",
        "outputId": "b5c0a851-e485-4669-aa3a-57706c28e393"
      },
      "source": [
        "[s.text for s in doc.sents]"
      ],
      "id": "periodic-defendant",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['la vaca come hierba.', 'El perro come longanizas.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urban-appearance"
      },
      "source": [
        "### Limpieza de acentos"
      ],
      "id": "urban-appearance"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "addressed-international",
        "outputId": "e9d9600d-f45a-4a83-9a2f-b4aa85dc23f9"
      },
      "source": [
        "import unicodedata\n",
        "\n",
        "data = 'Sómě Áccěntěd tëxt'\n",
        "normal = unicodedata.normalize('NFKD', data).encode('ASCII', 'ignore')\n",
        "print(normal)"
      ],
      "id": "addressed-international",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Some Accented text'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atmospheric-manhattan"
      },
      "source": [
        "def remove_accents(text):\n",
        "    new_text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    return new_text"
      ],
      "id": "atmospheric-manhattan",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "expensive-hearts",
        "outputId": "b058f79d-6436-4bbf-f015-68885b9e4774"
      },
      "source": [
        "remove_accents(data)"
      ],
      "id": "expensive-hearts",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Some Accented text'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "touched-clerk",
        "outputId": "79e648de-1603-473f-8531-c924bce08a62"
      },
      "source": [
        "from gensim.utils import deaccent\n",
        "#https://radimrehurek.com/gensim/utils.html#gensim.utils.deaccent"
      ],
      "id": "touched-clerk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'gensim'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-540ea719ebbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeaccent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#https://radimrehurek.com/gensim/utils.html#gensim.utils.deaccent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scheduled-brush"
      },
      "source": [
        "deaccent(data)"
      ],
      "id": "scheduled-brush",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "surface-chemical"
      },
      "source": [
        "help(deaccent)"
      ],
      "id": "surface-chemical",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "given-spencer"
      },
      "source": [
        "### Limpieza de caracteres especiales"
      ],
      "id": "given-spencer"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "steady-organic"
      },
      "source": [
        "import re, string\n",
        "\n",
        "def remove_special_characters(text):\n",
        "    pat = '[{}]'.format(re.escape(string.punctuation))\n",
        "    return re.sub(pat, '', text)\n",
        " \n",
        "remove_special_characters(\"007 Not sure@ if this % was #fun! 558923 What do# you think** of it.? $500USD!\")"
      ],
      "id": "steady-organic",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "senior-mortgage"
      },
      "source": [
        "string.punctuation"
      ],
      "id": "senior-mortgage",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yellow-upper"
      },
      "source": [
        "'[{}]'.format(re.escape(string.punctuation))"
      ],
      "id": "yellow-upper",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "contemporary-soundtrack"
      },
      "source": [
        "### Expandir contracciones\n",
        "hay que instalar la librería https://github.com/kootenpv/contractions con ```pip install contractions```"
      ],
      "id": "contemporary-soundtrack"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adopted-playing"
      },
      "source": [
        "import contractions\n",
        "contractions.fix(\"you're happy now, aren't you?\")"
      ],
      "id": "adopted-playing",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "textile-batch"
      },
      "source": [
        "nlp_en = spacy.load(\"en_core_web_md\")"
      ],
      "id": "textile-batch",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "after-controversy"
      },
      "source": [
        "doc = nlp_en(\"you're happy now, aren't you?\")\n",
        "[t for t in doc]"
      ],
      "id": "after-controversy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clinical-adelaide"
      },
      "source": [
        "### Stop-words"
      ],
      "id": "clinical-adelaide"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuclear-reading"
      },
      "source": [
        "from spacy.lang.en.stop_words import STOP_WORDS"
      ],
      "id": "nuclear-reading",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "harmful-resource"
      },
      "source": [
        "len(STOP_WORDS)"
      ],
      "id": "harmful-resource",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naked-marijuana"
      },
      "source": [
        "print(STOP_WORDS)"
      ],
      "id": "naked-marijuana",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "textile-cabinet"
      },
      "source": [
        "import spacy    \n",
        "nlp = spacy.load(\"es_core_news_sm\")\n",
        "print(len(nlp.Defaults.stop_words))\n",
        "print(nlp.Defaults.stop_words)"
      ],
      "id": "textile-cabinet",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bright-strike"
      },
      "source": [
        "'y' in nlp.Defaults.stop_words"
      ],
      "id": "bright-strike",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "operating-answer"
      },
      "source": [
        "'nunca' in nlp.Defaults.stop_words"
      ],
      "id": "operating-answer",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "powerful-accused"
      },
      "source": [
        "nlp(\"tuya\")[0].is_stop"
      ],
      "id": "powerful-accused",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cooked-laptop"
      },
      "source": [
        "#podemos añadir o quitar palabras de la lista\n",
        "\n",
        "#añadir\n",
        "nlp.Defaults.stop_words.add(\"my_new_stopword\")\n",
        "nlp.Defaults.stop_words |= {\"my_new_stopword1\",\"my_new_stopword2\"}\n",
        "\n",
        "#quitar\n",
        "nlp.Defaults.stop_words.remove(\"tuya\")\n",
        "nlp.Defaults.stop_words -= {\"tuya\", \"mia\"}"
      ],
      "id": "cooked-laptop",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "electric-sydney"
      },
      "source": [
        "\"tuya\" in nlp.Defaults.stop_words"
      ],
      "id": "electric-sydney",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sensitive-memphis"
      },
      "source": [
        "from gensim.parsing.preprocessing import remove_stopwords\n",
        "import gensim\n",
        "gensim_stopwords = gensim.parsing.preprocessing.STOPWORDS\n",
        "text = f\"The first time I saw Catherine she was wearing a vivid crimson dress and was nervously \" \\\n",
        "       f\"leafing through a magazine in my waiting room.\"\n",
        "print(f\"Original Text : {text}\")\n",
        "print(f\"Text without stopwords : {remove_stopwords(text.lower())}\")\n",
        "print(f\"Total count of stopwords in Gensim is {len(list(gensim_stopwords))}\")"
      ],
      "id": "sensitive-memphis",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vital-intention"
      },
      "source": [
        "### Corrección ortográfica\n",
        "Librería `spellchecker`. Instalamos con\n",
        "```pip install pyspellchecker```"
      ],
      "id": "vital-intention"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atmospheric-jewelry"
      },
      "source": [
        "from spellchecker import SpellChecker\n",
        "\n",
        "spell = SpellChecker(language='es')  # Spanish dictionary\n",
        "print(f\"Hay {spell.word_frequency._unique_words} palabras en el diccionario\")"
      ],
      "id": "atmospheric-jewelry",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "entire-serial"
      },
      "source": [
        "spell.correction('mañnaa')"
      ],
      "id": "entire-serial",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "technological-declaration"
      },
      "source": [
        "spell.candidates('mañnaa')"
      ],
      "id": "technological-declaration",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "injured-watson"
      },
      "source": [
        "#si una palabra está en el diccionario devuelve su frecuencia relativa:\n",
        "spell['mañana']  #equivale a spell.word_frequency['mañana']"
      ],
      "id": "injured-watson",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "extensive-olive"
      },
      "source": [
        "spell['mañnaa']"
      ],
      "id": "extensive-olive",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "impressive-digest"
      },
      "source": [
        "spell['mañna']"
      ],
      "id": "impressive-digest",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "color-poland"
      },
      "source": [
        "### Lematizado"
      ],
      "id": "color-poland"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reasonable-buying"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"es_core_news_sm\")\n",
        "doc = nlp(\"el gato es blanco\")\n",
        "[t.lemma_ for t in doc]"
      ],
      "id": "reasonable-buying",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "front-foster"
      },
      "source": [
        "doc = nlp(\"el perro de Juan se comió mi bocadillo pero se dejó la mitad\")\n",
        "[(t.lemma_, t.pos_) for t in doc]"
      ],
      "id": "front-foster",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blind-alfred"
      },
      "source": [
        "doc = nlp(\"la salida se ha bloqueado. La salida está bloqueada.\")\n",
        "[(t.lemma_, t.pos_) for t in doc]"
      ],
      "id": "blind-alfred",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "overhead-youth"
      },
      "source": [
        "### Funciones de normalización"
      ],
      "id": "overhead-youth"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "temporal-brighton"
      },
      "source": [
        "texto = \"@Graffitera23 qué hermoso!,es bueno desviar la mirada al cielo y a las nubes de vez en cuando,abajo está jodido.Preciosa foto,mil abrazos \""
      ],
      "id": "temporal-brighton",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neural-property"
      },
      "source": [
        "# en spacy\n",
        "import re\n",
        "import spacy\n",
        "nlp=spacy.load('es_core_news_sm')\n",
        "               \n",
        "def normalize_document(doc):\n",
        "   # separamos en tokens\n",
        "    tokens = nlp(doc)\n",
        "    # quitamos puntuación/espacios y stopwords\n",
        "    filtered_tokens = [t.lower_ for t in tokens if not t.is_stop and not t.is_punct]\n",
        "    # juntamos de nuevo en una cadena\n",
        "    doc = ' '.join(filtered_tokens)\n",
        "\n",
        "    return doc"
      ],
      "id": "neural-property",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "surprising-prize"
      },
      "source": [
        "normalize_document(texto)"
      ],
      "id": "surprising-prize",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "further-acquisition"
      },
      "source": [
        "Con esta función no se eliminan los signos de puntuación que no forman un token de manera independiente, debemos hacerlo con un patrón regular"
      ],
      "id": "further-acquisition"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "national-numbers"
      },
      "source": [
        "import string\n",
        "\n",
        "pat  = '[{}]'.format(re.escape(string.punctuation))\n",
        "\n",
        "def normalize_document_remove_punct(doc):\n",
        "   # separamos en tokens\n",
        "    tokens = nlp(doc)\n",
        "    # quitamos puntuación/espacios y stopwords\n",
        "    filtered_tokens = [re.sub(pat, ' ', t.lower_) for t in tokens if not t.is_stop and not t.is_punct]\n",
        "    # juntamos de nuevo en una cadena\n",
        "    doc = ' '.join(filtered_tokens)\n",
        "\n",
        "    return doc"
      ],
      "id": "national-numbers",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "perfect-history"
      },
      "source": [
        "normalize_document_remove_punct(texto)"
      ],
      "id": "perfect-history",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "champion-consequence"
      },
      "source": [
        "from gensim.utils import simple_preprocess\n",
        "#https://radimrehurek.com/gensim/utils.html#gensim.utils.simple_preprocess\n",
        "\n",
        "help(simple_preprocess)"
      ],
      "id": "champion-consequence",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "armed-speaker"
      },
      "source": [
        "simple_preprocess(texto, deacc=True)"
      ],
      "id": "armed-speaker",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "powered-supplier"
      },
      "source": [
        "from gensim.utils import tokenize\n",
        "#https://radimrehurek.com/gensim/utils.html#gensim.utils.tokenize\n",
        "\n",
        "help(tokenize)"
      ],
      "id": "powered-supplier",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anonymous-survivor"
      },
      "source": [
        "tokenize(texto)"
      ],
      "id": "anonymous-survivor",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "organized-conservative"
      },
      "source": [
        "list(tokenize(texto, deacc=True, lowercase=True))"
      ],
      "id": "organized-conservative",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "specified-printing"
      },
      "source": [
        "from gensim.parsing.preprocessing import preprocess_string\n",
        "#https://radimrehurek.com/gensim/parsing/preprocessing.html#gensim.parsing.preprocessing.preprocess_string\n",
        "help(preprocess_string)"
      ],
      "id": "specified-printing",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "intense-japan"
      },
      "source": [
        "preprocess_string(texto) #elimina stop words y deja raíz de las palabras"
      ],
      "id": "intense-japan",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "graduate-cutting"
      },
      "source": [
        "texto"
      ],
      "id": "graduate-cutting",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "distinct-institution"
      },
      "source": [
        "preprocess_string(\"<i>Hel 9lo</i> <b>Wo9 rld</b>! Th3     weather_is really g00d today, isn't it?\")"
      ],
      "id": "distinct-institution",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clear-piano"
      },
      "source": [
        "preprocess_string(\"Transformer is behind the recent NLP developments, including Google’s BERT\")"
      ],
      "id": "clear-piano",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "transparent-payday"
      },
      "source": [
        "from gensim.parsing.preprocessing import *\n",
        "preprocess_string(\"Transformer is behind the recent NLP developments, including Google’s BERT\", [remove_stopwords])"
      ],
      "id": "transparent-payday",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "downtown-aquarium"
      },
      "source": [
        "preprocess_string(\"Transformer is behind the recent NLP developments, including Google’s BERT\", [remove_stopwords, stem_text])"
      ],
      "id": "downtown-aquarium",
      "execution_count": null,
      "outputs": []
    }
  ]
}