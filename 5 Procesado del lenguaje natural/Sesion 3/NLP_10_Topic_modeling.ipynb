{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "NLP_10-Topic modeling.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vicentcamison/idal_ia3/blob/main/5%20Procesado%20del%20lenguaje%20natural/Sesion%203/NLP_10_Topic_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JOOqXF3nTjR"
      },
      "source": [
        "# Topic modeling\n",
        "En este notebook se va a mostrar el uso de distintos modelos de extracción de temáticas (*topic modeling*) en un conjunto de textos de ejemplo sencillo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xO2gJ8svnTjc"
      },
      "source": [
        "import spacy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "nlp=spacy.load('en_core_web_sm')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acz9ZyivnTjf"
      },
      "source": [
        "### Creación del corpus\n",
        "Creamos un pequeño Corpus de ejemplo formado por 8 frases cortas. Definimos una sencilla función de normalización y aplicamos esta normalización a todo el corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7oitytXnTjg",
        "outputId": "23e175a6-58cb-4727-8ac5-ecc636860ac3"
      },
      "source": [
        "def normalize_document(doc):\n",
        "    # tokenizamos el texto\n",
        "    tokens = nlp(doc)\n",
        "    # quitamos puntuación/espacios/stop words y cogemos el lema\n",
        "    lemmas = [t.lemma_ for t in tokens if not t.is_punct and not t.is_space and not t.is_stop]\n",
        "    doc = ' '.join(lemmas)\n",
        "    return doc\n",
        "\n",
        "def normalize_corpus(corpus):\n",
        "    \"\"\"Normaliza un corpus de documentos aplicando al función de normalización\n",
        "    normalize_document() a cada documento de la lista pasada como argumento\"\"\"   \n",
        "    return [normalize_document(text) for text in corpus]\n",
        "\n",
        "toy_corpus = [\n",
        "\"The fox jumps over the dog\",\n",
        "\"the fox is very clever and quick\",\n",
        "\"The dog is slow and lazy\",\n",
        "\"The cat is smarter than the fox and the dog\",\n",
        "\"Python is an excellent programming language\",\n",
        "\"Java and Ruby are other programming languages\",\n",
        "\"Python and Java are very popular programming languages\",\n",
        "\"Python programs are smaller than Java programs\"]\n",
        "\n",
        "norm_corpus = normalize_corpus(toy_corpus)\n",
        "norm_corpus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fox jump dog',\n",
              " 'fox clever quick',\n",
              " 'dog slow lazy',\n",
              " 'cat smart fox dog',\n",
              " 'Python excellent programming language',\n",
              " 'Java Ruby programming language',\n",
              " 'Python Java popular programming language',\n",
              " 'Python program small Java program']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHNwzDMxnTji"
      },
      "source": [
        "## Topic modeling usando Scikit-learn\n",
        "La librería `scikit-learn` implementa los modelos *Latent Semantic Analysis* (LSA) y *Latent Dirichlet Allocation* (LDA).  \n",
        "Partimos de un modelo TF-IDF para el modelado LSA y de un modelo BoW para el modelado LDA\n",
        "\n",
        "### Modelo LSA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Z8HTopKnTjj"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# usamos características tf-idf para LSA.\n",
        "tfidf_vectorizer = TfidfVectorizer(min_df=2)\n",
        "tfidf = tfidf_vectorizer.fit_transform(norm_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4afWePWnTjk",
        "outputId": "dbcd7bec-1425-42f9-a446-71f31cb75fe7"
      },
      "source": [
        "tfidf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<8x6 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 18 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_IuB2t6nTjl",
        "outputId": "455900b9-bca1-4427-e31a-2ff4a3a80e29"
      },
      "source": [
        "tfidf_vectorizer.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dog', 'fox', 'java', 'language', 'programming', 'python']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tk6rqxHnnTjn"
      },
      "source": [
        "Definimos una función de ayuda para mostrar los resultados (términos asociados a cada tema)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yCxFsyHnTjn"
      },
      "source": [
        "def print_top_words(model, feature_names, n_top_words):\n",
        "    \"\"\"Función auxiliar para mostrar los términos más importantes\n",
        "    de cada topic\"\"\"\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        message = \"Topic #%d: \" % topic_idx\n",
        "        message += \" \".join([feature_names[i]\n",
        "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
        "        print(message)\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhmuN_GknTjo"
      },
      "source": [
        "Calculamos los modelos para nuestro corpus (método `fit`) y vemos cuáles son los 5 términos con más peso para cada *topic*. Cada modelo asigna un grado de pertenencia en cada tema a cada término del vocabulario de la matriz tfidf o bow utilizada como entrada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rU4P9RrwnTjq",
        "outputId": "c475c711-d3e0-4d5b-9bd5-d2a1828ce707"
      },
      "source": [
        "from sklearn.decomposition import TruncatedSVD, LatentDirichletAllocation\n",
        "\n",
        "# Ajustamos el modelo LSA\n",
        "lsa = TruncatedSVD(n_components=2).fit(tfidf)\n",
        "\n",
        "print(\"\\nTopics en modelo LSA:\")\n",
        "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
        "print_top_words(lsa, tfidf_feature_names, 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Topics en modelo LSA:\n",
            "Topic #0: python programming\n",
            "Topic #1: dog fox\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OWjN1mgnTjr"
      },
      "source": [
        "El método `fit` aprende la matriz de `topics` x `términos` para el corpus dado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qThGgMEVnTjr",
        "outputId": "fe2d31d7-a96d-4c88-a549-075802e2e8e6"
      },
      "source": [
        "lsa.components_.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1IGwspbnTjs",
        "outputId": "44db303a-eaa8-4ac3-f13b-56307f3a94bb"
      },
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(lsa.components_, columns=tfidf_feature_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dog</th>\n",
              "      <th>fox</th>\n",
              "      <th>java</th>\n",
              "      <th>language</th>\n",
              "      <th>programming</th>\n",
              "      <th>python</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.000000</td>\n",
              "      <td>1.962616e-16</td>\n",
              "      <td>5.000000e-01</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>5.000000e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.707107</td>\n",
              "      <td>7.071068e-01</td>\n",
              "      <td>-1.110223e-16</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.665335e-16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        dog           fox          java  language  programming        python\n",
              "0 -0.000000  1.962616e-16  5.000000e-01       0.5          0.5  5.000000e-01\n",
              "1  0.707107  7.071068e-01 -1.110223e-16       0.0          0.0 -1.665335e-16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s39F9DwFnTjs"
      },
      "source": [
        "Podemos ver el porcentaje de pertenencia a cada *topic* de cada una de los documentos asignados por el modelo con el método `transform`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuRqstGCnTjt",
        "outputId": "5e68763e-c033-4ce9-a06b-cf9bc4c09652"
      },
      "source": [
        "lsa.transform(tfidf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.38777878e-16,  1.00000000e+00],\n",
              "       [ 1.96261557e-16,  7.07106781e-01],\n",
              "       [ 0.00000000e+00,  7.07106781e-01],\n",
              "       [ 1.38777878e-16,  1.00000000e+00],\n",
              "       [ 8.66025404e-01, -9.61481343e-17],\n",
              "       [ 8.66025404e-01, -6.40987562e-17],\n",
              "       [ 1.00000000e+00, -1.38777878e-16],\n",
              "       [ 7.07106781e-01, -1.96261557e-16]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mw272PsznTjt"
      },
      "source": [
        "Cada fila corresponde a un documento del Corpus, y cada columna el grado de pertenencia a ese tema del documento.  \n",
        "El modelo ha separado correctamente el corpus en las dos temáticas principales:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5Op-YelnTju",
        "outputId": "3987188e-882a-494f-e656-a8b9601a9c3a"
      },
      "source": [
        "import numpy as np\n",
        "np.argmax(lsa.transform(tfidf), axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT-jX3KynTju"
      },
      "source": [
        "### Modelo LDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEkDKLAvnTju"
      },
      "source": [
        "# usamos características BoW para LDA.\n",
        "tf_vectorizer = CountVectorizer(min_df=2)\n",
        "tf = tf_vectorizer.fit_transform(norm_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBmVYYFQnTjv",
        "outputId": "6f8f5a9b-3c8e-4ab9-b80c-0615cba62aaa"
      },
      "source": [
        "tf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<8x6 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 18 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIf-Zf6WnTjv",
        "outputId": "ef8f55f3-ea3b-426d-8a74-db3893e90013"
      },
      "source": [
        "# Ajustamos el modelo LDA\n",
        "lda = LatentDirichletAllocation(n_components=2, max_iter=5,\n",
        "                                learning_method='batch',\n",
        "                                learning_offset=50.,\n",
        "                                random_state=0).fit(tf)\n",
        "\n",
        "print(\"\\nTopics en modelo LDA:\")\n",
        "tf_feature_names = tf_vectorizer.get_feature_names()\n",
        "print_top_words(lda, tf_feature_names, 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Topics en modelo LDA:\n",
            "Topic #0: dog fox\n",
            "Topic #1: programming language\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeXN68-mnTjw"
      },
      "source": [
        "El atributo `components_` contiene los parámetros de la distribución de términos en *topics*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_2eOIz9nTjw",
        "outputId": "06db1e55-2c55-47b8-c17e-cb8afb3e380e"
      },
      "source": [
        "pd.DataFrame(lda.components_, columns=tfidf_feature_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dog</th>\n",
              "      <th>fox</th>\n",
              "      <th>java</th>\n",
              "      <th>language</th>\n",
              "      <th>programming</th>\n",
              "      <th>python</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.491959</td>\n",
              "      <td>3.491955</td>\n",
              "      <td>0.513787</td>\n",
              "      <td>0.511393</td>\n",
              "      <td>0.511393</td>\n",
              "      <td>0.513756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.508041</td>\n",
              "      <td>0.508045</td>\n",
              "      <td>3.486213</td>\n",
              "      <td>3.488607</td>\n",
              "      <td>3.488607</td>\n",
              "      <td>3.486244</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        dog       fox      java  language  programming    python\n",
              "0  3.491959  3.491955  0.513787  0.511393     0.511393  0.513756\n",
              "1  0.508041  0.508045  3.486213  3.488607     3.488607  3.486244"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFbyqFM8nTjy"
      },
      "source": [
        "Normalizando esta matriz muestra la distribución de términos dentro de cada *topic*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifxw7QybnTjy",
        "outputId": "dfa4873d-d961-466f-ee1e-89aca6bca8b8"
      },
      "source": [
        "distribucion = lda.components_ / lda.components_.sum(axis=1)[:, np.newaxis]\n",
        "pd.DataFrame(distribucion, columns=tfidf_feature_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dog</th>\n",
              "      <th>fox</th>\n",
              "      <th>java</th>\n",
              "      <th>language</th>\n",
              "      <th>programming</th>\n",
              "      <th>python</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.386525</td>\n",
              "      <td>0.386524</td>\n",
              "      <td>0.056871</td>\n",
              "      <td>0.056606</td>\n",
              "      <td>0.056606</td>\n",
              "      <td>0.056868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.033947</td>\n",
              "      <td>0.033947</td>\n",
              "      <td>0.232946</td>\n",
              "      <td>0.233106</td>\n",
              "      <td>0.233106</td>\n",
              "      <td>0.232948</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        dog       fox      java  language  programming    python\n",
              "0  0.386525  0.386524  0.056871  0.056606     0.056606  0.056868\n",
              "1  0.033947  0.033947  0.232946  0.233106     0.233106  0.232948"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsiaNePknTjz"
      },
      "source": [
        "Podemos ver el porcentaje de pertenencia a cada *topic* de cada una de los documentos asignados por el modelo con el método `transform`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeC29IHpnTjz",
        "outputId": "b50bc957-848f-41fd-f275-dce874a36eb6"
      },
      "source": [
        "lda.transform(tf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.8319788 , 0.1680212 ],\n",
              "       [0.74801655, 0.25198345],\n",
              "       [0.74801659, 0.25198341],\n",
              "       [0.8319788 , 0.1680212 ],\n",
              "       [0.1281347 , 0.8718653 ],\n",
              "       [0.12813488, 0.87186512],\n",
              "       [0.1025063 , 0.8974937 ],\n",
              "       [0.17085046, 0.82914954]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuFLRSblnTjz"
      },
      "source": [
        "Los porcentajes de pertenencia suman 1 para los *topics* de cada documento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abLGksfDnTj0",
        "outputId": "7f5b58b3-54c8-4008-a7a5-064abcc1476b"
      },
      "source": [
        "lda.transform(tf).sum(axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CReCVvsxnTj0"
      },
      "source": [
        "El modelo ha asignado correctamente los documentos a las dos temáticas del *corpus*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqSadu9mnTj0",
        "outputId": "bb7ab43c-6cd3-433f-813d-efefeb6bf878"
      },
      "source": [
        "np.argmax(lda.transform(tf), axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60miUeQFnTj1"
      },
      "source": [
        "## Topic modeling usando librería Gensim\n",
        "La librería `gensim` implementa los siguientes modelos:  \n",
        "* [Latent Semantic Indexing, LSI (or sometimes LSA)](https://en.wikipedia.org/wiki/Latent_semantic_indexing) transforms documents from either bag-of-words or (preferrably) TfIdf-weighted space into a latent space of a lower dimensionality.  \n",
        "* [Latent Dirichlet Allocation, LDA](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation) is yet another transformation from bag-of-words counts into a topic space of lower dimensionality. LDA is a probabilistic extension of LSA (also called multinomial PCA), so LDA’s topics can be interpreted as probability distributions over words. These distributions are, just like with LSA, inferred automatically from a training corpus. Documents are in turn interpreted as a (soft) mixture of these topics (again, just like with LSA).  \n",
        "* [Hierarchical Dirichlet Process, HDP](http://jmlr.csail.mit.edu/proceedings/papers/v15/wang11a/wang11a.pdf) is a non-parametric bayesian method (note the missing number of requested topics)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoMn4W7QnTj1"
      },
      "source": [
        "La entrada a los modelos de `gensim`\n",
        " debe ser una lista de tokens y no un texto por cada documento del corpus por lo que hay que cambiar la función de normalización "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01mCxiR9nTj1",
        "outputId": "d8d3d778-3036-4f64-8757-43990f924da1"
      },
      "source": [
        "def normalize_tokenize_document(doc):\n",
        "    # tokenizamos el texto\n",
        "    tokens = nlp(doc)\n",
        "    # quitamos puntuación/espacios y cogemos el lema\n",
        "    lemmas = [t.lemma_.lower() for t in tokens if not t.is_punct and not t.is_space and not t.is_stop]\n",
        "    return lemmas\n",
        "\n",
        "def normalize_tokenize_corpus(corpus):\n",
        "    \"\"\"Normaliza un corpus de documentos aplicando al función de normalización\n",
        "    normalize_tokenize_document() a cada documento de la lista pasada como argumento\"\"\"   \n",
        "    return [normalize_tokenize_document(text) for text in corpus]\n",
        "        \n",
        "norm_tokenized_corpus = normalize_tokenize_corpus(toy_corpus)\n",
        "norm_tokenized_corpus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['fox', 'jump', 'dog'],\n",
              " ['fox', 'clever', 'quick'],\n",
              " ['dog', 'slow', 'lazy'],\n",
              " ['cat', 'smart', 'fox', 'dog'],\n",
              " ['python', 'excellent', 'programming', 'language'],\n",
              " ['java', 'ruby', 'programming', 'language'],\n",
              " ['python', 'java', 'popular', 'programming', 'language'],\n",
              " ['python', 'program', 'small', 'java', 'program']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81fOk1DunTj2"
      },
      "source": [
        "Al igual que en los modelos de la librería `scikit-learn`, primero generamos matrices de características BoW y TF-IDF como paso previo a aplicar los modelos de topic-modeling.  \n",
        "En `gensim` estas matrices se calculan de manera diferente a `scikit-learn`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9OHVNy8nTj2"
      },
      "source": [
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel, TfidfModel\n",
        "\n",
        "#diccionario de términos únicos del corpus\n",
        "dictionary = Dictionary(norm_tokenized_corpus)\n",
        "#creamos matriz BoW\n",
        "corpus_bow = [dictionary.doc2bow(text)\n",
        "                 for text in norm_tokenized_corpus]\n",
        "#creamos matriz TF-IDF del corpus a partir de BoW\n",
        "tfidf = TfidfModel(corpus_bow)\n",
        "corpus_tfidf = tfidf[corpus_bow]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rdr-KXiRnTj3",
        "outputId": "42fed27f-103d-4a44-8d96-4e32690fe2cc"
      },
      "source": [
        "corpus_bow[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 1), (1, 1), (2, 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMbY8ruPnTj3",
        "outputId": "bb2cbdbd-f053-4f43-af2a-9fc4b298ed14"
      },
      "source": [
        "corpus_tfidf[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 0.39239043318859274), (1, 0.39239043318859274), (2, 0.8319011334792957)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXUY0yf_nTj4",
        "outputId": "88669e31-7b3a-4594-ccde-f7ce48a7f449"
      },
      "source": [
        "[(i, k) for i,k in dictionary.items()]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 'dog'),\n",
              " (1, 'fox'),\n",
              " (2, 'jump'),\n",
              " (3, 'clever'),\n",
              " (4, 'quick'),\n",
              " (5, 'lazy'),\n",
              " (6, 'slow'),\n",
              " (7, 'cat'),\n",
              " (8, 'smart'),\n",
              " (9, 'excellent'),\n",
              " (10, 'language'),\n",
              " (11, 'programming'),\n",
              " (12, 'python'),\n",
              " (13, 'java'),\n",
              " (14, 'ruby'),\n",
              " (15, 'popular'),\n",
              " (16, 'program'),\n",
              " (17, 'small')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_SiG4oJnTj4"
      },
      "source": [
        "### Latent Semantic Indexing\n",
        "Los modelos de *topic modeling* de `gensim` asignan un peso de pertenencia de cada término del diccionario bow/tfidf a cada tema:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrLF4qfhnTj4",
        "outputId": "1894518c-a1fd-4844-86e0-7c2ab8b47c27"
      },
      "source": [
        "lsi = LsiModel(corpus_tfidf, \n",
        "                      id2word=dictionary,\n",
        "                      num_topics=2)\n",
        "\n",
        "for index, topic in lsi.print_topics(2):\n",
        "    print('Topic #{}\\n{}\\n'.format(str(index+1), topic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic #1\n",
            "0.459*\"language\" + 0.459*\"programming\" + 0.344*\"python\" + 0.344*\"java\" + 0.336*\"popular\" + 0.318*\"excellent\" + 0.318*\"ruby\" + 0.148*\"program\" + 0.074*\"small\" + -0.000*\"cat\"\n",
            "\n",
            "Topic #2\n",
            "0.459*\"fox\" + 0.459*\"dog\" + 0.444*\"jump\" + 0.322*\"cat\" + 0.322*\"smart\" + 0.208*\"quick\" + 0.208*\"clever\" + 0.208*\"slow\" + 0.208*\"lazy\" + -0.000*\"popular\"\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SOM85iXnTj5",
        "outputId": "93689150-6a02-4dd5-d074-f829e751240e"
      },
      "source": [
        "topics_lsi = lsi[corpus_tfidf]\n",
        "topics_lsi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.interfaces.TransformedCorpus at 0x7f5f49b93ac0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0YgY5FGnTj5"
      },
      "source": [
        "El modelo LSI de `gensim` genera un objeto iterable e indexable con la transformación LSI de todos los documentos del corpus.\\\n",
        "El modelo devuelve una lista de tuplas por cada documento con (*topic_id*, *peso del topic*). El número de tuplas que devuelve es variable para cada documento, sólo devuelve las que tienen mayor importancia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlyOOE2BnTj5",
        "outputId": "c2ab7c7c-51fb-4bd2-def7-b007ad5569bc"
      },
      "source": [
        "topics_lsi[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 0.7296053406305377)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAui7RBXnTj6",
        "outputId": "d71fedb5-76a3-40b7-963f-ddbbbf4292a2"
      },
      "source": [
        "for t in topics_lsi:\n",
        "    print(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(1, 0.7296053406305377)]\n",
            "[(1, 0.4246970606936986)]\n",
            "[(1, 0.4246970606936975)]\n",
            "[(1, 0.6892950729735762)]\n",
            "[(0, 0.7070677687653233)]\n",
            "[(0, 0.7070677687653228)]\n",
            "[(0, 0.7950457769187105)]\n",
            "[(0, 0.29788705652128283)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkP-27oUnTj6"
      },
      "source": [
        "### Latent Dirichlet Allocation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByUBqZCXnTj7",
        "outputId": "bda85f40-b83b-4d6f-d1ea-046668e27f4d"
      },
      "source": [
        "lda = LdaModel(corpus_bow, \n",
        "                      id2word=dictionary,\n",
        "                      iterations=1000,\n",
        "                      num_topics=2)\n",
        "for index, topic in lda.print_topics(2):\n",
        "    print('Topic #{}\\n{}\\n'.format(str(index+1), topic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic #1\n",
            "0.110*\"program\" + 0.098*\"python\" + 0.084*\"fox\" + 0.079*\"dog\" + 0.076*\"java\" + 0.068*\"small\" + 0.056*\"programming\" + 0.055*\"jump\" + 0.051*\"language\" + 0.051*\"excellent\"\n",
            "\n",
            "Topic #2\n",
            "0.105*\"language\" + 0.101*\"programming\" + 0.086*\"java\" + 0.084*\"dog\" + 0.080*\"fox\" + 0.070*\"python\" + 0.051*\"ruby\" + 0.051*\"popular\" + 0.048*\"lazy\" + 0.046*\"slow\"\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45piq7oLnTj7",
        "outputId": "7d6d2c4c-28b3-4b99-cc4b-6c4a8ba0a253"
      },
      "source": [
        "topics_lda = lda[corpus_bow]\n",
        "topics_lda"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.interfaces.TransformedCorpus at 0x7f5f48f478e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot7sJv-_nTj8",
        "outputId": "678242b2-a3ae-452b-d124-50b9df5bcdf7"
      },
      "source": [
        "topics_lda[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 0.77280724), (1, 0.22719279)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cN74cySHnTj8"
      },
      "source": [
        "### Hierarchical Dirichlet Process\n",
        "En este modelo no se especifica un número de *topics*. El modelo ajusta tantos *topics* como documentos y los ordena por importancia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sI02FZpnTj8",
        "outputId": "69fcba3b-b95b-4471-aafe-326e4b30831c"
      },
      "source": [
        "#no hay que especificar un núm. de topics\n",
        "hdp = HdpModel(corpus_bow, \n",
        "                      id2word=dictionary)\n",
        "for index, topic in hdp.print_topics(2):\n",
        "    print('Topic #{}\\n{}\\n'.format(str(index+1), topic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic #1\n",
            "0.181*quick + 0.159*program + 0.116*lazy + 0.105*smart + 0.077*cat + 0.068*jump + 0.051*python + 0.050*clever + 0.031*small + 0.030*excellent\n",
            "\n",
            "Topic #2\n",
            "0.281*lazy + 0.095*cat + 0.085*excellent + 0.080*slow + 0.067*programming + 0.064*ruby + 0.047*language + 0.045*small + 0.044*dog + 0.039*popular\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my_g-lzrnTj9"
      },
      "source": [
        "Si especificamos un total de 2 topics, las palabras que contribuyen a cada uno de ellos son las que aparecen detalladas, y el valor asociado a cada una es lo 'fuertemente' que está relacionada esa palabra con dicho topic"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aJM61nQnTj9",
        "outputId": "36b76527-ffcc-4cef-ff5e-261a481a6bd8"
      },
      "source": [
        "for index, topic in hdp.print_topics(4):\n",
        "    print('Topic #{}\\n{}\\n'.format(str(index+1), topic))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic #1\n",
            "0.181*quick + 0.159*program + 0.116*lazy + 0.105*smart + 0.077*cat + 0.068*jump + 0.051*python + 0.050*clever + 0.031*small + 0.030*excellent\n",
            "\n",
            "Topic #2\n",
            "0.281*lazy + 0.095*cat + 0.085*excellent + 0.080*slow + 0.067*programming + 0.064*ruby + 0.047*language + 0.045*small + 0.044*dog + 0.039*popular\n",
            "\n",
            "Topic #3\n",
            "0.154*fox + 0.104*python + 0.088*ruby + 0.081*programming + 0.076*cat + 0.075*popular + 0.071*dog + 0.064*small + 0.064*program + 0.039*lazy\n",
            "\n",
            "Topic #4\n",
            "0.268*cat + 0.140*jump + 0.087*programming + 0.082*java + 0.079*fox + 0.078*smart + 0.050*language + 0.046*clever + 0.043*quick + 0.032*program\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziiR2G73nTj_",
        "outputId": "d0bbf40c-ef8b-4f36-8763-d5fe7d0b3ddd"
      },
      "source": [
        "topics_hdp = hdp[corpus_bow]\n",
        "topics_hdp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.interfaces.TransformedCorpus at 0x7f5f49b93b80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xV9OP6eVnTj_"
      },
      "source": [
        "El modelo HDP sólo devuelve para cada documentos los *topics* que tienen mayor relavancia en su composición:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNDgiIgtnTkA",
        "outputId": "8ac49f86-a1b2-4ee5-f442-48f74ade5ae1"
      },
      "source": [
        "for t in topics_hdp:\n",
        "    print(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 0.07328190139955858), (1, 0.04901361450713037), (2, 0.7788827828216391), (3, 0.0266230207447064), (4, 0.019599164793479312), (5, 0.01431472544131097), (6, 0.010532653366491408)]\n",
            "[(0, 0.8153515946759589), (1, 0.04892964010977624), (2, 0.036905019164293784), (3, 0.026615294101975724), (4, 0.0195989416136308), (5, 0.0143147200338518), (6, 0.0105326533748281)]\n",
            "[(0, 0.06779468503778084), (1, 0.7968696132183295), (2, 0.036540245686808095), (3, 0.026597042226215582), (4, 0.019598907745612522), (5, 0.014314715788214399), (6, 0.01053265337135506)]\n",
            "[(0, 0.2437520393219116), (1, 0.03971087621308347), (2, 0.6374819252498064), (3, 0.021296439175269695), (4, 0.01567911530026445), (5, 0.011451772505553515)]\n",
            "[(0, 0.05590578030123453), (1, 0.835713186765757), (2, 0.029337026488526097), (3, 0.021285135779718606), (4, 0.015679266722736486), (5, 0.011451771708803)]\n",
            "[(0, 0.30814273002078396), (1, 0.5833163467359885), (2, 0.029460601384669927), (3, 0.021320576952027725), (4, 0.015680129498551208), (5, 0.011451783168382412)]\n",
            "[(0, 0.045585641724828735), (1, 0.03330554218520961), (2, 0.8552308853894866), (3, 0.01774507376761183), (4, 0.013066517782089117)]\n",
            "[(0, 0.8769253848965434), (1, 0.03277124497393775), (2, 0.024432533369233504), (3, 0.017738427058250184), (4, 0.013066072734545662)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HwvpCBxnTkA"
      },
      "source": [
        "### Estimación de temática principal\n",
        "Podemos calcular la pertenencia de cada documento a una temática mayoritaria a partir de su modelo calculado, cogiendo la primera tupla devuelta por el modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nu5t3smSnTkA",
        "outputId": "ec4f3699-5c7f-4d97-c524-ed235fc2e0fa"
      },
      "source": [
        "corpus_lsi = lsi[corpus_tfidf]\n",
        "for i, doc in enumerate(corpus_lsi):\n",
        "     print(doc, toy_corpus[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(1, 0.7296053406305377)] The fox jumps over the dog\n",
            "[(1, 0.4246970606936986)] the fox is very clever and quick\n",
            "[(1, 0.4246970606936975)] The dog is slow and lazy\n",
            "[(1, 0.6892950729735762)] The cat is smarter than the fox and the dog\n",
            "[(0, 0.7070677687653233)] Python is an excellent programming language\n",
            "[(0, 0.7070677687653228)] Java and Ruby are other programming languages\n",
            "[(0, 0.7950457769187105)] Python and Java are very popular programming languages\n",
            "[(0, 0.29788705652128283)] Python programs are smaller than Java programs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9nQyu5nnTkB"
      },
      "source": [
        "Cada modelo guarda internamente los pesos que otorga a cada término en cada temática"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtHQTfAsnTkB",
        "outputId": "d6e011c8-de6d-4603-acb4-13c63e44fa49"
      },
      "source": [
        "lsi.get_topics().shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUBVM21anTkB",
        "outputId": "2d1eaa41-30fa-4469-b5af-90feaa94fe3d"
      },
      "source": [
        "len([t for t in dictionary.values()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TH5S7M_bnTkB",
        "outputId": "3452b66e-579f-4e96-8b1a-d494d79dc48c"
      },
      "source": [
        "lsi.get_topics()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.00000000e+00, -8.32667268e-17,  5.55111512e-17,\n",
              "         5.04457587e-15,  4.94743135e-15,  5.32907052e-15,\n",
              "         5.24580379e-15, -5.45397061e-15, -5.34294831e-15,\n",
              "         3.18217601e-01,  4.58720976e-01,  4.58720976e-01,\n",
              "         3.43618045e-01,  3.43618045e-01,  3.18217601e-01,\n",
              "         3.36092332e-01,  1.48379168e-01,  7.41895838e-02],\n",
              "       [ 4.59433532e-01,  4.59433532e-01,  4.43623263e-01,\n",
              "         2.08216334e-01,  2.08216334e-01,  2.08216334e-01,\n",
              "         2.08216334e-01,  3.22198614e-01,  3.22198614e-01,\n",
              "        -1.11022302e-16, -4.44089210e-16, -4.44089210e-16,\n",
              "        -2.56739074e-16, -4.30211422e-16, -4.16333634e-16,\n",
              "        -4.51028104e-16, -1.11022302e-16, -5.55111512e-17]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PUJc4nrnTkC",
        "outputId": "148885ed-5ec6-4fda-b3b9-aed7f3977029"
      },
      "source": [
        "corpus_lda = lda[corpus_bow]\n",
        "for i, doc in enumerate(corpus_lda):\n",
        "     print(doc, toy_corpus[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 0.7727445), (1, 0.22725552)] The fox jumps over the dog\n",
            "[(0, 0.19212334), (1, 0.80787665)] the fox is very clever and quick\n",
            "[(0, 0.16202964), (1, 0.8379703)] The dog is slow and lazy\n",
            "[(0, 0.16993101), (1, 0.83006895)] The cat is smarter than the fox and the dog\n",
            "[(0, 0.21532944), (1, 0.78467053)] Python is an excellent programming language\n",
            "[(0, 0.11891045), (1, 0.88108957)] Java and Ruby are other programming languages\n",
            "[(0, 0.112972006), (1, 0.887028)] Python and Java are very popular programming languages\n",
            "[(0, 0.9002772), (1, 0.09972281)] Python programs are smaller than Java programs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRcukechnTkC"
      },
      "source": [
        "Los números asociados a cada frase en la celda de arriba indican las probabilidades de que cada frase trate de cada uno de los topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybWnz_uenTkD",
        "outputId": "f038655b-8998-4cba-aef2-ca1ed63a6123"
      },
      "source": [
        "lda.get_topics().shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "audGywT4nTkD",
        "outputId": "b5b58a4b-a2ed-43b9-c3fb-700e8b792294"
      },
      "source": [
        "lda.get_topics()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.07886329, 0.08364438, 0.05513915, 0.03610821, 0.03890279,\n",
              "        0.03175268, 0.03422564, 0.0381352 , 0.03980745, 0.05077701,\n",
              "        0.05129281, 0.05553823, 0.09764033, 0.07588366, 0.02718895,\n",
              "        0.02767461, 0.1096984 , 0.06772716],\n",
              "       [0.08372255, 0.08011434, 0.03000719, 0.0443695 , 0.04226045,\n",
              "        0.04765654, 0.04579025, 0.04283974, 0.04157775, 0.03329921,\n",
              "        0.1045295 , 0.10132551, 0.06955191, 0.08597127, 0.05110073,\n",
              "        0.05073421, 0.02464205, 0.02050728]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wc4aUhf3nTkD"
      },
      "source": [
        "En el modelo LDA, los pesos de cada término en un *topic* es su probabilidad de pertenencia, por lo que la suma de todos los pesos por *topic* es 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkCIpnPfnTkE",
        "outputId": "c19e6c24-9dd9-442b-f5b2-f7854d37f51b"
      },
      "source": [
        "np.sum(lda.get_topics(), axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 0.99999994], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH09vp9_nTkE"
      },
      "source": [
        "Con el modelo HDP no se especifica un número de temas sino que se definen automáticamente (con importancia decreciente)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjxpXO6SnTkE",
        "outputId": "07ca47bf-054b-4c08-a992-27e944369b0f"
      },
      "source": [
        "# Solución\n",
        "corpus_hdp = hdp[corpus_bow]\n",
        "for i, doc in enumerate(corpus_hdp):\n",
        "     print(doc, toy_corpus[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 0.07328190139955858), (1, 0.04901361450713037), (2, 0.7788827828216391), (3, 0.0266230207447064), (4, 0.019599164793479312), (5, 0.01431472544131097), (6, 0.010532653366491408)] The fox jumps over the dog\n",
            "[(0, 0.8153515946759589), (1, 0.04892964010977624), (2, 0.036905019164293784), (3, 0.026615294101975724), (4, 0.0195989416136308), (5, 0.0143147200338518), (6, 0.0105326533748281)] the fox is very clever and quick\n",
            "[(0, 0.06779468503778084), (1, 0.7968696132183295), (2, 0.036540245686808095), (3, 0.026597042226215582), (4, 0.019598907745612522), (5, 0.014314715788214399), (6, 0.01053265337135506)] The dog is slow and lazy\n",
            "[(0, 0.2437520393219116), (1, 0.03971087621308347), (2, 0.6374819252498064), (3, 0.021296439175269695), (4, 0.01567911530026445), (5, 0.011451772505553515)] The cat is smarter than the fox and the dog\n",
            "[(0, 0.05590578030123453), (1, 0.835713186765757), (2, 0.029337026488526097), (3, 0.021285135779718606), (4, 0.015679266722736486), (5, 0.011451771708803)] Python is an excellent programming language\n",
            "[(0, 0.30814273002078396), (1, 0.5833163467359885), (2, 0.029460601384669927), (3, 0.021320576952027725), (4, 0.015680129498551208), (5, 0.011451783168382412)] Java and Ruby are other programming languages\n",
            "[(0, 0.045585641724828735), (1, 0.03330554218520961), (2, 0.8552308853894866), (3, 0.01774507376761183), (4, 0.013066517782089117)] Python and Java are very popular programming languages\n",
            "[(0, 0.8769253848965434), (1, 0.03277124497393775), (2, 0.024432533369233504), (3, 0.017738427058250184), (4, 0.013066072734545662)] Python programs are smaller than Java programs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vvsZlm5nTkE",
        "outputId": "75f8d45e-e939-461e-fe8b-9c0ab558d660"
      },
      "source": [
        "hdp.get_topics().shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0XhBUkqnTkF"
      },
      "source": [
        "Podemos obtener los términos relevantes para cada tema y su importancia con el métoo `show_topics` del modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE26H-6vnTkF"
      },
      "source": [
        "lsitopics = [[(word,prob) for word, prob in topic] for topicid, topic in lsi.show_topics(formatted=False)]\n",
        "\n",
        "hdptopics = [[(word,prob) for word, prob in topic] for topicid, topic in hdp.show_topics(formatted=False)]\n",
        "\n",
        "ldatopics = [[(word,prob) for word, prob in topic] for topicid, topic in lda.show_topics(formatted=False)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "439y8KfenTkF",
        "outputId": "d4ccf239-64df-4268-e5ed-ab6268d3464c"
      },
      "source": [
        "ldatopics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('program', 0.1096984),\n",
              "  ('python', 0.09764033),\n",
              "  ('fox', 0.083644375),\n",
              "  ('dog', 0.07886329),\n",
              "  ('java', 0.075883664),\n",
              "  ('small', 0.06772716),\n",
              "  ('programming', 0.05553823),\n",
              "  ('jump', 0.055139154),\n",
              "  ('language', 0.05129281),\n",
              "  ('excellent', 0.050777014)],\n",
              " [('language', 0.1045295),\n",
              "  ('programming', 0.10132551),\n",
              "  ('java', 0.085971266),\n",
              "  ('dog', 0.08372255),\n",
              "  ('fox', 0.08011434),\n",
              "  ('python', 0.069551915),\n",
              "  ('ruby', 0.05110073),\n",
              "  ('popular', 0.050734207),\n",
              "  ('lazy', 0.047656536),\n",
              "  ('slow', 0.045790248)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntip00SfnTkG"
      },
      "source": [
        "### Topic Coherence\n",
        "La librería `gensim` proporciona una funcionalidad para identificar qué modelo de *topic modeling* se adapta mejor al corpus. La función `CoherenceModel` calcula una puntuación sobre la coherencia del modelo, que podemos usar para compararlos. Esta función utiliza las palabras que definen cada tópico en los modelos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKytkbPunTkG"
      },
      "source": [
        "lsitopics = [[word for word, prob in topic] for topicid, topic in lsi.show_topics(formatted=False)]\n",
        "\n",
        "hdptopics = [[word for word, prob in topic] for topicid, topic in hdp.show_topics(formatted=False)]\n",
        "\n",
        "ldatopics = [[word for word, prob in topic] for topicid, topic in lda.show_topics(formatted=False)]\n",
        "\n",
        "\n",
        "lsi_coherence = CoherenceModel(topics=lsitopics[:10], texts=norm_tokenized_corpus,\n",
        "                               dictionary=dictionary, window_size=10).get_coherence()\n",
        "\n",
        "hdp_coherence = CoherenceModel(topics=hdptopics[:10], texts=norm_tokenized_corpus, \n",
        "                               dictionary=dictionary, window_size=10).get_coherence()\n",
        "\n",
        "lda_coherence = CoherenceModel(topics=ldatopics, texts=norm_tokenized_corpus,\n",
        "                               dictionary=dictionary, window_size=10).get_coherence()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UTbyLt0nTkG"
      },
      "source": [
        "lsi_coherence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ButzTe_XnTkH"
      },
      "source": [
        "def evaluate_bar_graph(coherences, indices):\n",
        "    \"\"\"\n",
        "    Función para dibujar una gráfica de barras con:\n",
        "    \n",
        "    coherences: lista de los valores de coherencia\n",
        "    indices: textos para etiquetar las barras.\n",
        "    Ambos parámetros deben tener la misma longitud\n",
        "    \"\"\"\n",
        "    assert len(coherences) == len(indices)\n",
        "    n = len(coherences)\n",
        "    x = np.arange(n)\n",
        "    plt.bar(x, coherences, width=0.2, tick_label=indices, align='center')\n",
        "    plt.xlabel('Modelos')\n",
        "    plt.ylabel('Valor Coherencia')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CZ3V8cJnTkH"
      },
      "source": [
        "evaluate_bar_graph([lsi_coherence, hdp_coherence, lda_coherence],\n",
        "                   ['LSI', 'HDP', 'LDA'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}