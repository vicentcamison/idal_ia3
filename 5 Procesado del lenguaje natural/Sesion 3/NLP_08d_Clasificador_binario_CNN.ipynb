{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "NLP_08d-Clasificador binario-CNN.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vicentcamison/idal_ia3/blob/main/5%20Procesado%20del%20lenguaje%20natural/Sesion%203/NLP_08d_Clasificador_binario_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isRWjj7km1X-"
      },
      "source": [
        "# Clasificador de texto con CNN\n",
        "Implementemos un clasificador con Convolutional Neural Networks aplicado al an√°lisis de sentimiento en Twitter usando la librer√≠a `Keras`.  \n",
        "Aplicamos una primera capa de embeddings para convertir las palabras en vectores y luego entrenamos con una red CNN (seleccionando el max-pooling de cada filtro para obtener un vector por tweet).  \n",
        "Para calcular los embeddings usamos:  \n",
        "- Una capa de embeddings propia sobre los tweets\n",
        "- Transfer Learning con los word embeddings de spaCy \n",
        "- Transfer Learning con los word embeddings de GloVe \n",
        "\n",
        "Implementado seg√∫n el modelo planteado en [Convolutional Neural Networks for Sentence Classification](http://arxiv.org/abs/1408.5882)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_XfbTx05-L2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43cf49ad-2332-40f4-cfad-1a3182f4690c"
      },
      "source": [
        "#(ejecutar esto s√≥lo si est√°s en Colab)\n",
        "!python -m spacy download es_core_news_md"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: es_core_news_md==2.2.5 from https://github.com/explosion/spacy-models/releases/download/es_core_news_md-2.2.5/es_core_news_md-2.2.5.tar.gz#egg=es_core_news_md==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from es_core_news_md==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_md==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_md==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_md==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_md==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_md==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_md==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_md==2.2.5) (57.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_md==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_md==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_md==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_md==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->es_core_news_md==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_md==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_md==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_md==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->es_core_news_md==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_md==2.2.5) (4.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_md==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->es_core_news_md==2.2.5) (3.4.1)\n",
            "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('es_core_news_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6FUfyh-m1YK"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re, string, spacy\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Dropout, Activation, Conv1D, GlobalMaxPooling1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "pd.options.display.max_colwidth = None\n",
        "np.random.seed(123)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ke3qQOSFm1YN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "f6a04d70-d774-4037-9757-520db24344e9"
      },
      "source": [
        "# Leemos los datos\n",
        "#LOCAL:\n",
        "#df = pd.read_csv('tweets_all.csv', index_col=None)\n",
        "#GITHUB:\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/vicentcamison/idal_ia3/main/5%20Procesado%20del%20lenguaje%20natural/Sesion%203/tweets_all.csv', index_col=None)\n",
        "\n",
        "#seleccionamos columnas de inter√©s\n",
        "df = df[['content', 'polarity']]\n",
        "\n",
        "#dejamos polaridades definidas\n",
        "df = df[(df['polarity']=='P') | (df['polarity']=='N')]\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@myendlesshazza a. que puto mal escribo\\n\\nb. me sigo surrando help \\n\\n3. ha quedado raro el \"c√≥metelo\" ah√≠ JAJAJAJA</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@estherct209 jajajaja la tuya y la d mucha gente seguro!! Pero yo no puedo sin mi melena me muero</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Quiero mogoll√≥n a @AlbaBenito99 pero sobretodo por lo r√°pido que contesta a los wasaps</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Vale he visto la tia bebiendose su regla y me hs dado muchs grima</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>@Yulian_Poe @guillermoterry1 Ah. mucho m√°s por supuesto! solo que lo incluyo. Me hab√≠as entendido mal</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                 content polarity\n",
              "1  @myendlesshazza a. que puto mal escribo\\n\\nb. me sigo surrando help \\n\\n3. ha quedado raro el \"c√≥metelo\" ah√≠ JAJAJAJA        N\n",
              "2                     @estherct209 jajajaja la tuya y la d mucha gente seguro!! Pero yo no puedo sin mi melena me muero         N\n",
              "3                                Quiero mogoll√≥n a @AlbaBenito99 pero sobretodo por lo r√°pido que contesta a los wasaps         P\n",
              "4                                                     Vale he visto la tia bebiendose su regla y me hs dado muchs grima         N\n",
              "5                 @Yulian_Poe @guillermoterry1 Ah. mucho m√°s por supuesto! solo que lo incluyo. Me hab√≠as entendido mal         P"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYzV9CwTm1YS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39be69eb-70bd-449a-d40f-11e146f4f213"
      },
      "source": [
        "df.polarity.value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "N    637\n",
              "P    474\n",
              "Name: polarity, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHvSoL1em1YU"
      },
      "source": [
        "## Limpieza de texto\n",
        "Usamos Spacy para separar el texto en tokens y mantener s√≥lo las palabras importantes, dejando su lemma"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrqsNoVtm1YU"
      },
      "source": [
        "import re, string, spacy\n",
        "nlp=spacy.load('es_core_news_md')\n",
        "\n",
        "pattern2 = re.compile('[{}]'.format(re.escape(string.punctuation))) #elimina s√≠mbolos de puntuaci√≥n\n",
        "\n",
        "def clean_text(text, lemas=False):\n",
        "    \"\"\"Limpiamos las menciones y URL del texto. Luego convertimos en tokens\n",
        "    y eliminamos signos de puntuaci√≥n.\n",
        "    Si lemas=True extraemos el lema, si no dejamos en min√∫sculas solamente.\n",
        "    Como salida volvemos a convertir los tokens en cadena de texto\"\"\"\n",
        "    text = re.sub(r'@[\\w_]+|https?://[\\w_./]+', '', text) #elimina menciones y URL\n",
        "    tokens = nlp(text)\n",
        "    tokens = [tok.lemma_.lower() if lemas else tok.lower_ for tok in tokens if not tok.is_punct]\n",
        "    filtered_tokens = [pattern2.sub('', tok) for tok in tokens] #no quitamos stop-words\n",
        "    filtered_text = ' '.join(filtered_tokens)\n",
        "    \n",
        "    return filtered_text\n",
        "    "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bV-9QfvLm1YV"
      },
      "source": [
        "## Preparamos el conjunto de datos\n",
        "Convertimos el texto en *tokens* y asignamos una ID num√©rica a cada token.  \n",
        "Convertimos a secuencias de longitud fija.  \n",
        "La longitud de la secuencia viene dada por la longitud en tokens del tweet m√°s largo. S√≥lo se conservan los tokens de las palabras en el vocabulario."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kmts0-j9m1YW"
      },
      "source": [
        "#limpiamos texto y quitamos tweets que se han quedado vac√≠os\n",
        "df.content=df.content.apply(clean_text, lemas=True)\n",
        "df = df[df['content']!='']\n",
        "\n",
        "#el conjunto de salida es la polaridad, hay que convertir a num√©rico para Keras\n",
        "#codificamos 'P' como 1 y 'N' se queda como 0\n",
        "Y=(df.polarity=='P').values*1\n",
        "\n",
        "#Separamos entrenamiento y test\n",
        "tweets_train, tweets_test, Y_train, Y_test = train_test_split(df.content,Y, test_size = 0.3, random_state = 42)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFP8pygCm1YX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c14fbc43-9f31-4c84-cca9-cd96a180b20c"
      },
      "source": [
        "tokenizer = Tokenizer(split=' ')\n",
        "tokenizer.fit_on_texts(tweets_train.values)\n",
        "X_train = tokenizer.texts_to_sequences(tweets_train.values)\n",
        "X_train = pad_sequences(X_train, padding='post')\n",
        "word_index = tokenizer.word_index\n",
        "print(f'N√∫mero de tokens distintos: {len(word_index)}')\n",
        "MAX_SEQUENCE_LENGTH = X_train.shape[1]\n",
        "max_features = len(word_index)+1\n",
        "X_test = tokenizer.texts_to_sequences(tweets_test.values)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=MAX_SEQUENCE_LENGTH)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N√∫mero de tokens distintos: 2606\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M0Qzcum5s-3",
        "outputId": "d11b5e38-9be9-43ea-b9f9-ab5a72d221bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Este es el diccionario de tokens que se ha creado al aplicar el tokenizer\n",
        "print(tokenizer.word_index)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'que': 1, 'de': 2, 'ser': 3, 'lo': 4, 'el': 5, 'y': 6, 'no': 7, 'a': 8, 'me': 9, 'uno': 10, 'en': 11, 'haber': 12, 'tener': 13, 'pero': 14, 'estar': 15, 'mi': 16, 'por': 17, 'se': 18, 'yo': 19, 'los': 20, 'ya': 21, 'ir': 22, 'te': 23, 'con': 24, 'poder': 25, 'hacer': 26, 'parir': 27, 'todo': 28, 'bueno': 29, 'ver': 30, 'este': 31, 'si': 32, 'muy': 33, 'ese': 34, 'comer': 35, 'al': 36, 'porque': 37, 'del': 38, 'mucho': 39, 'decir': 40, 'm√°s': 41, 'd√≠a': 42, 'o': 43, 'poner': 44, 'coser': 45, 'solo': 46, 'dar': 47, 'cuando': 48, 'su': 49, 'mejor': 50, 'pasar': 51, 'gracia': 52, 'tu': 53, 'querer': 54, 'tan': 55, 'asir': 56, 'gente': 57, 'salir': 58, 'le': 59, 'bien': 60, 'vez': 61, 'qu√©': 62, 'algo': 63, 'otro': 64, 'nadar': 65, 'mismo': 66, 'ahora': 67, 'mal': 68, 'feliz': 69, 'hoy': 70, 'malo': 71, 'q': 72, 'es': 73, 'saber': 74, 'poco': 75, 'seguir': 76, 'pues': 77, 'menos': 78, 'gran': 79, 'volver': 80, 'dejar': 81, 'dormir': 82, 'hora': 83, 'bonito': 84, 't√∫': 85, 'genial': 86, 'vida': 87, 'gustar': 88, 'sin': 89, 'a√±o': 90, 'ma√±ana': 91, 'gracias': 92, 'casar': 93, 'tiempo': 94, 'jugar': 95, 'verdad': 96, 'noche': 97, 'puto': 98, 'creer': 99, 'acabar': 100, 'nuevo': 101, 's√≠': 102, 'esperar': 103, 'un': 104, 'llegar': 105, 'ni': 106, 'hasta': 107, 'la': 108, 'venir': 109, 'hablar': 110, 'siempre': 111, 'tambi√©n': 112, 'grande': 113, 'do': 114, 'triste': 115, 'leer': 116, 'desde': 117, 'quedar': 118, 'parecer': 119, 'verano': 120, 'antes': 121, 'aun': 122, '√©l': 123, 'aqu√≠': 124, 'peque√±o': 125, 'hola': 126, 'sentir': 127, 'aunque': 128, 'trabajar': 129, 'tanto': 130, 'entrar': 131, 'peor': 132, 'tio': 133, 'mas': 134, 'semana': 135, 'vestir': 136, 'ganar': 137, 'encontrar': 138, 'chico': 139, 'primero': 140, 'conocer': 141, 'sobrar': 142, 'espero': 143, 'llevar': 144, 'foto': 145, 'subir': 146, 'precioso': 147, 'personar': 148, 'tranquilo': 149, 'empezar': 150, '2': 151, 'tengo': 152, 'seriar': 153, 'partir': 154, 'casi': 155, 'cambiar': 156, 'mundo': 157, 'm√≠': 158, 'escuchar': 159, 'amigo': 160, 'madrid': 161, 'üòÇ': 162, 'besitos': 163, 'desear': 164, 'nuestro': 165, 'unir': 166, 'mejorar': 167, 'tardar': 168, 'ti': 169, 'caro': 170, 'odiar': 171, 'quiero': 172, 'valer': 173, 'encantar': 174, 'luego': 175, 'bastante': 176, 'encimar': 177, 'raro': 178, 'final': 179, 'fiesta': 180, 'seguro': 181, 'quedo': 182, 'k': 183, 'morir': 184, 'echar': 185, 'contar': 186, 'nunca': 187, 'ja': 188, 'escribir': 189, 'suerte': 190, 'valencia': 191, 'joder': 192, 'jajajaja': 193, 'felicidad': 194, 'durar': 195, 'normal': 196, 'alguien': 197, 'mierda': 198, '3': 199, 'tal': 200, 'tampoco': 201, 'nadie': 202, 'c√≥mo': 203, 'cada': 204, '5': 205, 't√≠o': 206, 'claro': 207, 'fin': 208, 'llorar': 209, 'para': 210, 'penar': 211, 'pensar': 212, 'jaja': 213, 'ni√±o': 214, 'igual': 215, 'perro': 216, 'maravilloso': 217, 'jajaja': 218, 'ojal√°': 219, 'social': 220, 'amor': 221, 'nosotros': 222, 'feo': 223, 'pelar': 224, 'entender': 225, '√∫nico': 226, 'eh': 227, 'pa': 228, 'conmigo': 229, 'd': 230, 'pobre': 231, 'justar': 232, 'cumplea√±os': 233, 'pagar': 234, 'como': 235, 'guay': 236, 'mirar': 237, 'hemo': 238, 'perfecto': 239, 'ah√≠': 240, 'alguno': 241, 'ideo': 242, '1': 243, 'so√±ar': 244, 'temporada': 245, 'estoy': 246, 'abrir': 247, 'v√≠deo': 248, 'paso': 249, 'merecer': 250, '\\ufeff1': 251, 'madre': 252, 'ellos': 253, 'levantar': 254, 'temer': 255, 'formar': 256, 'clase': 257, 'soler': 258, 'cierto': 259, 'amigar': 260, 'preguntar': 261, 'aburrir': 262, 'vosotros': 263, 'muchas': 264, 'much√≠simo': 265, 'ayudar': 266, 'meter': 267, 'hacerlo': 268, 'mensaje': 269, 'hacia': 270, 'vivir': 271, 'septiembre': 272, 'pr√≥ximo': 273, 'necesitar': 274, 'haz': 275, 'soy': 276, 'regalar': 277, 'demasiar': 278, 'ninguno': 279, 'comprar': 280, 'recordar': 281, 'abrazar': 282, '4': 283, 'familia': 284, 'personaje': 285, 'padre': 286, 'tweet': 287, 'propio': 288, '√∫ltimo': 289, 'despu√©s': 290, 'doler': 291, 'largar': 292, 'ah': 293, 'librar': 294, 'quien': 295, 'ingl√©s': 296, 'donde': 297, 'vamos': 298, 'segundar': 299, 'imaginar': 300, 'esto': 301, 'alegrar': 302, 'buenos': 303, 'libro': 304, 'pokemon': 305, 'cap√≠tulo': 306, 'ba√±ar': 307, 'cagar': 308, 'espalda': 309, 'gracioso': 310, 'pel√≠cula': 311, 'hermano': 312, 'realidad': 313, 'buen': 314, 'quitar': 315, 'pronto': 316, 'terminar': 317, 'les': 318, 'darle': 319, 'callar': 320, 'hijo': 321, 'adem√°s': 322, 'compa√±ero': 323, 'contigo': 324, 'directo': 325, 'nombrar': 326, 'mesar': 327, 'mandar': 328, 'tres': 329, 'as√≠': 330, 'favor': 331, 'pesar': 332, 'deber': 333, 'tuyo': 334, 'favorito': 335, 'gobierno': 336, 'representar': 337, 'p√°gina': 338, 'poquito': 339, 'mil': 340, 'verlo': 341, 'tonto': 342, '‚ù§': 343, 'tocar': 344, 'problema': 345, 'viejo': 346, 'junto': 347, 'lado': 348, 'alternativo': 349, 'tambien': 350, 'sad': 351, 'momento': 352, 'miedo': 353, 'resultar': 354, 'cansar': 355, 'especial': 356, 'tw': 357, 'andar': 358, 'notar': 359, 'vacaci√≥n': 360, 'estudiar': 361, 'nos': 362, 'estupendo': 363, 'capaz': 364, 'asi': 365, 'vender': 366, 'f√°cil': 367, 'plan': 368, 'voz': 369, 'doblar': 370, 'rt': 371, '2017': 372, 'cenar': 373, 'he': 374, 'enamorar': 375, 'bello': 376, 'eres': 377, 'cultura': 378, 'negro': 379, 'otra': 380, 'b': 381, 'verdadero': 382, 'ejemplo': 383, 'acabo': 384, 'compartir': 385, 'desagradable': 386, 'estable': 387, 'tirar': 388, 'mutuo': 389, 'cu√°ndo': 390, 'enga√±ar': 391, 't': 392, 'litro': 393, 'salud': 394, 'imposible': 395, 'humor': 396, 'insultar': 397, 'educaci√≥n': 398, 'montar': 399, 'hableconellas': 400, 'entrevistar': 401, 'sortear': 402, 'super': 403, 'galo': 404, 'sevilla': 405, 'espa√±a': 406, 'dia': 407, 'cruel': 408, 'dias': 409, 'faltar': 410, 'cine': 411, 'usar': 412, 'falto': 413, 'entrenar': 414, 'cumplir': 415, 'saludos': 416, 'diferente': 417, 'opini√≥n': 418, 'üòò': 419, 'fan': 420, 'chino': 421, 'artista': 422, '√°nimo': 423, 'rajoy': 424, 'duro': 425, 'manir': 426, 'una': 427, 'pasear': 428, 'mes': 429, 'i': 430, 'sorpresa': 431, 'culpar': 432, 'hay': 433, 'muerte': 434, 'wifi': 435, 'cama': 436, 'bienvenido': 437, 'link': 438, 'existir': 439, 'izquierdo': 440, 'rotar': 441, 'ideal': 442, 'ke': 443, 'inteligente': 444, 'viajar': 445, 'canal': 446, 'e': 447, 'llamar': 448, 'estrenar': 449, 'all√≠': 450, 'pie': 451, 'm√≥vil': 452, 'loco': 453, 'r√°pido': 454, 'abandonar': 455, 'aquel': 456, 'post': 457, 'mediar': 458, 'entonces': 459, 'rayar': 460, 'pedir': 461, 'edici√≥n': 462, 'amar': 463, 'horrible': 464, 'cutre': 465, 'ponerme': 466, 'rollo': 467, 'largo': 468, 'interesante': 469, 'calor': 470, 'mar': 471, 's√≥lo': 472, 'fe': 473, 'aqui': 474, 'olvidar': 475, 'avisar': 476, 'twitter': 477, 'desgraciar': 478, 'decirme': 479, 'porqu√©': 480, 'm√©dico': 481, 'caer': 482, 'permitir': 483, 'hombre': 484, 'buscar': 485, 'üòÄ': 486, 'comenzar': 487, 'coger': 488, 'sino': 489, 'da√±ar': 490, 'culo': 491, 'pantal√≥n': 492, 'construir': 493, 'cl√°sico': 494, 'mola': 495, 'importante': 496, 'valor': 497, 'aportar': 498, 'curro': 499, 'edificio': 500, 'facil': 501, 'luis': 502, 'ayer': 503, 'cosplay': 504, 'the': 505, '100': 506, 'mosca': 507, 'cualquiera': 508, 'apagar': 509, 'luz': 510, 'pos': 511, 'disfrutar': 512, 'descubrir': 513, 'der': 514, 'pr√°ctico': 515, 'vomitar': 516, 'poblar': 517, '√©s': 518, 'gravar': 519, 'etc√©tera': 520, 'cancelar': 521, 'capullo': 522, 'respetar': 523, 'web': 524, 'funcionar': 525, 'ministerio': 526, 'boca': 527, 'tragar': 528, 'par': 529, 'ha': 530, 'visitar': 531, 'pasarlo': 532, 'eso': 533, 'intentar': 534, 'varios': 535, 'se√±or': 536, 'posible': 537, 'atrever': 538, 'enhorabuena': 539, 'premiar': 540, 'vuestro': 541, 'bloquear': 542, 'perder': 543, 'willy': 544, 'toledo': 545, '30': 546, 'divertir': 547, 'hilar': 548, 'unico': 549, 'ense√±ar': 550, 'video': 551, 'invitar': 552, 'romper': 553, 'snifff': 554, 'saludo': 555, 'coru√±a': 556, 'fijar': 557, 'teta': 558, 'tallar': 559, 'est√°s': 560, 'julio': 561, 'n': 562, 'serio': 563, 'emitir': 564, 'evolucionar': 565, 'celebrar': 566, 'nacer': 567, 'pro': 568, 'listo': 569, 'concertar': 570, 'decepcionar': 571, 'motivaci√≥n': 572, 'rever': 573, 'color': 574, 'volar': 575, 'minuto': 576, 'est√°': 577, 'lejos': 578, 'topar': 579, 'decente': 580, 'democr√°tico': 581, 'funci√≥n': 582, 'politica': 583, 'amiguitos': 584, 'saludar': 585, 'dif√≠cil': 586, 'ventana': 587, 'definir': 588, 'sera': 589, 'mio': 590, 'mayor': 591, 'rodilla': 592, 'abrazarte': 593, 'desaparecido': 594, 'combatir': 595, 'lograr': 596, 'contrario': 597, 'etapa': 598, '22': 599, 'promocionar': 600, 'anda': 601, 'tb': 602, 'disparar': 603, 'haci√©ndolo': 604, 'preocupar': 605, 'querido': 606, 'asentir': 607, 'resignar': 608, 'tras': 609, 'enseriar': 610, 'aparecer': 611, '9': 612, 'leche': 613, 'real': 614, 'respuesta': 615, 'panorama': 616, 'legion': 617, 'home': 618, 'ser√≠a': 619, 'espectacular': 620, 'corregir': 621, 'fuerte': 622, 'irme': 623, 'tl': 624, 'convencer': 625, 'rat√≥n': 626, 'envidiar': 627, 'robar': 628, 'picar': 629, 'necesito': 630, 'noticiar': 631, 'enquistar': 632, 'gusto': 633, 'juego': 634, 'vac√≠o': 635, 'sufrir': 636, 'disfruta': 637, 'parar': 638, 'espejar': 639, 'playa': 640, 'esta': 641, 'os': 642, 'agostar': 643, 'feminismo': 644, 'comentar': 645, 'adaptar': 646, 'necesidad': 647, 'confundir': 648, 'aprender': 649, 'tomar': 650, 'conveniente': 651, 'abuelo': 652, 'versi√≥n': 653, 'punto': 654, 'golpe': 655, 'menudo': 656, 'descansar': 657, 'bro': 658, '2016': 659, 'parejo': 660, 'aguantar': 661, 'dinero': 662, 'chulada': 663, 'octubre': 664, 'lunes': 665, 'mantener': 666, 'canci√≥n': 667, 'enterar': 668, 'jo': 669, 'mir√≥n': 670, 'desierto': 671, '14': 672, 'anterior': 673, 'detallar': 674, 'las': 675, 'inter√©s': 676, 'asustar': 677, 'paranormal': 678, 'reventar': 679, 'us': 680, 'coincidir': 681, 'absurdo': 682, 'apenar': 683, 'mill√≥n': 684, 'voy': 685, 'ni√±uca': 686, 'cortar': 687, 'totalmente': 688, 'cerrar': 689, '√∫ltimamente': 690, 'gato': 691, 'contento': 692, 'qui√©n': 693, 'citar': 694, 'hace': 695, 'skype': 696, 'com√∫n': 697, 'mo√±o': 698, 'dios': 699, 'cristal': 700, 'cuerpo': 701, 'cabeza': 702, 'pf': 703, '10': 704, 'bonica': 705, 'ambos': 706, 'much√≠sima': 707, 'cuanto': 708, 'romano': 709, 'escuela': 710, 'pierna': 711, 'historia': 712, 'explotar': 713, 'Ô∏è': 714, 'examen': 715, 'honor': 716, '‚ú®': 717, 'igualar': 718, 'lleno': 719, 'encima': 720, 'solucionar': 721, 'sacar': 722, 'huerta': 723, 'imagen': 724, 'pll': 725, 'cristina': 726, 'demonio': 727, 'ay': 728, 'ciudad': 729, 'c': 730, 'carretero': 731, 'tercero': 732, 'xq': 733, 'teneis': 734, 'pelear': 735, 'sexy': 736, 'experiencia': 737, 'cosita': 738, 'p√∫blico': 739, 'dise√±ar': 740, 'tipo': 741, 'm√°laga': 742, 'fifa': 743, 'saltar': 744, 'feriar': 745, '12': 746, 'siguiente': 747, 'depresi√≥n': 748, 'probar': 749, 'mujer': 750, 'dentro': 751, 'nada': 752, 'han': 753, 'intent√°ndolo': 754, 'sona': 755, 'europa': 756, 'responder': 757, 'sistema': 758, 'parece': 759, 'juan': 760, 'oscuro': 761, 'info': 762, 'caminar': 763, 'acompa√±ar': 764, 'escapar': 765, 'usarlo': 766, 'pes': 767, 'pesimista': 768, 'esperanzar': 769, 'adolescente': 770, 'bilbao': 771, 'sois': 772, 'seguirme': 773, 'pintar': 774, 'cabo': 775, 'cuadro': 776, 'aguar': 777, 'recibir': 778, 'tuit': 779, 'jajajajaja': 780, 'aventurar': 781, 'clasificaci√≥n': 782, 'recomendar': 783, 'creo': 784, 'despertar': 785, 'p': 786, 'pisar': 787, 'arreglar': 788, 'ave': 789, 'harias': 790, 'verte': 791, 'v': 792, 'calvo': 793, 'musicar': 794, 'comprender': 795, 'rendir': 796, 'ojo': 797, 'calcet√≠n': 798, 'filler': 799, 'profesional': 800, 'f√∫tbol': 801, 'fatal': 802, 'griego': 803, 'chupar': 804, 'crisis': 805, 'rosendo': 806, 'flojos': 807, 'flipante': 808, 'estilar': 809, 'chicaa': 810, 'emotivo': 811, 'alegr√≠a': 812, 'defensa': 813, 'gratamente': 814, 'sorprender': 815, 'darnos': 816, 'misi√≥n': 817, 'felizmartes': 818, 'optimista': 819, 'seguridad': 820, 'porqe': 821, 'obligatorio': 822, 'situacion': 823, 'lee': 824, 'morder': 825, 'antibi√≥tico': 826, 'milagroso': 827, 'facil√≠simo': 828, 'articular': 829, 'unicovy': 830, 'much√≠simas': 831, 'constancia': 832, 'probarme': 833, 'nozomi': 834, 'verme': 835, 'diamond': 836, 'ace': 837, 'rojo': 838, 't√≠pic': 839, 'correr': 840, 'veloz': 841, 'fantasma': 842, 'alcanzar': 843, 'ai': 844, 'personalidad': 845, 'ancho': 846, 'bc': 847, 'utilizar': 848, 'toca': 849, 'ficci√≥n': 850, 'darse': 851, 'vol02': 852, 'sudar': 853, 'limitar': 854, 'aburrirse': 855, 'arruinar': 856, 'berni': 857, 'dulce': 858, 'cansino': 859, 'edad': 860, 'paciencia': 861, 'filip': 862, 'cruyssen': 863, 'increibles': 864, 'fotografia': 865, 'retrato': 866, 'ask': 867, '20': 868, 'rebeca': 869, 'escribirlo': 870, 'seguir√©': 871, 'linear': 872, 'fresquita': 873, 'banco': 874, 'rio2016': 875, 'lamentablemente': 876, 'arrendar': 877, 'ganancia': 878, 'brasile√±o': 879, 'penuria': 880, 'solidaridad': 881, 'fallir': 882, 'pleno': 883, 'utop√≠': 884, 'audiencia': 885, 'medio': 886, '85': 887, 'imdb': 888, 'manta': 889, 'farmac√©utico': 890, 'venderlo': 891, 'pep': 892, 'mevoy': 893, 'unpaseo': 894, 'improvisto': 895, 'grasias': 896, 'hermoso': 897, 'admiraci√≥n': 898, 'jardi': 899, 'veian': 900, 'rastreador': 901, 'macar': 902, 'lavar': 903, 'ps': 904, 'exterminar': 905, 'mental': 906, 'rid√≠culo': 907, 'jajajaj': 908, 'niall': 909, 'liam': 910, 'libre': 911, 'fugaz': 912, 'ir√≥nico': 913, 'vma': 914, 'realid√°': 915, '√©': 916, 'asimilar': 917, 'alcohol': 918, 'hablaba': 919, 'deber√≠a': 920, 'quedarme': 921, 'serie': 922, 'walter': 923, 'echarle': 924, 'cenizo': 925, 'donie': 926, 'ultimamente': 927, 'macarr√≥n': 928, 'll√©vame': 929, 'fi': 930, 'willytoledo': 931, 'dici√©ndole': 932, 'ganador': 933, 'escr√≠benos': 934, 'privar': 935, 'darte': 936, 'mg': 937, 'adjetivar': 938, 'repelente': 939, 'agente': 940, 'cni': 941, 'burrada': 942, 'heterada': 943, 'caer√°n': 944, 'prontito': 945, 'alba': 946, 'carrillo': 947, 'modelar': 948, 'profesi√≥n': 949, 'lucio': 950, 'vd': 951, 'tapadera': 952, 'nutella': 953, 'algeciras': 954, 'terremoto': 955, 'justamente': 956, 'sostener': 957, 'mason': 958, 'hh': 959, 'podr√≠amos': 960, 'jajajajajajajjaajaja': 961, '2018': 962, 'flipado': 963, 'enmarcar': 964, 'defib': 965, 'kills': 966, 'award': 967, 'sigui√©ndote': 968, 'figurar': 969, 'madison': 970, 'alicia': 971, 'desmovilizar': 972, 'concha': 973, 'as': 974, 'calle': 975, 'vaticinar': 976, 'club': 977, 'palabra': 978, 'criticar': 979, 'vaya': 980, 'cuba': 981, 'astroymas': 982, 'podcast': 983, 'emberd√°': 984, 'dibujo': 985, 'paint': 986, 'mmmm': 987, 'supongo': 988, 'l√≥gico': 989, 'obligarte': 990, 'forzar': 991, 'happyjungkookday': 992, 'ÍæπÏù¥ÏÉùÏùº„Öä„Öã': 993, 'galleta': 994, 'maknae': 995, 'pecar': 996, 'interior': 997, 'cien': 998, 'escotar': 999, 'calladito': 1000, 'radiar': 1001, 'rico': 1002, 'basura': 1003, 'simplemente': 1004, 'enamorarme': 1005, 'superficial': 1006, 'estan': 1007, 'hahahahahahha': 1008, 'estetico': 1009, 'siiiii': 1010, 'programar': 1011, 'ot': 1012, 'enemigo': 1013, 'caramusgo': 1014, 'torete': 1015, 'a√±adir': 1016, 'sabio': 1017, 'encontre': 1018, 'modo': 1019, 'borrar': 1020, 'rehacer': 1021, 'britney': 1022, 'odisea': 1023, 'shakespeare': 1024, 'hamlet': 1025, 'general': 1026, 'ego': 1027, 'azular': 1028, 'conseguirlo': 1029, 'tinte': 1030, 'kinox': 1031, 'zi': 1032, 'zoy': 1033, 'perzona': 1034, 'lamentar': 1035, 'danos': 1036, 'detalle': 1037, 'clientees': 1038, 'atender': 1039, 'salu2': 1040, 'rom√°ntico': 1041, 'dildos': 1042, 'lubricante': 1043, 'masaje': 1044, 'bel': 1045, 'porno': 1046, 'echo': 1047, 'lexa': 1048, 'braga': 1049, 'limpiarlas': 1050, 'drag√≥n': 1051, 'autob√∫s': 1052, 'pantalla': 1053, 'corruppci√≥n': 1054, 'tod': 1055, 'trayectoria': 1056, 'pol√≠tico': 1057, 'defendi√©ndole': 1058, 'dici√©ndome': 1059, 'paz': 1060, 'coraje': 1061, 'lxs': 1062, 'prepotentxs': 1063, 'ouch': 1064, 'indirecto': 1065, 'preparate': 1066, 'f': 1067, 'reformar': 1068, 'necesitoelviajeaandalucia': 1069, 'mongol': 1070, 'gafo': 1071, 'morar': 1072, 'soportar': 1073, 'bona': 1074, 'nit': 1075, 'pastar': 1076, 'apuntar': 1077, 'laser': 1078, 'pesadito': 1079, 'cerveza': 1080, 'entretener': 1081, 'amore': 1082, 'sprite': 1083, 'lider': 1084, 'gimnasio': 1085, 'made': 1086, 'manifestar': 1087, 'cable': 1088, 'cojonudo': 1089, 'barato': 1090, 'ponerla': 1091, 'azote': 1092, 'culete': 1093, 'iman': 1094, 'miguelrios': 1095, 'insurrecci√≥n': 1096, 'im': 1097, 'back': 1098, 'lot': 1099, 'graduaci√≥n': 1100, 'dr': 1101, 'mir': 1102, 'investidurarajoy': 1103, 'noticia': 1104, 'becario': 1105, 'curioso': 1106, 'fortuna': 1107, 'finde': 1108, 'tobillo': 1109, 'competir': 1110, 'sucumbir': 1111, 'maldito': 1112, 'c√°mara': 1113, 'usarla': 1114, 'perfecci√≥n': 1115, 'brillar': 1116, 'kk': 1117, 'esteban': 1118, 'estopa': 1119, 'leganes': 1120, 'bromar': 1121, 'barriobajeres': 1122, 'todes': 1123, 'temprano': 1124, 'equivocarme': 1125, 'estacionar': 1126, 'aut√©ntico': 1127, 'gozar': 1128, 'surrando': 1129, 'help': 1130, 'c√≥metelo': 1131, 'targaryen': 1132, 'paradero': 1133, 'desconocer': 1134, 'pueh': 1135, 'imagenes': 1136, 'ostia': 1137, 'ahi': 1138, 'escaqueas': 1139, 'destino': 1140, 'guada': 1141, 'dawn': 1142, 'beth': 1143, 'daryl': 1144, 'inmediatamente': 1145, 'conservador': 1146, 'thanks': 1147, 'pap√°': 1148, 'piano': 1149, 'castalla': 1150, 'alicante': 1151, 'oportunamente': 1152, 'moros': 1153, 'cristians': 1154, 'habemos': 1155, 'saturar': 1156, 'idnwhy': 1157, 'ccaa': 1158, 'cargar': 1159, 'naci√≥n': 1160, 'nigtwish': 1161, 'fueramos': 1162, 'sentarnos': 1163, 'pistar': 1164, 'disponer': 1165, 'fallecer': 1166, 'contrastar': 1167, 'divorciar': 1168, 'lupus': 1169, 'nenaaaaaa': 1170, 'crecer': 1171, 'enano': 1172, 'extra√±o': 1173, 'wey': 1174, 'platicar': 1175, 'uy': 1176, 'colocar': 1177, 'port√°til': 1178, 'flauta': 1179, 'saxo': 1180, 'nariclete': 1181, 'partitura': 1182, 'desorden': 1183, 'tormenta': 1184, 'solita': 1185, 'buenico': 1186, 'üíú': 1187, 'low': 1188, 'cost': 1189, 'hostia': 1190, 'asqueroso': 1191, 'ex': 1192, 'pegar': 1193, 'incre√≠ble': 1194, 'cri': 1195, 'emergente': 1196, 'disponible': 1197, 'rey': 1198, 'mago': 1199, 'üëç': 1200, 'mid': 1201, 'remake': 1202, 'vale': 1203, 'funciona': 1204, 'aleluya': 1205, 'boton': 1206, 'palanza': 1207, 'derecho': 1208, 'mediocre': 1209, 'ingenioso': 1210, 'libros': 1211, 'enganchar': 1212, 'buenisismas': 1213, 'macedonio': 1214, 'ibiza': 1215, 'timbal': 1216, 'ruta': 1217, 'sinverg√ºenza': 1218, 'dormio': 1219, '6': 1220, 'porke': 1221, '2011': 1222, 'respetuoso': 1223, 'respetable': 1224, 'combativo': 1225, 'omar': 1226, 'cod': 1227, 'players': 1228, 'bcn': 1229, 'disfrutarlo': 1230, 'venga': 1231, 'work': 1232, 'from': 1233, 'verlas': 1234, 'conmtval727tour': 1235, 'harley': 1236, 'profesor': 1237, 'reenviar': 1238, 'mascota': 1239, 'planazo': 1240, 'sabado': 1241, 'perverso': 1242, 'reglamentario': 1243, 'putada': 1244, 'lv': 1245, 'ruedecita': 1246, 'jenko': 1247, 'danielle': 1248, 'cojo': 1249, 'avi√≥n': 1250, 'equipar': 1251, 'jojojojo': 1252, 'acertar': 1253, 'anoche': 1254, 'quejica': 1255, 'ehhhhhhh': 1256, 'coj√≥n': 1257, 'identidad': 1258, 'trokistas': 1259, 'piedra': 1260, 'gulag': 1261, 'amistar': 1262, 'riri': 1263, 'conformar': 1264, 'vmas': 1265, 'notasdelmisterio': 1266, 'lugar': 1267, 'comerlos': 1268, 'preciar': 1269, 'secundario': 1270, 'ligar': 1271, 'musical': 1272, 'tronos': 1273, 'emulador': 1274, 'rub√≠': 1275, 'ios': 1276, '934': 1277, 'verda': 1278, 'soi': 1279, 'lameculos': 1280, 'pfff': 1281, 'caia': 1282, 'muchisima': 1283, 'terapia': 1284, 'firstdates112': 1285, 'soltero': 1286, 'vista': 1287, 'dni': 1288, 'pasaporte': 1289, 'presumir': 1290, 'serlo': 1291, 'peculiar': 1292, 'caritativo': 1293, 'molan': 1294, 'speakingio': 1295, 'zack': 1296, 'holman': 1297, 'ensuciar': 1298, 'mano': 1299, 'dependiente': 1300, 'ser√°': 1301, 'salar': 1302, 'mandame': 1303, 'despertarme': 1304, 'intrigante': 1305, 'autoexploraci√≥n': 1306, 'consciencia': 1307, 'trav√©s': 1308, 'pionero': 1309, 'gaona': 1310, 'mariano': 1311, 'brey': 1312, 'francia': 1313, 'partidario': 1314, 'tarjeta': 1315, 'pp': 1316, 'viva': 1317, 'espana': 1318, 'alarmar': 1319, 'noooo': 1320, 'lucena': 1321, 'rottweiler': 1322, 'zumbadisimo': 1323, 'atacar': 1324, 'achucharlo': 1325, 'incantus': 1326, 'conectar': 1327, 'global': 1328, 'talents': 1329, 'actuaci√≥n': 1330, 'valoraci√≥n': 1331, 'previo': 1332, 'hermanar': 1333, 'pulgaaas': 1334, 'chachi': 1335, 'careto': 1336, '16': 1337, 'cabr√≥n': 1338, 'silenciar': 1339, 'movil': 1340, 'efecto': 1341, 'plazo': 1342, 'desafecci√≥n': 1343, 'mayoritario': 1344, 'votante': 1345, 'fomentar': 1346, 'stream': 1347, '24horas': 1348, 'objetivar': 1349, '2012': 1350, '13': 1351, 'novelar': 1352, 'perrie': 1353, 'verg√ºenza': 1354, 'tant√≠simo': 1355, 'chocar': 1356, 'pared': 1357, 's√∫per': 1358, 'gilipollas': 1359, 'pat√©tico': 1360, 'pr√°cticamente': 1361, 'repasito': 1362, 'tornear': 1363, 'liga': 1364, 'playstation': 1365, 'jejejeje': 1366, 'tele': 1367, 'nerviosita': 1368, 'vibrador': 1369, 'juguete': 1370, 'concepto': 1371, 'nivel': 1372, 'medir': 1373, '‚â†': 1374, 'socialismo': 1375, 'buenas': 1376, 'madrugar': 1377, 'fabuloso': 1378, 'sumir': 1379, 'felicitaci√≥n': 1380, 'retarse': 1381, 'increible': 1382, 'medirse': 1383, 'obst√°culo': 1384, 'joyita': 1385, 'coronar': 1386, 'descojona': 1387, 'indignar': 1388, 'corrupci√≥npp': 1389, 'chatel': 1390, 'primo': 1391, 'funeral': 1392, 'lora': 1393, 'cantar': 1394, 'adaptaci√≥n': 1395, 'querida': 1396, 'dep': 1397, 'juanga': 1398, 'empatia': 1399, 'distinci√≥n': 1400, 'm√∫sico': 1401, 'adivinar': 1402, 'pobres': 1403, 'simple': 1404, 'mortal': 1405, 'encargar': 1406, 'estupend√≠sima': 1407, 'barce': 1408, 'nacido': 1409, 'agradecer': 1410, 'tiene': 1411, 'r√©cord': 1412, 'vcfcreo': 1413, 'dificil': 1414, 'acostumbrarse': 1415, 's√≠ndrome': 1416, 'uncharted': 1417, 's': 1418, 'peeeero': 1419, 'debajo': 1420, 'dichoso': 1421, 'm√°quina': 1422, 'sofocar': 1423, 'aprovechar': 1424, 'currar': 1425, 'liar': 1426, 'malague√±o': 1427, 'ole': 1428, 'almeriense': 1429, 'felicitaria': 1430, 'car√°cter': 1431, 'cual': 1432, 'tocayo': 1433, 'rabiar': 1434, 'extremar': 1435, 'machismo': 1436, 'significa': 1437, 'traerlos': 1438, 'peazo': 1439, 'pletorico': 1440, 'noja': 1441, 'despedirnos': 1442, 'askalvarogango': 1443, 'coraz√≥n': 1444, 'seta': 1445, 'sonreir': 1446, 'bicho': 1447, 'original': 1448, 'antiguo': 1449, 'ayudarme': 1450, 'matar√≥': 1451, 'raci√≥n': 1452, 'atenci√≥n': 1453, 'diario': 1454, 'autoestima': 1455, 'buenisimas': 1456, 'üòô': 1457, 'expectante': 1458, 'cubreselfem': 1459, 'llevarlo': 1460, 'ahhh': 1461, 'audio': 1462, 'apiadar': 1463, 'andrea': 1464, 'sabran': 1465, 'm√©s': 1466, 'cursar': 1467, 'ccc': 1468, 'refutarme': 1469, 'fe√©ricos': 1470, '32': 1471, 'derretir': 1472, 'acercar': 1473, 'desvivir': 1474, 'aaaa': 1475, 'aaa': 1476, 'jueves': 1477, 'demostrar': 1478, 'conocerme': 1479, 'villa': 1480, 'calidad': 1481, 'fre√≠r': 1482, 'abrigar': 1483, 'anunciar': 1484, 'joseba': 1485, 'baby': 1486, 'followspree': 1487, 'verd√°': 1488, 'go': 1489, 'galicia': 1490, 'deprimir': 1491, 'sortija': 1492, 'nuestros': 1493, 'animar': 1494, 'verseme': 1495, 'desnudo': 1496, 'envidiosillo': 1497, 'llenar': 1498, 'crushes': 1499, 'atraigo': 1500, 'trendingestreno': 1501, 'david': 1502, 'carrera': 1503, 'coche': 1504, 'empresa': 1505, 'dio': 1506, 'ilusi√≥n': 1507, 'boda': 1508, 'jp': 1509, 'conocerte': 1510, 'maite': 1511, 'monada': 1512, 'promocionarse': 1513, 'complicadillo': 1514, 'aprobar': 1515, 'suspender': 1516, 'beber': 1517, 'h√≠gado': 1518, 'amazon': 1519, 'si√©ntete': 1520, 'afortunado': 1521, 'festival': 1522, 'hemos': 1523, 'met√°fora': 1524, 'comparaci√≥n': 1525, 'teor√≠a': 1526, 'literario': 1527, 'store': 1528, 'canad√°': 1529, 'convenci√≥n': 1530, 'puff': 1531, 'acostumbrarme': 1532, 'diente': 1533, 'norma': 1534, 'estratificar': 1535, '1477': 1536, 'confi': 1537, 'pib': 1538, 'd√©ficit': 1539, '40000': 1540, 'gastar': 1541, 'ingresar': 1542, 'to': 1543, 'ono': 1544, 'venio': 1545, 'giga': 1546, 'jajajja': 1547, 'parque': 1548, 'despierto': 1549, 'prometer': 1550, 'enternecedor': 1551, 'beso': 1552, 'castr√≥n': 1553, 'troc√≠n': 1554, 'tertulio': 1555, 'evoluci√≥n': 1556, 'involuci√≥n': 1557, 'piscina': 1558, 'pillo': 1559, 'corte': 1560, 'perfilar': 1561, 'tono': 1562, 'instagram': 1563, 'hotel': 1564, 'quedamos': 1565, 'muuuuuuuuy': 1566, 'invierno': 1567, 'chaqueta': 1568, 'sudadera': 1569, 'abrigo': 1570, 'faltar√≠a': 1571, 'pensaba': 1572, 'discurso': 1573, 'emplear': 1574, 'debatir': 1575, 'tonyysorayaenmalaga': 1576, 'pijama': 1577, 'pq': 1578, 'ronch√≥n': 1579, 'considerable': 1580, 'acuerd': 1581, 'retwitteo': 1582, 'divulgar': 1583, 'reinar': 1584, 'sof√≠a': 1585, 'descuento': 1586, 'estudiante': 1587, 'menor': 1588, '27': 1589, 'monta√±a': 1590, 'ruso': 1591, 'emocional': 1592, 'pilotar': 1593, 'ovario': 1594, 'putis': 1595, 'ftwd': 1596, 'ameno': 1597, 'twd': 1598, 'hablabamos': 1599, 'manotazo': 1600, 'templar': 1601, 'reglar': 1602, 'destrzando': 1603, 'tripa': 1604, 'fiebre': 1605, 'marear': 1606, 'bus': 1607, 'muuuuuuy': 1608, 'mol√≥n': 1609, 'hoya': 1610, 'felicitad': 1611, 'majo': 1612, 'crei': 1613, 'expulsion': 1614, 'parecio': 1615, 'tongo': 1616, 'ares': 1617, 'karlita': 1618, 'consejo': 1619, 'spoiler': 1620, '2015': 1621, 'insultarlos': 1622, 'comisaria': 1623, 'ampliando': 1624, 'denuncia': 1625, 'acoso': 1626, 'hip√≥crita': 1627, 'camiseta': 1628, 'femimism': 1629, 'hym': 1630, 'cotidiano': 1631, 'bucle': 1632, 'infinito': 1633, 'imprimir': 1634, 'mapa': 1635, 'cualquier': 1636, 'detr√°s': 1637, 'pau': 1638, 'bronquitis': 1639, '15': 1640, 'queduroesseradulto': 1641, 'omega': 1642, 'constellation': 1643, 'num√©rico': 1644, 'ojala': 1645, 'present√°ndome': 1646, 'concursar': 1647, 'shawn': 1648, 'vergonzoso': 1649, 'participar': 1650, 'm√∫sica': 1651, 'oj√∫': 1652, 'a√∫n': 1653, 'deberias': 1654, 'mirarte': 1655, 'guille': 1656, 're√≠r': 1657, 'rie': 1658, 'manchar': 1659, 'divino': 1660, 'potado': 1661, 'arcoiris': 1662, 'kiko': 1663, 'cuartar': 1664, 'r√≠o': 1665, 'bbs': 1666, 'vecino': 1667, 'ruido': 1668, 'f√≥rmula': 1669, 'matem√°tico': 1670, 'pasivo': 1671, 'cabesa': 1672, 'master': 1673, 'sensibilidad': 1674, 'valorar': 1675, 'corasonsito': 1676, 'grito': 1677, 'clexa': 1678, 'fanfics': 1679, 'profundo': 1680, 'intagram': 1681, 'seguia': 1682, 'igualmente': 1683, 'üôÑ': 1684, 'fardar': 1685, 'vegano': 1686, 'tuiter': 1687, 'inestimable': 1688, 'colaboraci√≥n': 1689, 'sonar': 1690, 'lejano': 1691, 'jajaxd': 1692, 'comprobar': 1693, 'linkedin': 1694, 'antiguar': 1695, 'alumno': 1696, 'chisme': 1697, 'expreso': 1698, 'matizar': 1699, 'elementar': 1700, 'cortante': 1701, 'librillo': 1702, 'recien': 1703, 'comprao': 1704, 'polla': 1705, 'vente': 1706, 'piti': 1707, 'horarios': 1708, 'distinto': 1709, 'total': 1710, 'absolutamente': 1711, 'desesperanzar': 1712, 'portavoz': 1713, 'inmenso': 1714, 'minor√≠a': 1715, 'molesto': 1716, 'minorizaci√≥n': 1717, 'plural': 1718, 'cuantas': 1719, 'idioma': 1720, 'oficial': 1721, 'cat': 1722, 'ambientado': 1723, 'italia': 1724, 'comediar': 1725, 'entuerto': 1726, 'te√±irme': 1727, '100010': 1728, 'petarda': 1729, 'experto': 1730, 'rosa': 1731, 'freir': 1732, 'huevo': 1733, 'gemelo': 1734, 'haberme': 1735, 'box': 1736, 'kebab': 1737, 'ayudadme': 1738, 'picadura': 1739, 'mosquito': 1740, 'herir': 1741, 'oie': 1742, 'adorar': 1743, 'gante': 1744, 'presi√≥n': 1745, 'avanzar': 1746, 'escarmentams': 1747, 'encueshshtasshs': 1748, 'despreciable': 1749, 'peter': 1750, 'iglesias': 1751, 'gobernar': 1752, 'bollero': 1753, 'perrito': 1754, 'condicionar': 1755, 'somos': 1756, 'modesto': 1757, 'abarcar': 1758, 'capturar': 1759, 'actividad': 1760, 'sorprendente': 1761, 'inivitado': 1762, 'mear': 1763, 'espa√±olar': 1764, 'pronunciar': 1765, 'raven': 1766, 'raiven': 1767, 'reiven': 1768, 'links': 1769, 'guardar': 1770, 'summer': 1771, 'finale': 1772, 'hmm': 1773, 'estos': 1774, 'd√©bil': 1775, 'cracias': 1776, 'bendici√≥n': 1777, 'paciente': 1778, 'vera': 1779, 'milagro': 1780, 'lapsus': 1781, 'advertir': 1782, 'subsanar': 1783, 'aportaci√≥n': 1784, 'marginar': 1785, 'humano': 1786, 'manipulable': 1787, 'libreta': 1788, 'somn√≠fero': 1789, 'instant√°neo': 1790, 'completamente': 1791, 'vegana': 1792, 'oye': 1793, 'tenemos': 1794, 'presidente': 1795, 'non': 1796, 'grato': 1797, 'segundo': 1798, 'le√±a': 1799, 'mono': 1800, 'suelto': 1801, 'subnormal': 1802, 'sara': 1803, 'beret': 1804, 'weno': 1805, 'comparar': 1806, 'surrealista': 1807, 'pewdiepie': 1808, 'ufff': 1809, 'd√°ndome': 1810, '11s': 1811, 'pam': 1812, 'preferir': 1813, 'vs': 1814, 'ddh': 1815, 'lvl': 1816, 'nicol√°s': 1817, '4k': 1818, 'distanciar': 1819, 'pensando': 1820, 'netflix': 1821, 'uhd': 1822, 'nazismo': 1823, 'fangirleo': 1824, 'filosof√≠a': 1825, 'moral': 1826, 'juju': 1827, 'nerea': 1828, 'defender': 1829, 'apoyar': 1830, 'activista': 1831, 'machista': 1832, 'opresor': 1833, 'sincerar': 1834, 'leal': 1835, 'escenario': 1836, 'muwi': 1837, 'revell√≠n': 1838, 'gratuito': 1839, 'preparar': 1840, 'apostar': 1841, 'recuperarme': 1842, '‚ô•': 1843, 'directillo': 1844, 'liverpool': 1845, 'jurar': 1846, 'pantin': 1847, 'classic': 1848, 'gorra': 1849, 'calleron': 1850, 'aplastar': 1851, 'jaj': 1852, 'especie': 1853, 'titanic': 1854, 'tierra': 1855, '√©xito': 1856, 'anfitri√≥n': 1857, 'fernando': 1858, 'jornada': 1859, 'toro': 1860, 'heidegger': 1861, 'tu√≠ter': 1862, 'mclaren': 1863, '15s': 1864, 'qualy': 1865, 'williams': 1866, 'spa': 1867, 'miserable': 1868, 'silmarillion': 1869, 'ajajajaja': 1870, 'benidorm': 1871, 'carrito': 1872, 'beb√©': 1873, 'flipados': 1874, 'sabrina': 1875, 'cari√±oso': 1876, 'novia': 1877, 'legi√≥n': 1878, 'novio': 1879, 'pack': 1880, 'viii': 1881, 'resumir': 1882, 'jam√°s': 1883, 'chiqui': 1884, '‚ù£': 1885, 'üíû': 1886, 'precisamente': 1887, 'arte': 1888, 'desplegar': 1889, 'fingelo': 1890, 'expresar': 1891, 'vaso': 1892, 'm√≥stoles': 1893, 'ambientar': 1894, 'recomendaci√≥n': 1895, 'paintball': 1896, 'losers': 1897, 'casters': 1898, 'vigo': 1899, 'enfrentarnos': 1900, 'apuf': 1901, 'iniciativo': 1902, 'raquel': 1903, 'support': 1904, 'razonar': 1905, 'nop': 1906, 'asunto': 1907, 'sorteo': 1908, 'saludais': 1909, 'hablais': 1910, 'habeis': 1911, 'molando': 1912, 'knifing': 1913, 'tricks': 1914, 'bal√≠stico': 1915, 'bof': 1916, 'followexpress': 1917, 'talar': 1918, 'abedul': 1919, 'gigante': 1920, 'esquinar': 1921, 'r√≠os': 1922, 'rosas': 1923, 'castellana': 1924, 'vital': 1925, 'intentarlo': 1926, 'usa': 1927, 'obligar': 1928, 'embarazar': 1929, 'caua': 1930, 'violaci√≥n': 1931, 'art√≠culo': 1932, 'carlos': 1933, 'lucas': 1934, 'dramatizar': 1935, 'mandaria': 1936, 'comprarte': 1937, 'burro': 1938, 'tienda': 1939, 'donaci√≥n': 1940, 'asociacionmariloli': 1941, 'proyecto': 1942, 'completito': 1943, 'fuengirola': 1944, 'pe√±iscola': 1945, 'valle': 1946, 'jerte': 1947, 'sepul': 1948, 'pr√≥ximamente': 1949, 'olmillo': 1950, '‚Ñ¢': 1951, 'complicar': 1952, 'vendr√°': 1953, 'contra': 1954, 'generaci√≥n': 1955, 'fav': 1956, 'life': 1957, 'conocia': 1958, 'shay': 1959, 'lucy': 1960, 'recuper√°ndome': 1961, 'bird': 1962, 'shit': 1963, 'parodiar': 1964, 'escocia': 1965, 'apenas': 1966, 'plaza': 1967, 'hoguera': 1968, 'san': 1969, 'sensible': 1970, 'igot7': 1971, 'comprartido': 1972, 'isac': 1973, 'emisi√≥n': 1974, 'olear': 1975, 'hom√≥fobas': 1976, 'hab√≠a': 1977, 'estornud√≥': 1978, 'loser': 1979, 'basar': 1980, 'feels': 1981, 'verdaderx': 1982, 'fot√≥grafx': 1983, 'masculino': 1984, 'razon': 1985, 'alvaro': 1986, 'clash': 1987, 'of': 1988, 'clans': 1989, 'agotar': 1990, 'fuerza': 1991, 'mareo': 1992, 'molin√≥n': 1993, 'sitiar': 1994, 'fanpage': 1995, 'facebook': 1996, 'activo': 1997, 'ohhhhh': 1998, 'vetar': 1999, '√°baco': 2000, 'sobre': 2001, 'mayor√≠a': 2002, 'escuchal': 2003, 'enlacabezano': 2004, 'losiento': 2005, 'oto√±o': 2006, 'noviembre': 2007, 'diciembre': 2008, 'baj√≥n': 2009, 'ds': 2010, 'manual': 2011, 'leyenda': 2012, '0': 2013, 'velocidad': 2014, 'impresionante': 2015, 'pes2017': 2016, 'despues': 2017, 'capricho': 2018, 'siiiiii': 2019, 'viernes': 2020, 'jurao': 2021, 'jajajajjjaajjjjajajaa': 2022, 'asistencia': 2023, 'triple': 2024, 'gilipolleces': 2025, 'nicky': 2026, 'mira': 2027, 'mazar': 2028, 'taaaan': 2029, 'estaci√≥n': 2030, 'puentedevallecas': 2031, 'bici': 2032, 'principio': 2033, 'silvia': 2034, 'notificaci√≥n': 2035, 'gemeliers': 2036, 'aceptar': 2037, 'guidettinosevende': 2038, 'mandarlo': 2039, 'amuntvalencia': 2040, 'halacelta': 2041, 'entretenido': 2042, 'ojalar': 2043, 'oudiese': 2044, 'acceder': 2045, 'comunidad': 2046, 'furg√≥n': 2047, 'blindar': 2048, 'quiquegonz√°lez': 2049, 'esperando': 2050, 'supershore2': 2051, 'calentar': 2052, 'motor': 2053, 'acapulcoshore3': 2054, '2230': 2055, 'inflar': 2056, 'barriga': 2057, 'mediador': 2058, 'investigar√©': 2059, 'sal√≥n': 2060, '25': 2061, 'metro': 2062, '50': 2063, 'manteca': 2064, 'cerdo': 2065, 'gominolastristemente': 2066, 'esa': 2067, 'nasa': 2068, 'cansadete': 2069, 'repente': 2070, 'ratejo': 2071, 'beta': 2072, 'battlefield': 2073, 'ganitas': 2074, 'premier': 2075, 'esque': 2076, 'exposici√≥n': 2077, 'estropeandose': 2078, 'aire': 2079, 'acondicionar': 2080, 'izdo': 2081, 'autopista': 2082, 'huelva': 2083, 'entrarme': 2084, 'impotencia': 2085, 'esperemos': 2086, 'arribar': 2087, 'despegar': 2088, 'proyectar': 2089, 'bronco': 2090, 'proximo': 2091, 'cajon': 2092, 'jugable': 2093, 'tgs': 2094, 'irresponsable': 2095, 'll√©vales': 2096, 'bibliograf√≠a': 2097, 'evidenciar': 2098, 'subtitulos': 2099, 'bojack': 2100, 'horseman': 2101, 'pais': 2102, 'today': 2103, 'alaska': 2104, 'mario': 2105, 'ye': 2106, 'terrible': 2107, 'vivo': 2108, 'reaccionar': 2109, 'violencia': 2110, 'verbal': 2111, 'f√≠sico': 2112, 'agresor': 2113, 'meleno': 2114, 'manguerazo': 2115, 'hijos': 2116, 'puta': 2117, 'preguntadle': 2118, 'dao': 2119, 'crear': 2120, 'colectivo': 2121, 'estatal': 2122, 'divisi√≥n': 2123, 'local': 2124, 'poderoso': 2125, 'over25': 2126, 'aspirante': 2127, 'opci√≥n': 2128, 'zona': 2129, 'escoger': 2130, 'permiso': 2131, 'miquel': 2132, 'verla': 2133, 'timeline': 2134, 'all': 2135, 'bran': 2136, 'compis': 2137, 'grand√≠sima': 2138, '29': 2139, 'discursar': 2140, 'sesiondeinvestidura': 2141, 'ch√©': 2142, 'ciudadan√≠a': 2143, 'diariamente': 2144, 'ola': 2145, 'wapa': 2146, 'stas': 2147, 'spero': 2148, 'sorra': 2149, 'kmo': 2150, 'xikas': 2151, 'machirulo': 2152, 'cojones': 2153, 'jajsakjkjsadjjsjasjajaja': 2154, 'promocion': 2155, 'gestionar': 2156, 'via': 2157, 'rapida': 2158, 'todas': 2159, 'm√≠ercoles': 2160, 'se√±a': 2161, 'stranger': 2162, 'mr': 2163, 'robot': 2164, 'get': 2165, 'down': 2166, 'plat√≥nico': 2167, 'gay': 2168, 'demo': 2169, '17': 2170, 'wuouuoo': 2171, 'esport3': 2172, '2¬™': 2173, 'rcde': 2174, 'fara': 2175, 'marcar': 2176, 'grotesco': 2177, 'ojeda': 2178, '1030': 2179, 'perdona': 2180, 'comprensible': 2181, 'caere': 2182, 'popular': 2183, 'ea': 2184, 'estare': 2185, 'distraido': 2186, 'cadiz': 2187, 'preocupeis': 2188, 'juicio': 2189, 'lento': 2190, 'carcel': 2191, 'desventura': 2192, 'albert': 2193, 'grifo': 2194, 'decidir': 2195, 'ilustres': 2196, 'jose': 2197, 'insulto': 2198, 'burgos': 2199, 'murcia': 2200, 'sociable': 2201, 'n√°': 2202, 'actriz': 2203, 'costar': 2204, 'encontrarte': 2205, 'incitar': 2206, 'lectura': 2207, 'm√°gico': 2208, 'pillar': 2209, 'frustrante': 2210, 'acordarse': 2211, 'guapis': 2212, 'durante': 2213, 'matricular': 2214, 'opinion': 2215, 'psicologia': 2216, 'fp': 2217, 'infor': 2218, 'atrasar': 2219, 'abrazoteee': 2220, 'correcci√≥n': 2221, 'tom√°s': 2222, 'hab√©is': 2223, 'dinos': 2224, 'tierramagna': 2225, 'cola': 2226, 'espect√°culo': 2227, 'ta': 2228, 'cerrao': 2229, 'estancar': 2230, 'llamandome': 2231, 'instar': 2232, 'histories': 2233, 'buscar√©': 2234, 'pinterest': 2235, 'm√≠o': 2236, 'seestrenasietevidas': 2237, 'garfield': 2238, 'vagar': 2239, 'lasa√±a': 2240, 'sensaci√≥n': 2241, 'din': 2242, 'eu': 2243, 'na': 2244, 'ofi': 2245, 'lendo': 2246, 'tampouco': 2247, 'te√±o': 2248, 'cobrar': 2249, 'prat': 2250, 'unminutosindolor': 2251, 'singlar': 2252, 'promocional': 2253, '40globalshow51': 2254, '1010': 2255, 'lindar': 2256, 'le√≥n': 2257, 'bae': 2258, 'carta': 2259, 'seprona': 2260, 'cuidar': 2261, 'pepito': 2262, 'mecanicas': 2263, 'rapido': 2264, 'cruzar': 2265, 'marchar': 2266, 'mego': 2267, 'mamaheasesinadoaminovia': 2268, 'despedir': 2269, 'ri√±a': 2270, 'trifulca': 2271, 'cuello': 2272, 'm√°talo': 2273, 'posiblemente': 2274, 'yoshi': 2275, 'primer': 2276, 'operaci√≥n': 2277, 'bikini': 2278, 'superar': 2279, 'can': 2280, 'altafitdonosti': 2281, 'objetivospartan2017': 2282, 'pajarito': 2283, 'reservar': 2284, 'bibo': 2285, 'demandar': 2286, 'aspecto': 2287, 'solar': 2288, 'probablemente': 2289, 'necesario': 2290, 'amargar': 2291, 'capacidad': 2292, 'an√°lisis': 2293, 'visi√≥n': 2294, 'l': 2295, 'm': 2296, 'prontisimo': 2297, 'x': 2298, 'j': 2299, 'hambre': 2300, 'hacerme': 2301, 'todav√≠a': 2302, 'ubisoft': 2303, 'sony': 2304, 'lamento': 2305, 'decirles': 2306, 'opacar': 2307, 'spotify': 2308, 'tenerlas': 2309, 'colaborativas': 2310, 'entero': 2311, 'literalmente': 2312, 'caminante': 2313, 'ante': 2314, 'niebla': 2315, 'portar': 2316, 'encantado': 2317, 'visitaros': 2318, 'trailer': 2319, 'pokemongo': 2320, 'minecraft': 2321, 'pokecasas': 2322, 'rts': 2323, 'leila': 2324, 'fuistes': 2325, 'quevaaa': 2326, 'dejandome': 2327, 'esquinita': 2328, 'retuitea': 2329, 'haser': 2330, 'sensual': 2331, 'pase': 2332, 'regalo': 2333, 'suculento': 2334, 'son': 2335, 'frase': 2336, 'complementar': 2337, 'tumblrr': 2338, 'oo': 2339, 'extra√±ar': 2340, 'hetero': 2341, 'gratis': 2342, 'tweets': 2343, 'brutal': 2344, 'manis': 2345, 'separatista': 2346, 'catalunya': 2347, 'conseguir': 2348, 'anhelar': 2349, 'libertar': 2350, 'lesbiano': 2351, 'machorro': 2352, 'pelis': 2353, 'suponer': 2354, 'incluir': 2355, 'salvo': 2356, 'siento': 2357, 'spam': 2358, 'capit√°n': 2359, 'kylie': 2360, 'vasco': 2361, 'pur√©': 2362, 'verdura': 2363, 'pota': 2364, 'gritar': 2365, 'terror': 2366, 'jajajajajajajajajajajajaja': 2367, 'cari√±o': 2368, '3h': 2369, 'quejar': 2370, 'adiosagosto': 2371, 'legendario': 2372, 'ojino': 2373, 'bandera': 2374, 'jap√≥n': 2375, 'productivo': 2376, 'intimidar': 2377, 'prohibirlo': 2378, 'campa√±a': 2379, 'pedagog√≠a': 2380, 'aplaudir': 2381, 'pseudo': 2382, 'feminista': 2383, 'extudiar': 2384, 'lastimar': 2385, 'java': 2386, 'microsoft': 2387, 'sentimental': 2388, 'pa√±uelos': 2389, 'palabras': 2390, 'impulsar': 2391, 'confirmao': 2392, 'hueso': 2393, 'mover': 2394, 'abel': 2395, 'resfriar': 2396, 'campar': 2397, 'coleccionista': 2398, 'pagarla': 2399, 'reconocer': 2400, 'perfil': 2401, 'placer': 2402, 'guapo': 2403, 'perd√≥name': 2404, 'maldad': 2405, 'borr√°ndose': 2406, 'ami': 2407, 'separata': 2408, 'recomer': 2409, 'mon√≥tono': 2410, 'ubicaci√≥n': 2411, 'tuiteo': 2412, 'actualizar': 2413, 'mercar': 2414, 'vaciar': 2415, 'tarde': 2416, 'orzuelo': 2417, 'asim√©trico': 2418, 'universidad': 2419, 'jajajajajajajajajajajaja': 2420, 'mentira': 2421, 'jope': 2422, 'tias': 2423, 'intenso': 2424, 'hagais': 2425, 'rodrigo': 2426, 'nani': 2427, 'inc√≥gnito': 2428, 'falta': 2429, 'fichar': 2430, 'ow': 2431, 'confirmarlo': 2432, 'üòä': 2433, 'expo': 2434, 'citizen': 2435, 'mias': 2436, 'üòè': 2437, 'molar√≠a': 2438, 'grupal': 2439, 'spidey': 2440, 'futuro': 2441, 'maridar': 2442, 'organizar': 2443, 'pa√≠s': 2444, 'chancla': 2445, 'asco': 2446, 'harto': 2447, 'menda': 2448, 'eriichii': 2449, 'so': 2450, 'marrana': 2451, 'frios': 2452, 'gafar': 2453, 'chicha': 2454, 'xdd': 2455, 'olimpo': 2456, 'duel': 2457, 'darme': 2458, 'chulo': 2459, 'getwellsoonselenafromspain': 2460, 'oir': 2461, 'haran': 2462, 'wow': 2463, 'acordar': 2464, 'server': 2465, 'orishas': 2466, 'esteis': 2467, 'pet√°ndolo': 2468, 'victorerubio': 2469, 'recomendarme': 2470, 'seguimiento': 2471, 'artistas': 2472, 'internacional': 2473, 'mon√≥logo': 2474, 'rusia': 2475, 'obviamente': 2476, 'mail': 2477, 'molestar': 2478, 'blme': 2479, 'sparks': 2480, 'ia': 2481, 'fue': 2482, 'espaciar': 2483, 'dinamizaci√≥n': 2484, '√∫til': 2485, 'fecho': 2486, 'caducidad': 2487, 'abrumador': 2488, 'erik': 2489, 'esther': 2490, 'üíó': 2491, 'pocas': 2492, 'manera': 2493, 'ocurrir': 2494, 'adicci√≥n': 2495, 'burguer': 2496, 'king': 2497, 'gayumbos': 2498, 'paisano': 2499, 'animal': 2500, 'sentimiento': 2501, 'o√≠r': 2502, 'nini': 2503, 'informaci√≥n': 2504, 'olor': 2505, 'cesar': 2506, 'persiano': 2507, 'quitarte': 2508, 'diversion': 2509, 'vendr√°s': 2510, 'barcelona': 2511, 'tardeparalaira': 2512, 'crack': 2513, 'froot': 2514, 'loops': 2515, 'ofrecer': 2516, 'rivera': 2517, 'pactar': 2518, 'nivea': 2519, 'lanzar': 2520, 'pelota': 2521, 'avioneta': 2522, '25d': 2523, 'sub': 2524, 'campe√≥n': 2525, 'dominar': 2526, 'anular': 2527, 'hablarme': 2528, 'alta': 2529, 'ok': 2530, 'pastilla': 2531, 'bajar': 2532, '36': 2533, 'perdon': 2534, 'dudar': 2535, 'traves': 2536, 'asklfi': 2537, 'ayudaslfi': 2538, 'convocatorio': 2539, 'interesnate': 2540, 'pervertir': 2541, 'viciar': 2542, 'pasa': 2543, 'please': 2544, 'f√≠n': 2545, 'extra': 2546, 'copar': 2547, 'bar': 2548, 'gb': 2549, 'impartir': 2550, 'actor': 2551, 'puesto': 2552, 'paripe': 2553, 'nombre': 2554, 'hsm': 2555, 'digno': 2556, 'cosas': 2557, 'tostar': 2558, 'calentito': 2559, '300': 2560, 'aforo': 2561, 'tienes': 2562, 'conocio': 2563, 'qt': 2564, 'noto': 2565, 'merlu': 2566, 'tiemp': 2567, 'oque': 2568, 'conmigoooooooo': 2569, 'pueblo': 2570, 'piso': 2571, 'documental': 2572, 'pir√°mide': 2573, 'moais': 2574, 'predicci√≥n': 2575, 'donostiarra': 2576, 'quedarse': 2577, 'casita': 2578, 'donostia': 2579, 'preciosa': 2580, 'sab√≠a': 2581, 'casting': 2582, 'buen√≠simo': 2583, 'irrespetuoso': 2584, 'grupo': 2585, '600': 2586, 'triplete': 2587, 'rapar': 2588, 'cero': 2589, 'grabar': 2590, 'jejej': 2591, 'chiringuitopiqu√©': 2592, 'dejarlo': 2593, 'ayay': 2594, 'grrabar': 2595, 'trocito': 2596, 'drown': 2597, 'ukelele': 2598, 'humanidades': 2599, 'lat√≠n': 2600, 'latin': 2601, 'iria': 2602, 'tia': 2603, 'contexto': 2604, 'llevarlas': 2605, 'terreno': 2606}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4AG7tvim1YX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07344fa6-6b8c-4d02-af13-751345cf960d"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(777, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlkmKD_dm1YY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87c8a60d-48ce-4e20-fb6e-5b113be4ca38"
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 15, 375,   6,   8,  61,   9,  26, 490,  37,  18,  22,   8, 804,\n",
              "       491,   2,  64, 216,   6,   7,   9,  40,  65, 805,   0,   0,   0,\n",
              "         0,   0,   0,   0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhSmMZvtm1Ya",
        "outputId": "ea498497-6687-4175-aeef-598e3e10df84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tweets_train.values[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'  estar enamorar y a vez me hacer da√±ar porque se ir a chupar culo de otro perro y no me decir nadar   crisis'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOhVsMTBm1Ya",
        "outputId": "42a8a4eb-36df-4a83-afde-0c3d41293273",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "word_index['despu√©s']"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "290"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1k1ND-9m1Yb",
        "outputId": "6a5567a4-be4b-4b87-87da-14f0d3010278",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(777, 30) (777,)\n",
            "(334, 30) (334,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLW2R67Nm1Yb"
      },
      "source": [
        "## Word embeddins propios\n",
        "Entrenamos una capa de embedding para aprender los WE con los textos de nuestro problema."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R96rc5Wm1Yc",
        "outputId": "e62fdcc8-50b1-4d78-9325-55eeeebb7f55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Creamos el modelo CNN en Keras\n",
        "#Usamos como referencia el ejemplo de Keras: https://github.com/keras-team/keras/blob/master/examples/imdb_cnn.py\n",
        "#pero quitamos la capa oculta intermedia para simplificar el modelo y dejarlo como en el art√≠culo\n",
        "\n",
        "#Par√°metros de la red\n",
        "embed_dim = 50\n",
        "filters = 64\n",
        "kernel_size = 3\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, embed_dim, input_length = MAX_SEQUENCE_LENGTH))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# a√±adimos una capa de convoluci√≥n 1D que aprende\n",
        "# filtros de grupos de palabras de tama√±o kernel_size\n",
        "model.add(Conv1D(filters,\n",
        "                 kernel_size,\n",
        "                 padding='valid',\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "\n",
        "# calculamos el max pooling:\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "# conectamos a una capa de salida de una unidad con activaci√≥n sigmoide\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "# compilamos el modelo\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 30, 50)            130350    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 30, 50)            0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 28, 64)            9664      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 65        \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 140,079\n",
            "Trainable params: 140,079\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6MC-Ryom1Yd"
      },
      "source": [
        "### Pregunta:\n",
        "¬øde d√≥nde vienen los tama√±os de los par√°metros de cada capa?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXRqlqKIm1Ye",
        "outputId": "95ba8e30-c105-45c0-99d5-a3c9c8c93ca6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#soluci√≥n\n",
        "print(max_features * embed_dim)\n",
        "print(filters*embed_dim*kernel_size+filters)\n",
        "print(filters+1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "130350\n",
            "9664\n",
            "65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITjTPA9Xm1Yf",
        "outputId": "144774f0-bb91-4d13-bb44-856b2f4233ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "batch_size = 16\n",
        "history = model.fit(X_train, Y_train, epochs=20, batch_size=batch_size, verbose=2, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "49/49 - 2s - loss: 0.6820 - accuracy: 0.5804 - val_loss: 0.6822 - val_accuracy: 0.5569\n",
            "Epoch 2/20\n",
            "49/49 - 0s - loss: 0.6600 - accuracy: 0.5804 - val_loss: 0.6682 - val_accuracy: 0.5569\n",
            "Epoch 3/20\n",
            "49/49 - 0s - loss: 0.6147 - accuracy: 0.6384 - val_loss: 0.6272 - val_accuracy: 0.6647\n",
            "Epoch 4/20\n",
            "49/49 - 0s - loss: 0.5182 - accuracy: 0.8443 - val_loss: 0.5747 - val_accuracy: 0.7275\n",
            "Epoch 5/20\n",
            "49/49 - 0s - loss: 0.3733 - accuracy: 0.8983 - val_loss: 0.5384 - val_accuracy: 0.7545\n",
            "Epoch 6/20\n",
            "49/49 - 0s - loss: 0.2267 - accuracy: 0.9588 - val_loss: 0.5465 - val_accuracy: 0.7695\n",
            "Epoch 7/20\n",
            "49/49 - 0s - loss: 0.1256 - accuracy: 0.9820 - val_loss: 0.5672 - val_accuracy: 0.7515\n",
            "Epoch 8/20\n",
            "49/49 - 0s - loss: 0.0642 - accuracy: 0.9949 - val_loss: 0.6238 - val_accuracy: 0.7365\n",
            "Epoch 9/20\n",
            "49/49 - 0s - loss: 0.0396 - accuracy: 0.9974 - val_loss: 0.6723 - val_accuracy: 0.7395\n",
            "Epoch 10/20\n",
            "49/49 - 0s - loss: 0.0244 - accuracy: 0.9974 - val_loss: 0.6796 - val_accuracy: 0.7455\n",
            "Epoch 11/20\n",
            "49/49 - 0s - loss: 0.0169 - accuracy: 0.9987 - val_loss: 0.7336 - val_accuracy: 0.7335\n",
            "Epoch 12/20\n",
            "49/49 - 0s - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.7557 - val_accuracy: 0.7275\n",
            "Epoch 13/20\n",
            "49/49 - 0s - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.7878 - val_accuracy: 0.7275\n",
            "Epoch 14/20\n",
            "49/49 - 0s - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.8110 - val_accuracy: 0.7305\n",
            "Epoch 15/20\n",
            "49/49 - 0s - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.8361 - val_accuracy: 0.7425\n",
            "Epoch 16/20\n",
            "49/49 - 0s - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.8485 - val_accuracy: 0.7246\n",
            "Epoch 17/20\n",
            "49/49 - 0s - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.8745 - val_accuracy: 0.7246\n",
            "Epoch 18/20\n",
            "49/49 - 0s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.8911 - val_accuracy: 0.7216\n",
            "Epoch 19/20\n",
            "49/49 - 0s - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.9044 - val_accuracy: 0.7186\n",
            "Epoch 20/20\n",
            "49/49 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.9175 - val_accuracy: 0.7156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF-Ish42m1Yf",
        "outputId": "bda8697f-8d2c-4ab9-9cc3-1baa945c74e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('WE propios')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sY9GYg1m1Yf"
      },
      "source": [
        "#los word embeddings aprendidos son los pesos de la primera capa\n",
        "embeddings=model.get_weights()[0]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNFRGuDqm1Yg",
        "outputId": "c7064046-437f-42a4-a871-c9e08b74cd19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "embeddings.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2607, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFa5jSOJm1Yg",
        "outputId": "010a196c-7528-4567-a95b-2d7f4f686ace",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "embeddings[1]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.06848046, -0.03185182,  0.0217838 , -0.03959312,  0.00657247,\n",
              "       -0.037142  ,  0.01262981, -0.01940588, -0.08902517, -0.03203628,\n",
              "        0.04225971,  0.03595794, -0.01213439, -0.06424483, -0.01469962,\n",
              "       -0.03399598,  0.03240829,  0.0078414 , -0.05154438,  0.0204957 ,\n",
              "        0.0585907 ,  0.02564078, -0.02995742, -0.03373651, -0.04984083,\n",
              "        0.01461077,  0.06644509, -0.02141668,  0.10427225,  0.05907809,\n",
              "        0.01692927,  0.02496457,  0.00951653, -0.0157396 , -0.02677639,\n",
              "        0.02135545,  0.02956246, -0.01711577, -0.02729973,  0.05555876,\n",
              "       -0.01156183,  0.02772356, -0.04483744, -0.02107281, -0.03914533,\n",
              "       -0.01220341, -0.03153637, -0.00764413,  0.01661984,  0.01624751],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zgu8Seqbm1Yg",
        "outputId": "73812d57-1bbd-4e5f-a1e8-4b0fc154ace8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
        "print(\"score: %.2f\" % (score))\n",
        "print(\"acc: %.2f\" % (acc))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21/21 - 0s - loss: 0.9175 - accuracy: 0.7156\n",
            "score: 0.92\n",
            "acc: 0.72\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gG4lacBpm1Yh",
        "outputId": "236c0fca-9b64-477e-c298-82dafc034c52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predict=model.predict(X_test, batch_size=1)\n",
        "prediccion=(predict>0.5).tolist()\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(Y_test, prediccion, target_names=['N','P']))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           N       0.72      0.81      0.76       186\n",
            "           P       0.72      0.59      0.65       148\n",
            "\n",
            "    accuracy                           0.72       334\n",
            "   macro avg       0.72      0.70      0.71       334\n",
            "weighted avg       0.72      0.72      0.71       334\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0spPUPXm1Yh"
      },
      "source": [
        "### Ejercicio 1\n",
        "Introduce una capa densa de 50 neuronas, con un Dropout con p=0.4 y una funci√≥n de activaci√≥n 'ReLU' entre la salida de la capa convolucional (despu√©s del MaxPooling) y la capa de salida. Compila y entrena con un tama√±o de batch de 16 y 20 √©pocas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH-zluONm1Yi",
        "outputId": "efe6f2f3-5878-4f5b-cae9-b916fdacba22",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Soluci√≥n\n",
        "#Creamos el modelo CNN en Keras\n",
        "#Usamos como referencia el ejemplo de Keras: https://github.com/keras-team/keras/blob/master/examples/imdb_cnn.py\n",
        "#pero quitamos la capa oculta intermedia para simplificar el modelo y dejarlo como en el art√≠culo\n",
        "\n",
        "#Par√°metros de la red\n",
        "embed_dim = 50\n",
        "filters = 64\n",
        "kernel_size = 3\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, embed_dim, input_length = MAX_SEQUENCE_LENGTH))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# a√±adimos una capa de convoluci√≥n 1D que aprende\n",
        "# filtros de grupos de palabras de tama√±o kernel_size\n",
        "model.add(Conv1D(filters,\n",
        "                 kernel_size,\n",
        "                 padding='valid',\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "\n",
        "# calculamos el max pooling:\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# conectamos a una capa de salida de una unidad con activaci√≥n sigmoide\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "# compilamos el modelo\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 30, 50)            130350    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 30, 50)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 28, 64)            9664      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 50)                3250      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 51        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 143,315\n",
            "Trainable params: 143,315\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7-TQLwXm1Yj"
      },
      "source": [
        "Compara los resultados con los anteriores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYwmWA0Zm1Yj",
        "outputId": "2ccb4834-e48b-457b-df02-0efd90406d57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "batch_size = 16\n",
        "history = model.fit(X_train, Y_train, epochs=20, batch_size=batch_size, verbose=2, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "49/49 - 1s - loss: 0.6854 - accuracy: 0.5431 - val_loss: 0.6841 - val_accuracy: 0.5569\n",
            "Epoch 2/20\n",
            "49/49 - 0s - loss: 0.6667 - accuracy: 0.5817 - val_loss: 0.6676 - val_accuracy: 0.5569\n",
            "Epoch 3/20\n",
            "49/49 - 0s - loss: 0.6227 - accuracy: 0.6178 - val_loss: 0.6292 - val_accuracy: 0.6647\n",
            "Epoch 4/20\n",
            "49/49 - 0s - loss: 0.5254 - accuracy: 0.8301 - val_loss: 0.5586 - val_accuracy: 0.7246\n",
            "Epoch 5/20\n",
            "49/49 - 0s - loss: 0.3300 - accuracy: 0.9138 - val_loss: 0.5155 - val_accuracy: 0.7575\n",
            "Epoch 6/20\n",
            "49/49 - 0s - loss: 0.1487 - accuracy: 0.9627 - val_loss: 0.5514 - val_accuracy: 0.7665\n",
            "Epoch 7/20\n",
            "49/49 - 0s - loss: 0.0625 - accuracy: 0.9897 - val_loss: 0.6523 - val_accuracy: 0.7485\n",
            "Epoch 8/20\n",
            "49/49 - 0s - loss: 0.0266 - accuracy: 0.9987 - val_loss: 0.6843 - val_accuracy: 0.7425\n",
            "Epoch 9/20\n",
            "49/49 - 0s - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.7541 - val_accuracy: 0.7275\n",
            "Epoch 10/20\n",
            "49/49 - 0s - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.7898 - val_accuracy: 0.7275\n",
            "Epoch 11/20\n",
            "49/49 - 0s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.8143 - val_accuracy: 0.7455\n",
            "Epoch 12/20\n",
            "49/49 - 0s - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.8817 - val_accuracy: 0.7425\n",
            "Epoch 13/20\n",
            "49/49 - 0s - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.8838 - val_accuracy: 0.7455\n",
            "Epoch 14/20\n",
            "49/49 - 0s - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.9134 - val_accuracy: 0.7455\n",
            "Epoch 15/20\n",
            "49/49 - 0s - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.9411 - val_accuracy: 0.7455\n",
            "Epoch 16/20\n",
            "49/49 - 0s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.9683 - val_accuracy: 0.7455\n",
            "Epoch 17/20\n",
            "49/49 - 0s - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.0080 - val_accuracy: 0.7455\n",
            "Epoch 18/20\n",
            "49/49 - 0s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.0103 - val_accuracy: 0.7395\n",
            "Epoch 19/20\n",
            "49/49 - 0s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.0247 - val_accuracy: 0.7425\n",
            "Epoch 20/20\n",
            "49/49 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0321 - val_accuracy: 0.7365\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I2xfYEem1Yj",
        "outputId": "b4291bcb-12be-4608-d1a6-f7335e3058d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
        "print(\"score: %.2f\" % (score))\n",
        "print(\"acc: %.2f\" % (acc))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21/21 - 0s - loss: 1.0321 - accuracy: 0.7365\n",
            "score: 1.03\n",
            "acc: 0.74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyRPhKdTm1Yj",
        "outputId": "e5ce2ee3-0097-44f7-d620-bacdb324468a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('WE propios 2 capas')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cADEO2aFm1Yk",
        "outputId": "868ac15f-86e8-4023-9ad9-8a5565f0cfa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "predict=model.predict(X_test, batch_size=1)\n",
        "prediccion=(predict>0.5).tolist()\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(Y_test, prediccion, target_names=['N','P']))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           N       0.76      0.77      0.76       186\n",
            "           P       0.71      0.70      0.70       148\n",
            "\n",
            "    accuracy                           0.74       334\n",
            "   macro avg       0.73      0.73      0.73       334\n",
            "weighted avg       0.74      0.74      0.74       334\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYaNdn2Ym1Yk"
      },
      "source": [
        "## Word embeddings de spaCy\n",
        "Aplicamos Transfer Learning usando los embeddings GloVe incluidos en el modelo de spaCy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dCP6-CJm1Yl"
      },
      "source": [
        "nlp=spacy.load('es_core_news_md')\n",
        "#Rellenamos los vectores con el valor en spaCy para nuestro vocabulario\n",
        "EMBEDDING_DIM = nlp.vocab.vectors_length\n",
        "embedding_matrix = np.zeros((max_features, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    if(i>max_features):\n",
        "        break\n",
        "    embedding_vector = nlp.vocab[word].vector\n",
        "    if embedding_vector is not None:\n",
        "        # las palabras que no est√°n en spaCy ser√°n cero.\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v91D_aZQm1Ym",
        "outputId": "344f569b-45d3-461a-8ff9-258634e6b602",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "embedding_matrix.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2607, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJZ6UEf9m1Ym",
        "outputId": "b7882048-bf04-4ced-8978-a3172b6202aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Creamos el modelo CNN en Keras\n",
        "\n",
        "#par√°metros de la red\n",
        "filters = 64\n",
        "kernel_size = 3\n",
        "\n",
        "embedding_layer = Embedding(max_features,\n",
        "                            EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=True)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(embedding_layer)\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(filters,\n",
        "                 kernel_size,\n",
        "                 padding='valid',\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 30, 50)            130350    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 30, 50)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 28, 64)            9664      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_2 (Glob (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 140,079\n",
            "Trainable params: 140,079\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq1gJPaDm1Ym",
        "outputId": "6119d000-645a-4e94-ea7a-ca045656b0de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "batch_size = 16\n",
        "history = model.fit(X_train, Y_train, epochs=20, batch_size=batch_size, verbose=2, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "49/49 - 1s - loss: 0.7146 - accuracy: 0.5534 - val_loss: 0.6753 - val_accuracy: 0.5898\n",
            "Epoch 2/20\n",
            "49/49 - 0s - loss: 0.6632 - accuracy: 0.5972 - val_loss: 0.6426 - val_accuracy: 0.6497\n",
            "Epoch 3/20\n",
            "49/49 - 0s - loss: 0.6126 - accuracy: 0.6615 - val_loss: 0.6207 - val_accuracy: 0.6796\n",
            "Epoch 4/20\n",
            "49/49 - 0s - loss: 0.5588 - accuracy: 0.7310 - val_loss: 0.5966 - val_accuracy: 0.7036\n",
            "Epoch 5/20\n",
            "49/49 - 0s - loss: 0.5157 - accuracy: 0.7619 - val_loss: 0.5770 - val_accuracy: 0.7126\n",
            "Epoch 6/20\n",
            "49/49 - 0s - loss: 0.4878 - accuracy: 0.7825 - val_loss: 0.5723 - val_accuracy: 0.7156\n",
            "Epoch 7/20\n",
            "49/49 - 0s - loss: 0.4572 - accuracy: 0.8211 - val_loss: 0.5614 - val_accuracy: 0.7575\n",
            "Epoch 8/20\n",
            "49/49 - 0s - loss: 0.3975 - accuracy: 0.8378 - val_loss: 0.6558 - val_accuracy: 0.6018\n",
            "Epoch 9/20\n",
            "49/49 - 0s - loss: 0.4022 - accuracy: 0.8327 - val_loss: 0.5510 - val_accuracy: 0.7335\n",
            "Epoch 10/20\n",
            "49/49 - 0s - loss: 0.3460 - accuracy: 0.8726 - val_loss: 0.5701 - val_accuracy: 0.7246\n",
            "Epoch 11/20\n",
            "49/49 - 0s - loss: 0.3218 - accuracy: 0.8752 - val_loss: 0.5359 - val_accuracy: 0.7575\n",
            "Epoch 12/20\n",
            "49/49 - 0s - loss: 0.2808 - accuracy: 0.8932 - val_loss: 0.5254 - val_accuracy: 0.7695\n",
            "Epoch 13/20\n",
            "49/49 - 0s - loss: 0.2467 - accuracy: 0.9163 - val_loss: 0.5276 - val_accuracy: 0.7635\n",
            "Epoch 14/20\n",
            "49/49 - 0s - loss: 0.2110 - accuracy: 0.9395 - val_loss: 0.5264 - val_accuracy: 0.7665\n",
            "Epoch 15/20\n",
            "49/49 - 0s - loss: 0.1841 - accuracy: 0.9447 - val_loss: 0.5225 - val_accuracy: 0.7695\n",
            "Epoch 16/20\n",
            "49/49 - 0s - loss: 0.1661 - accuracy: 0.9511 - val_loss: 0.5355 - val_accuracy: 0.7605\n",
            "Epoch 17/20\n",
            "49/49 - 0s - loss: 0.1405 - accuracy: 0.9614 - val_loss: 0.5315 - val_accuracy: 0.7545\n",
            "Epoch 18/20\n",
            "49/49 - 0s - loss: 0.1240 - accuracy: 0.9678 - val_loss: 0.5394 - val_accuracy: 0.7665\n",
            "Epoch 19/20\n",
            "49/49 - 0s - loss: 0.1034 - accuracy: 0.9768 - val_loss: 0.5438 - val_accuracy: 0.7575\n",
            "Epoch 20/20\n",
            "49/49 - 0s - loss: 0.0976 - accuracy: 0.9781 - val_loss: 0.5702 - val_accuracy: 0.7425\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49864FO2m1Yn"
      },
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('TF con WE spaCy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7swNmJkm1Yn"
      },
      "source": [
        "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
        "print(\"score: %.2f\" % (score))\n",
        "print(\"acc: %.2f\" % (acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-uRtOw3m1Yn"
      },
      "source": [
        "predict=model.predict(X_test, batch_size=1)\n",
        "prediccion=(predict>0.5).tolist()\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(Y_test, prediccion, target_names=['N','P']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JLdT8oGm1Yn"
      },
      "source": [
        "### Word embeddings de FastText\n",
        "Podemos usar cualquier conjunto de *word embeddings* con el formato `KeyedVectors` de Gensim para hacer Transfer Learning.  \n",
        "WE descargados desde https://fasttext.cc/docs/en/crawl-vectors.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVAVR65rm1Yo"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "modelWE = KeyedVectors.load_word2vec_format('/Users/jovifran/Downloads/fasttext-sbwc.100k.vec')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNGTWqK-m1Yo"
      },
      "source": [
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "#https://github.com/mquezada/starsconf2018-word-embeddings\n",
        "modelWE = KeyedVectors.load_word2vec_format('~/Downloads/fasttext-sbwc.100k.vec')\n",
        "\n",
        "EMBEDDING_DIM = modelWE.vector_size\n",
        "\n",
        "embedding_matrix = np.zeros((max_features, EMBEDDING_DIM))\n",
        "vectores = 0\n",
        "for word, i in word_index.items():\n",
        "    if(i<max_features):\n",
        "        try:\n",
        "            embedding_vector = modelWE[word]\n",
        "        except:\n",
        "            embedding_vector = np.zeros(EMBEDDING_DIM)\n",
        "            # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        vectores += 1\n",
        "        \n",
        "print(\"Cargados {} vectores en la matriz\".format(vectores))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJVnL695m1Yo"
      },
      "source": [
        "max_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgegNivkm1Yp"
      },
      "source": [
        "embedding_matrix.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2urjHZrm1Yp"
      },
      "source": [
        "#Creamos el modelo CNN en Keras\n",
        "\n",
        "#par√°metros de la red\n",
        "filters = 64\n",
        "kernel_size = 3\n",
        "\n",
        "embedding_layer = Embedding(max_features,\n",
        "                            EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=True)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(embedding_layer)\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv1D(filters,\n",
        "                 kernel_size,\n",
        "                 padding='valid',\n",
        "                 activation='relu',\n",
        "                 strides=1))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RY81JFXm1Yp"
      },
      "source": [
        "batch_size = 16\n",
        "history = model.fit(X_train, Y_train, epochs=20, batch_size=batch_size, verbose=2, validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68zWy5EYm1Yp"
      },
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('TF con WE FastText')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NA9pjK47m1Yq"
      },
      "source": [
        "score,acc = model.evaluate(X_test, Y_test, verbose = 2, batch_size = batch_size)\n",
        "print(\"score: %.2f\" % (score))\n",
        "print(\"acc: %.2f\" % (acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7yiBWidm1Yq"
      },
      "source": [
        "predict=model.predict(X_test, batch_size=1)\n",
        "prediccion=(predict>0.5).tolist()\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(Y_test, prediccion, target_names=['N','P']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1FXatP1m1Ys"
      },
      "source": [
        "### Inferencia en nuevos textos\n",
        "\n",
        "Si queremos utilizar el clasificador con un texto nuevo hay que procesar el texto con la misma secuencia: limpieza, tokenizado y conversi√≥n en secuencia de la longitud adecuada:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnsBg0tlm1Ys"
      },
      "source": [
        "twt = 'estoy triste con el partido'\n",
        "#vectorizing the tweet by the pre-fitted tokenizer instance\n",
        "twt = tokenizer.texts_to_sequences([clean_text(twt, lemas=True)]) #hay que pasar el texto a array\n",
        "#padding the tweet to have exactly the same shape as `embedding_2` input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OprP5Z-hm1Ys"
      },
      "source": [
        "twt = pad_sequences(twt, maxlen=X_train.shape[1], dtype='int32', padding='post', truncating='post', value=0)\n",
        "sentiment = model.predict(twt,batch_size=1,verbose = 2)\n",
        "if(np.round(sentiment) == 0):\n",
        "    print(\"negativo\")\n",
        "elif (np.round(sentiment) == 1):\n",
        "    print(\"positivo\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxfxU3Vwm1Yt"
      },
      "source": [
        "### Ejercicio 2\n",
        "Repite el entrenamiento con la capa de embeddings de spaCy con `trainable = True` y compara los resultados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3T_90Sim1Yt"
      },
      "source": [
        "## Soluci√≥n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}