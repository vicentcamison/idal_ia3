{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "NLP_12-Búsqueda_LSI.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vicentcamison/idal_ia3/blob/main/5%20Procesado%20del%20lenguaje%20natural/Sesion%203/NLP_12_Bu%CC%81squeda_LSI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfwVDP03nrM8"
      },
      "source": [
        "# Búsqueda de texto (*information retrieval*)\n",
        "Vamos a usar el algoritmo LSI para realizar una búsqueda indexada de textos similares.\n",
        "### Cargamos librerías"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrsP4AhvnrNI"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "\n",
        "# Gensim\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "\n",
        "from gensim.models import TfidfModel, LsiModel\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# spacy para lematizar\n",
        "import spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4NsTySKnrNK"
      },
      "source": [
        "Utilizamos un generador para obtener los documentos del Corpus línea a línea desde el archivo del conjunto de ejemplo y convertirlos en un listado de tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Q-01xjfnrNL"
      },
      "source": [
        "nlp = spacy.load('en_core_web_md', disable=['parser', 'ner'])\n",
        "stop_words = [word.text for word in nlp.vocab if word.is_stop] #listado de stop-words\n",
        "\n",
        "def lemmatize_doc(text, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"Función que devuelve el lema de una string,\n",
        "    excluyendo las palabras cuyo POS_TAG no está en la lista\"\"\"\n",
        "    text_out = [token.lemma_.lower() for token in nlp(text) if token.pos_ in allowed_postags and len(token.lemma_)>3]\n",
        "    return text_out\n",
        "\n",
        "class PreprocesaArchivo(object):\n",
        "    \"\"\"Pre-procesa un archivo de texto línea a línea\n",
        "    Entrada: nombre del archivo de texto a procesar (string)\n",
        "    Salida: iterador sobre cada línea normalizado (lista de tokens)\"\"\"\n",
        "    def __init__(self, filename):\n",
        "        self.filename = filename\n",
        " \n",
        "    def __iter__(self):\n",
        "        with open(self.filename) as f:\n",
        "            for line in f:\n",
        "                yield lemmatize_doc(line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgzEMJlSnrNM"
      },
      "source": [
        "data_dir = '{}'.format(os.sep).join([gensim.__path__[0], 'test', 'test_data'])\n",
        "lee_data_file = data_dir + os.sep + 'lee_background.cor'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0K_vE6hnrNM"
      },
      "source": [
        "texto=PreprocesaArchivo(lee_data_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6g-AclrnrNN"
      },
      "source": [
        "### Creamos bigramas y trigramas\n",
        "Creamos un modelo para las palabras más frecuentes como bigrama o trigrama para considerar estos tokens juntos en lugar de separados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdjvL3qwnrNO"
      },
      "source": [
        "#creamos bigramas y trigramas\n",
        "bigram = gensim.models.Phrases(texto, min_count=5, threshold=50) # higher threshold fewer phrases.\n",
        "#optimizamos una vez entreando\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "\n",
        "trigram = gensim.models.Phrases(bigram_mod[texto], min_count=5, threshold=50)  \n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "\n",
        "def make_trigrams(text):\n",
        "    '''Devuelve un doc convertido en trigramas según el\n",
        "    modelo trigram_mod. La entrada tiene que ser una lista\n",
        "    de de tokens'''\n",
        "    return trigram_mod[bigram_mod[text]]\n",
        "\n",
        "class TrigramCorpus(object):\n",
        "    \"\"\"Pre-procesa un archivo de texto línea a línea\n",
        "    Entrada: nombre del archivo de texto a procesar (string)\n",
        "    Salida: iterador sobre cada línea normalizado (lista de tokens)\"\"\"\n",
        "    def __init__(self, corpus):\n",
        "        self.corpus = corpus\n",
        " \n",
        "    def __iter__(self):\n",
        "        for t in self.corpus:\n",
        "            yield make_trigrams(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELwdHYBynrNP"
      },
      "source": [
        "Transformamos el corpus de texto con el modelo de trigramas. Creamos un `generador` para no cargar todo el corpus procesado en memoria."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAEPo9vgnrNP"
      },
      "source": [
        "textos_trigramas = TrigramCorpus(texto) #aplica modelo trigramas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gizVnwQLnrNQ"
      },
      "source": [
        "### Creamos el diccionario y el corpus para Topic Modeling\n",
        "Las dos entradas para el modelo LDA son un diccionario (id2word) y un corpus de `gensim`.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJgcaevwnrNT"
      },
      "source": [
        "#para no tener que cargar todo el corpus en memoria creamos un streamer\n",
        "class BOW_Corpus(object):\n",
        "    \"\"\"\n",
        "    Iterable: en cada iteración devuelve el vector bag-of-words\n",
        "    del siguiente documento en el corpus.\n",
        "    \n",
        "    Procesa un documento cada vez usando un generator, así\n",
        "    nunca carga el corpus entero en RAM.\n",
        "    \"\"\"\n",
        "    def __init__(self, corpus):\n",
        "        self.corpus = corpus\n",
        "        #crea el diccionario = mapeo de documentos a sparse vectors\n",
        "        self.diccionario = gensim.corpora.Dictionary(corpus)\n",
        " \n",
        "    def __iter__(self):\n",
        "        \"\"\"\n",
        "        __iter__ es un generator => TxtSubdirsCorpus es un streamed iterable.\n",
        "        \"\"\"\n",
        "        for tokens in self.corpus:\n",
        "            # transforma cada doc (lista de tokens) en un vector sparse uno a uno\n",
        "            yield self.diccionario.doc2bow(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znxuYPjInrNT"
      },
      "source": [
        "corpus_bow = BOW_Corpus(textos_trigramas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHuD5Z2qnrNU"
      },
      "source": [
        "Recuerda que en el modelo BoW de `gensim` el primer elemento de cada tupla es el ID del término en el diccionario, y el segundo su frecuencia en el doc.  \n",
        "`diccionario[ID]` devuelve el término con índice ID en el vocabulario:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jXCjtCenrNU",
        "outputId": "53485ed3-58c5-4989-a8f6-84d24daf6114"
      },
      "source": [
        "len(corpus_bow.diccionario.token2id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3893"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgH68A6QnrNW"
      },
      "source": [
        "## Topic modeling\n",
        "\n",
        "### Modelo LSI\n",
        "Este modelo ordena los temas y saca un listado ordenado. Hay que especificar el número de topics.  \n",
        "Este modelo se calcula a partir de la matriz TF-IDF."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bkwsQcYnrNX"
      },
      "source": [
        "modelo_tfidf = TfidfModel(corpus_bow)\n",
        "corpus_tfidf = modelo_tfidf[corpus_bow]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kShXLm-lnrNX"
      },
      "source": [
        "lsimodel = LsiModel(corpus=corpus_tfidf, num_topics=100, id2word=corpus_bow.diccionario)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Lq1YGsbnrNY",
        "outputId": "f4889932-a7d2-4ba4-e7e4-89deb5f2c906"
      },
      "source": [
        "for c in corpus_tfidf:\n",
        "    print(lsimodel[c])\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, -0.2251407755258509), (1, -0.05589503255567473), (2, -0.002034551814245636), (3, -0.3593856462694006), (4, -0.28754330493655716), (5, 0.08107965643463073), (6, -0.080779156190972), (7, 0.1837984676332464), (8, 0.10152403453856364), (9, -0.08102866088669473), (10, -0.11996943236579523), (11, -0.0060285766977523445), (12, -0.029952780313636247), (13, -0.027187161104453246), (14, -0.07220274933336726), (15, -0.11674557418450958), (16, -0.06134103094887532), (17, -0.06612417144054032), (18, -0.12308969044055872), (19, 0.03399998170571504), (20, 0.005729132412297129), (21, 0.07489768934899206), (22, 0.0896517880076868), (23, -0.04938688915250265), (24, -0.03893218375433099), (25, -0.050089719015085014), (26, 0.0045414665732406625), (27, 0.05036297587865491), (28, 0.03238253066154584), (29, 0.08754126488999821), (30, -0.02747752826308267), (31, 0.040902897373087485), (32, 0.03684836491905905), (33, 0.019704835036649954), (34, 0.005582368474545655), (35, 0.06013677329826353), (36, 0.028923539029123008), (37, 0.038123297878896074), (38, 0.014835919706799447), (39, -0.007155608970228312), (40, 0.04989584364144332), (41, 0.03507863182054586), (42, 0.00150695972851195), (43, -0.005680469540683727), (44, 0.057511604759415996), (45, 0.013950734019816273), (46, -0.004649021461472955), (47, -0.026899130670102495), (48, -0.005540088289839725), (49, -0.002725283355232607), (50, -0.005798530687354626), (51, -0.006293035420106603), (52, 0.019773445905949663), (53, -0.024161734552758888), (54, -0.01089768996562822), (55, -0.00252273735374158), (56, -0.022726968562665345), (57, 0.007879692532794767), (58, -0.028283695152647764), (59, -0.026668121188810075), (60, -0.06773772788473194), (61, 0.02578732787960654), (62, -0.03749044026358682), (63, -0.046097363972943596), (64, 0.04420753287836267), (65, -0.09019130034066641), (66, -0.0010830839646192851), (67, -0.03217166263428042), (68, -0.03273016888290741), (69, 0.04469888924566752), (70, 0.0075559718787254395), (71, -0.02622369374443645), (72, 0.039853086201199955), (73, -0.006562302608598936), (74, -0.033019796261648984), (75, -0.0524551390539761), (76, -0.04434677936080704), (77, 0.007594835703276945), (78, -0.04964346384307827), (79, -0.03592406267845401), (80, 0.017013537337888206), (81, 0.06837921360227864), (82, 0.01650627761311811), (83, 0.003887416768984952), (84, 0.018979410988298164), (85, 0.04792635135439809), (86, -0.0762815839859965), (87, -0.00857871055900113), (88, 0.04484747510604749), (89, -0.011342785662583184), (90, 0.024490140498532195), (91, 0.03381214599162832), (92, 0.02432075839710708), (93, 0.01954517848789836), (94, 0.011148061220351925), (95, 0.010207322227617626), (96, 0.020950361043352028), (97, -0.04360564041045631), (98, 0.016721660839039327), (99, 0.09595836981285184)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yhmtcwDnrNY"
      },
      "source": [
        "##  Búsqueda de documentos por temática (*information retrieval*)\n",
        "Para buscar los documentos más similares a un documento dado, hay que trabajar con el modelo *space vector* generado por el algoritmo LSI. Primero, generamos una matriz LSI para todos los documentos del corpus. Para buscar el documento más parecido a un nuevo texto, calculamos su vector LSI y buscamos cuál es el más cercano dentro de la matriz LSI del corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1z0WOIWunrNZ"
      },
      "source": [
        "#creamos un índice de similitud entre los documentos del corpus\n",
        "from gensim.similarities import MatrixSimilarity\n",
        "\n",
        "#creamos corpus transformado\n",
        "lsi_corpus = lsimodel[corpus_tfidf]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjYBMHbknrNZ",
        "outputId": "d6d23b57-42cc-44e0-b222-8486e9efc74c"
      },
      "source": [
        "lsi_corpus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.interfaces.TransformedCorpus at 0x7f8db6de2460>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mq2a-kCznrNa"
      },
      "source": [
        "#creamos índice\n",
        "lsi_corpus = list(lsi_corpus) #hay que pasarlo a una lista en memoria\n",
        "index = MatrixSimilarity(lsi_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OUdCnRanrNa",
        "outputId": "a27c392c-76b3-43e4-9634-81c4c965a399"
      },
      "source": [
        "index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.similarities.docsim.MatrixSimilarity at 0x7f8db7a57ee0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHfM3gwunrNa"
      },
      "source": [
        "Podemos ver la similitud de cualquier documento del corpus al resto de documentos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M227CKqenrNb"
      },
      "source": [
        "Esta matriz de similaridad usa (300 vectores de 100 componentes, con el grado de pertenencia de acda documento a cada una de las dimensiones). \n",
        "\n",
        "Guarda la similitud de cada documento con cada uno de los 299 restantes, utilizando la similitud coseno de los vectores de documentos asociados a cada documento (recordemos que cada documento lo hemos 'representado' como un conjunto de 100 valores/componentes)\n",
        "\n",
        "Por ejemplo, tal y como se puede apreciar en la celda siguiente en la que se ven las similaridades con el documento 1, la similitud entre el documento 0 y el 1 es de alrededor de 0.1, la similitud entre el documento 1 y el 1 es de prácticamente 1, la similitud entre el documento 1 y 2 es de en torno a 0.015"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJtAYMiOnrNb",
        "outputId": "87550728-60d7-4175-ad73-9779b84bb723"
      },
      "source": [
        "sims = index[lsi_corpus[1]]\n",
        "print(list(enumerate(sims)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, 0.096995465), (1, 0.99999994), (2, 0.016084313), (3, 0.036357336), (4, -0.005169048), (5, 0.035257604), (6, 0.07894909), (7, -0.019114595), (8, 0.048595857), (9, 0.10794885), (10, 0.067132495), (11, 0.015211977), (12, 0.5141053), (13, -0.022404313), (14, 0.056497663), (15, 0.0024327785), (16, 0.0017246548), (17, 0.026247222), (18, 0.016068885), (19, -0.0411802), (20, -0.037240278), (21, 0.019896697), (22, 0.009519938), (23, 0.012997538), (24, 0.077828035), (25, 0.035765894), (26, 0.4104902), (27, 0.016949251), (28, 0.03527139), (29, 0.029354021), (30, -0.015645945), (31, 0.10353141), (32, -0.03771535), (33, 0.1224274), (34, 0.6077539), (35, 0.06483999), (36, 0.14475338), (37, 0.058779977), (38, 0.039481375), (39, 0.003149828), (40, 0.09460867), (41, 0.26310873), (42, 0.017722148), (43, 0.023563396), (44, 0.049257606), (45, 0.03996374), (46, 0.043322645), (47, 0.08864278), (48, 0.092150636), (49, 0.037699647), (50, 0.09577018), (51, 0.07028355), (52, 0.014994817), (53, 0.022919115), (54, 0.032882553), (55, 0.1412149), (56, 0.047004264), (57, -0.0024883226), (58, 0.06728552), (59, 0.0074145272), (60, 0.26064992), (61, 0.026602017), (62, -0.028269775), (63, 0.018066935), (64, -0.053822584), (65, 0.021608133), (66, -0.015230134), (67, 0.010270365), (68, 0.0071339905), (69, 0.040139887), (70, 0.054278616), (71, -0.008770142), (72, 0.0111318305), (73, 0.11530006), (74, 0.1470344), (75, 0.19771618), (76, 0.05378429), (77, 0.11721056), (78, 0.060574368), (79, 0.091613695), (80, 0.03326767), (81, 0.20415741), (82, 0.18201552), (83, -0.03886522), (84, 0.015271168), (85, 0.5060218), (86, 0.10791756), (87, 0.004565932), (88, 0.25430033), (89, 0.17396185), (90, 0.047766842), (91, 0.048869696), (92, 0.0036464483), (93, 0.081789345), (94, 0.03637265), (95, 0.104134925), (96, -0.037104484), (97, 0.09935556), (98, 0.09819894), (99, 0.0065583847), (100, 0.015373331), (101, -0.0015715584), (102, 0.0058790892), (103, 0.04310727), (104, 0.08211294), (105, 0.04819029), (106, 0.06254116), (107, 0.09643398), (108, -0.03019815), (109, -0.015362719), (110, 0.08350843), (111, -0.020194795), (112, 0.08211294), (113, -0.030782651), (114, 0.08793543), (115, -0.0021129698), (116, 0.320574), (117, 0.07033936), (118, 0.020131491), (119, -0.0021129698), (120, 0.07033936), (121, 0.0563514), (122, 0.10270376), (123, 0.014118087), (124, -0.04178904), (125, 0.056223456), (126, 0.15191539), (127, 0.0713197), (128, 0.006341882), (129, 0.03247583), (130, 0.012298404), (131, 0.09872787), (132, 0.0017002337), (133, 0.10609014), (134, 0.057506964), (135, 0.034912627), (136, 0.08374377), (137, 0.023257595), (138, 0.048838466), (139, 0.008987937), (140, 0.05817204), (141, 0.28305617), (142, 0.02167384), (143, 0.67422736), (144, 0.08188015), (145, 0.25938675), (146, 0.010316493), (147, 0.17762163), (148, -0.043777622), (149, -0.04176155), (150, 0.015771441), (151, 0.0017445683), (152, 0.26518828), (153, 0.08944491), (154, -0.0020256937), (155, -0.005734112), (156, 0.015771441), (157, 0.058588628), (158, -0.017566498), (159, 0.090263076), (160, 0.059542097), (161, 0.0016001016), (162, -0.014582273), (163, 0.062408313), (164, -0.003215678), (165, -0.0133503415), (166, 0.03721997), (167, 0.06754504), (168, 0.010222595), (169, 0.08613244), (170, 0.063251525), (171, 0.05851537), (172, 0.063040294), (173, 0.08562249), (174, 0.04404561), (175, -0.0102592595), (176, 0.18767208), (177, 0.26556504), (178, -0.026557975), (179, 0.08649775), (180, 0.024086349), (181, -0.004100552), (182, 0.008947235), (183, 0.030395806), (184, 0.06421929), (185, 0.004228104), (186, 0.06880748), (187, -0.012941122), (188, 0.08305551), (189, 0.011926133), (190, -0.03375365), (191, -0.00064448826), (192, 0.24323371), (193, 0.059826743), (194, 0.090659), (195, -0.0384603), (196, 0.0009340234), (197, 0.19309254), (198, 0.07581567), (199, 0.010760836), (200, 0.27072135), (201, 0.12924), (202, -0.022245614), (203, 0.0030624904), (204, 0.052651085), (205, 0.072672755), (206, 0.011183348), (207, 0.044928502), (208, 0.16094708), (209, 0.038092554), (210, 0.08355014), (211, 0.098517925), (212, 0.07798571), (213, 0.06206147), (214, -0.0044966117), (215, -0.037305597), (216, 0.08493404), (217, 0.18523344), (218, 0.0197711), (219, 0.080347255), (220, 0.30432057), (221, -0.010096563), (222, 0.059237443), (223, 0.11475714), (224, 0.035569735), (225, -0.021451548), (226, 0.08838283), (227, 0.31225094), (228, -0.05506201), (229, -0.06794149), (230, -0.011950105), (231, 0.060946934), (232, 0.020131893), (233, 0.0895853), (234, 0.15654188), (235, 0.2750702), (236, -0.011950105), (237, 0.0780135), (238, 0.00013613328), (239, 0.043124847), (240, 0.11730881), (241, 0.019532993), (242, 0.009955827), (243, 0.021031983), (244, 0.023268122), (245, -0.0029240064), (246, 0.0025779717), (247, 0.029984124), (248, 0.014339767), (249, 0.08714886), (250, 0.19943158), (251, 0.08885008), (252, 0.031446718), (253, 0.0018934049), (254, 0.113292426), (255, 0.03660013), (256, -0.0028755441), (257, 0.06449884), (258, 0.034516655), (259, 0.17416087), (260, 0.03953573), (261, -0.014163405), (262, 0.0239769), (263, 0.07786335), (264, 0.031736042), (265, 0.008624934), (266, 0.06278866), (267, 0.22221372), (268, 0.1605737), (269, 0.09019502), (270, 0.101693496), (271, 0.07786335), (272, 0.037394457), (273, 0.04880465), (274, 0.0840659), (275, 0.036170755), (276, 0.16519977), (277, 0.2564463), (278, -0.013398945), (279, 0.08389334), (280, 0.014991872), (281, 0.0261174), (282, -0.00810045), (283, 0.10567321), (284, 0.19035968), (285, 0.0181944), (286, 0.17329384), (287, 0.013317086), (288, 0.0261174), (289, 0.014642119), (290, 0.011395562), (291, -0.004757352), (292, 0.05943571), (293, -0.010900499), (294, 0.016944535), (295, 0.09226909), (296, -0.010921076), (297, 0.12507465), (298, -0.06714591), (299, 0.026433934)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDOpNRlrnrNb",
        "outputId": "9542b40f-da60-4d87-df38-d263bd1dd0d9"
      },
      "source": [
        "#nos quedamos con los 10 primeros\n",
        "sims_sorted = sorted(enumerate(sims), key=lambda item: -item[1])\n",
        "print(sims_sorted[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(1, 0.99999994), (143, 0.67422736), (34, 0.6077539), (12, 0.5141053), (85, 0.5060218), (26, 0.4104902), (116, 0.320574), (227, 0.31225094), (220, 0.30432057), (141, 0.28305617)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9Ft6yGtnrNc"
      },
      "source": [
        "También podemos calcular el documento más similar dentro del corpus a un nuevo documento calculando primero su matriz TF-IDF/BoW y luego transformando a matriz LSI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ooN8wnJnrNc"
      },
      "source": [
        "new_doc = \"the new pakistan government falled in the terrorist attack by the islamic group hamas\"\n",
        "texto_lemmatizados = lemmatize_doc(new_doc)\n",
        "texto = make_trigrams(texto_lemmatizados)\n",
        "corpus_new = corpus_bow.diccionario.doc2bow(texto)\n",
        "lsi_corpus_new = lsimodel[corpus_new]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49AuG2ounrNd",
        "outputId": "c337c1aa-2d48-402f-8c37-6fb5a874fb2e"
      },
      "source": [
        "texto"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pakistan',\n",
              " 'government',\n",
              " 'fall',\n",
              " 'terrorist',\n",
              " 'attack',\n",
              " 'islamic',\n",
              " 'group',\n",
              " 'hamas']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyyPY3qanrNd",
        "outputId": "ac18498d-06b1-48ee-ae83-f9a83c88564d"
      },
      "source": [
        "print(lsi_corpus_new)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, -0.3613815479095896), (1, 0.19534752064686686), (2, -0.029855132428111643), (3, 0.01212041010484912), (4, 0.10984006678292624), (5, -0.0886267872635145), (6, 0.06598682864671415), (7, 0.05025922017894794), (8, 0.060260259573719804), (9, 0.12579025371953695), (10, 0.11260553943861919), (11, -0.05871609642986213), (12, -0.1741038616392151), (13, 0.028063100517521047), (14, 0.19478652390968715), (15, -0.02756769221077642), (16, -0.03704635354393259), (17, -0.14737547872746043), (18, -0.07309591948875903), (19, -0.05835029377225188), (20, 0.1924322965556895), (21, 0.0651554227036181), (22, 0.004326856838880198), (23, -0.027770096801394376), (24, 0.10000302434515991), (25, -0.07779878817932762), (26, 0.005529697593091548), (27, -0.07859458931789867), (28, -0.018084791489868492), (29, -0.06634210806356522), (30, -0.01695578625547719), (31, -0.055814108277498886), (32, 0.07323225219422785), (33, 0.15452653670404437), (34, -0.057824185136652814), (35, 0.1787275396770587), (36, -0.0025635734858478875), (37, 0.01797870568125349), (38, 0.17689355406928328), (39, -0.04619309740449249), (40, -0.10141487537651518), (41, 0.13898601175780773), (42, -0.06086171881985057), (43, 0.08120449398438746), (44, 0.1269894334856951), (45, 0.03823697747302919), (46, 0.04484583197087973), (47, 0.04782213168663807), (48, -0.1113122807967556), (49, -0.08613898310934243), (50, 0.07285096924505592), (51, 0.03875282128008876), (52, -0.15814379755385524), (53, -0.13615256226538175), (54, 0.06190637296708088), (55, -0.04982674451764171), (56, -0.18575277155307024), (57, -0.04686451164779265), (58, 0.13421990747984638), (59, -0.07293592622010624), (60, 0.04293310083582508), (61, -0.05429794422417898), (62, -0.02672134375005772), (63, -0.20384917470559677), (64, 0.13452565424578672), (65, -0.08100914237388536), (66, -0.058122041718428816), (67, 0.02291268814988765), (68, 0.009429133115644278), (69, -0.01699124098435588), (70, 0.014845031715819988), (71, -0.08159789730728875), (72, -0.019741716963251957), (73, -0.05017074819915042), (74, -0.06844549405834016), (75, -0.07110457665003725), (76, -0.11203914204489807), (77, 0.06869812591085431), (78, 0.04994047767488148), (79, 0.11683117326463763), (80, -0.028789797630118498), (81, 0.09918549376175403), (82, 0.003309146832487494), (83, 0.02736738232284003), (84, 0.0135250342062414), (85, 0.01288516623118105), (86, 0.04637006071698443), (87, 0.041208840176363976), (88, -0.026065111087230676), (89, 0.07605412177499853), (90, -0.09624199466812017), (91, -0.033741729415811605), (92, -0.021831772475646858), (93, 0.08152033448193668), (94, -0.11366603928136627), (95, 0.0123168395655669), (96, 0.03561440066162359), (97, -0.009403554611236088), (98, 0.037400895502899156), (99, -0.054535267651057415)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaNni7gEnrNd"
      },
      "source": [
        "Ahora buscamos en el índice cuáles son los documentos más parecidos dentro del corpus al nuevo documento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SW-LWK1nrNd",
        "outputId": "d1039c3e-c01e-48e3-9e7c-6e0f6631365b"
      },
      "source": [
        "sims = index[lsi_corpus_new]\n",
        "sims_sorted = sorted(enumerate(sims), key=lambda item: -item[1])\n",
        "print(sims_sorted[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(143, 0.5675734), (267, 0.46883836), (160, 0.4677524), (60, 0.43944794), (116, 0.4372841), (75, 0.41249728), (1, 0.39473557), (217, 0.37357435), (223, 0.36711973), (197, 0.3669526)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CA7M_kMVnrNe"
      },
      "source": [
        "El texto del documento más cercano es:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRO0PsOtnrNe",
        "outputId": "ef52336f-6ccb-4fa9-bca5-7659734c7746"
      },
      "source": [
        "with open(lee_data_file) as f:\n",
        "    textos = f.readlines()\n",
        "print(textos[sims_sorted[0][0]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Kashmiri militant groups denied involvement in Thursday's attack on the Indian Parliament, accusing Indian intelligence instead. \"We want to make it clear that Kashmiris have no connection with this attack,\" said the Muttahida Jihad Council (MJC), an alliance of 18 groups fighting Indian rule in Kashmir. \"We believe it was carried out by Indian intelligence agencies to achieve their motives about the Kashmir issue,\" the groups added in a statement. The attack on the Parliament building in New Delhi left at least 12 dead. The Indian authorities have not said who they believe was behind the killings. But the Kashmiri groups accused the Indian Government of masterminding the attack in a bid to divert attention from what they called increasing international pressure over Kashmir. \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kosFhr51nrNg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}