{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "01-cats_and_dogs_SIN_DATA_AUGMENTATION.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vicentcamison/idal_ia3/blob/main/2%20Aprendizaje%20profundo%20(I)/Sesion%204/01_cats_and_dogs_SIN_DATA_AUGMENTATION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrIBQZFhdEf_"
      },
      "source": [
        "COLAB = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CJTDGuDWa3M"
      },
      "source": [
        "# En parte de:\n",
        "# https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W68hFjybWa3P"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from keras.models import Sequential, load_model, Model\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import regularizers\n",
        "from keras import optimizers\n",
        "from keras import models\n",
        "from glob import glob\n",
        "import cv2\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from IPython.display import SVG, display, clear_output\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GXDzz3bTLMV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68821313-e375-426b-c07a-648fa6702c61"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-8gOCujdP37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b04d38d7-a0bc-4bb9-d64b-10f376a429e7"
      },
      "source": [
        "if COLAB:\n",
        "    from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "    gdd.download_file_from_google_drive(file_id='1CpfC-e5doyIQUXoaOUMDLeTL7EKR9UMu',\n",
        "                                        dest_path='./small_data.zip', unzip=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1CpfC-e5doyIQUXoaOUMDLeTL7EKR9UMu into ./small_data.zip... Done.\n",
            "Unzipping...Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Tb3C1EgWz1r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f430be7-5245-48a8-bb9e-4f6215a52dc5"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__MACOSX  sample_data  small_data  small_data.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJlZPaYmW22d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47bdd11b-1900-400d-8664-38fa61adf406"
      },
      "source": [
        "!ls small_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test0  train  validation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "walL9rvWW6Lf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75cfc7e1-89ce-4abd-f3c4-ebb13bf42859"
      },
      "source": [
        "!ls small_data/train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cats  dogs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl15faNNW88L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f407d43-e063-44dd-aa46-b2a7e9fa5109"
      },
      "source": [
        "!ls small_data/train/cats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cat.0.jpg    cat.250.jpg  cat.400.jpg  cat.551.jpg  cat.701.jpg  cat.852.jpg\n",
            "cat.100.jpg  cat.251.jpg  cat.401.jpg  cat.552.jpg  cat.702.jpg  cat.853.jpg\n",
            "cat.101.jpg  cat.252.jpg  cat.402.jpg  cat.553.jpg  cat.703.jpg  cat.854.jpg\n",
            "cat.102.jpg  cat.253.jpg  cat.403.jpg  cat.554.jpg  cat.704.jpg  cat.855.jpg\n",
            "cat.103.jpg  cat.254.jpg  cat.404.jpg  cat.555.jpg  cat.705.jpg  cat.856.jpg\n",
            "cat.104.jpg  cat.255.jpg  cat.405.jpg  cat.556.jpg  cat.706.jpg  cat.857.jpg\n",
            "cat.105.jpg  cat.256.jpg  cat.406.jpg  cat.557.jpg  cat.707.jpg  cat.858.jpg\n",
            "cat.106.jpg  cat.257.jpg  cat.407.jpg  cat.558.jpg  cat.708.jpg  cat.859.jpg\n",
            "cat.107.jpg  cat.258.jpg  cat.408.jpg  cat.559.jpg  cat.709.jpg  cat.85.jpg\n",
            "cat.108.jpg  cat.259.jpg  cat.409.jpg  cat.55.jpg   cat.70.jpg\t cat.860.jpg\n",
            "cat.109.jpg  cat.25.jpg   cat.40.jpg   cat.560.jpg  cat.710.jpg  cat.861.jpg\n",
            "cat.10.jpg   cat.260.jpg  cat.410.jpg  cat.561.jpg  cat.711.jpg  cat.862.jpg\n",
            "cat.110.jpg  cat.261.jpg  cat.411.jpg  cat.562.jpg  cat.712.jpg  cat.863.jpg\n",
            "cat.111.jpg  cat.262.jpg  cat.412.jpg  cat.563.jpg  cat.713.jpg  cat.864.jpg\n",
            "cat.112.jpg  cat.263.jpg  cat.413.jpg  cat.564.jpg  cat.714.jpg  cat.865.jpg\n",
            "cat.113.jpg  cat.264.jpg  cat.414.jpg  cat.565.jpg  cat.715.jpg  cat.866.jpg\n",
            "cat.114.jpg  cat.265.jpg  cat.415.jpg  cat.566.jpg  cat.716.jpg  cat.867.jpg\n",
            "cat.115.jpg  cat.266.jpg  cat.416.jpg  cat.567.jpg  cat.717.jpg  cat.868.jpg\n",
            "cat.116.jpg  cat.267.jpg  cat.417.jpg  cat.568.jpg  cat.718.jpg  cat.869.jpg\n",
            "cat.117.jpg  cat.268.jpg  cat.418.jpg  cat.569.jpg  cat.719.jpg  cat.86.jpg\n",
            "cat.118.jpg  cat.269.jpg  cat.419.jpg  cat.56.jpg   cat.71.jpg\t cat.870.jpg\n",
            "cat.119.jpg  cat.26.jpg   cat.41.jpg   cat.570.jpg  cat.720.jpg  cat.871.jpg\n",
            "cat.11.jpg   cat.270.jpg  cat.420.jpg  cat.571.jpg  cat.721.jpg  cat.872.jpg\n",
            "cat.120.jpg  cat.271.jpg  cat.421.jpg  cat.572.jpg  cat.722.jpg  cat.873.jpg\n",
            "cat.121.jpg  cat.272.jpg  cat.422.jpg  cat.573.jpg  cat.723.jpg  cat.874.jpg\n",
            "cat.122.jpg  cat.273.jpg  cat.423.jpg  cat.574.jpg  cat.724.jpg  cat.875.jpg\n",
            "cat.123.jpg  cat.274.jpg  cat.424.jpg  cat.575.jpg  cat.725.jpg  cat.876.jpg\n",
            "cat.124.jpg  cat.275.jpg  cat.425.jpg  cat.576.jpg  cat.726.jpg  cat.877.jpg\n",
            "cat.125.jpg  cat.276.jpg  cat.426.jpg  cat.577.jpg  cat.727.jpg  cat.878.jpg\n",
            "cat.126.jpg  cat.277.jpg  cat.427.jpg  cat.578.jpg  cat.728.jpg  cat.879.jpg\n",
            "cat.127.jpg  cat.278.jpg  cat.428.jpg  cat.579.jpg  cat.729.jpg  cat.87.jpg\n",
            "cat.128.jpg  cat.279.jpg  cat.429.jpg  cat.57.jpg   cat.72.jpg\t cat.880.jpg\n",
            "cat.129.jpg  cat.27.jpg   cat.42.jpg   cat.580.jpg  cat.730.jpg  cat.881.jpg\n",
            "cat.12.jpg   cat.280.jpg  cat.430.jpg  cat.581.jpg  cat.731.jpg  cat.882.jpg\n",
            "cat.130.jpg  cat.281.jpg  cat.431.jpg  cat.582.jpg  cat.732.jpg  cat.883.jpg\n",
            "cat.131.jpg  cat.282.jpg  cat.432.jpg  cat.583.jpg  cat.733.jpg  cat.884.jpg\n",
            "cat.132.jpg  cat.283.jpg  cat.433.jpg  cat.584.jpg  cat.734.jpg  cat.885.jpg\n",
            "cat.133.jpg  cat.284.jpg  cat.434.jpg  cat.585.jpg  cat.735.jpg  cat.886.jpg\n",
            "cat.134.jpg  cat.285.jpg  cat.435.jpg  cat.586.jpg  cat.736.jpg  cat.887.jpg\n",
            "cat.135.jpg  cat.286.jpg  cat.436.jpg  cat.587.jpg  cat.737.jpg  cat.888.jpg\n",
            "cat.136.jpg  cat.287.jpg  cat.437.jpg  cat.588.jpg  cat.738.jpg  cat.889.jpg\n",
            "cat.137.jpg  cat.288.jpg  cat.438.jpg  cat.589.jpg  cat.739.jpg  cat.88.jpg\n",
            "cat.138.jpg  cat.289.jpg  cat.439.jpg  cat.58.jpg   cat.73.jpg\t cat.890.jpg\n",
            "cat.139.jpg  cat.28.jpg   cat.43.jpg   cat.590.jpg  cat.740.jpg  cat.891.jpg\n",
            "cat.13.jpg   cat.290.jpg  cat.440.jpg  cat.591.jpg  cat.741.jpg  cat.892.jpg\n",
            "cat.140.jpg  cat.291.jpg  cat.441.jpg  cat.592.jpg  cat.742.jpg  cat.893.jpg\n",
            "cat.141.jpg  cat.292.jpg  cat.442.jpg  cat.593.jpg  cat.743.jpg  cat.894.jpg\n",
            "cat.142.jpg  cat.293.jpg  cat.443.jpg  cat.594.jpg  cat.744.jpg  cat.895.jpg\n",
            "cat.143.jpg  cat.294.jpg  cat.444.jpg  cat.595.jpg  cat.745.jpg  cat.896.jpg\n",
            "cat.144.jpg  cat.295.jpg  cat.445.jpg  cat.596.jpg  cat.746.jpg  cat.897.jpg\n",
            "cat.145.jpg  cat.296.jpg  cat.446.jpg  cat.597.jpg  cat.747.jpg  cat.898.jpg\n",
            "cat.146.jpg  cat.297.jpg  cat.447.jpg  cat.598.jpg  cat.748.jpg  cat.899.jpg\n",
            "cat.147.jpg  cat.298.jpg  cat.448.jpg  cat.599.jpg  cat.749.jpg  cat.89.jpg\n",
            "cat.148.jpg  cat.299.jpg  cat.449.jpg  cat.59.jpg   cat.74.jpg\t cat.8.jpg\n",
            "cat.149.jpg  cat.29.jpg   cat.44.jpg   cat.5.jpg    cat.750.jpg  cat.900.jpg\n",
            "cat.14.jpg   cat.2.jpg\t  cat.450.jpg  cat.600.jpg  cat.751.jpg  cat.901.jpg\n",
            "cat.150.jpg  cat.300.jpg  cat.451.jpg  cat.601.jpg  cat.752.jpg  cat.902.jpg\n",
            "cat.151.jpg  cat.301.jpg  cat.452.jpg  cat.602.jpg  cat.753.jpg  cat.903.jpg\n",
            "cat.152.jpg  cat.302.jpg  cat.453.jpg  cat.603.jpg  cat.754.jpg  cat.904.jpg\n",
            "cat.153.jpg  cat.303.jpg  cat.454.jpg  cat.604.jpg  cat.755.jpg  cat.905.jpg\n",
            "cat.154.jpg  cat.304.jpg  cat.455.jpg  cat.605.jpg  cat.756.jpg  cat.906.jpg\n",
            "cat.155.jpg  cat.305.jpg  cat.456.jpg  cat.606.jpg  cat.757.jpg  cat.907.jpg\n",
            "cat.156.jpg  cat.306.jpg  cat.457.jpg  cat.607.jpg  cat.758.jpg  cat.908.jpg\n",
            "cat.157.jpg  cat.307.jpg  cat.458.jpg  cat.608.jpg  cat.759.jpg  cat.909.jpg\n",
            "cat.158.jpg  cat.308.jpg  cat.459.jpg  cat.609.jpg  cat.75.jpg\t cat.90.jpg\n",
            "cat.159.jpg  cat.309.jpg  cat.45.jpg   cat.60.jpg   cat.760.jpg  cat.910.jpg\n",
            "cat.15.jpg   cat.30.jpg   cat.460.jpg  cat.610.jpg  cat.761.jpg  cat.911.jpg\n",
            "cat.160.jpg  cat.310.jpg  cat.461.jpg  cat.611.jpg  cat.762.jpg  cat.912.jpg\n",
            "cat.161.jpg  cat.311.jpg  cat.462.jpg  cat.612.jpg  cat.763.jpg  cat.913.jpg\n",
            "cat.162.jpg  cat.312.jpg  cat.463.jpg  cat.613.jpg  cat.764.jpg  cat.914.jpg\n",
            "cat.163.jpg  cat.313.jpg  cat.464.jpg  cat.614.jpg  cat.765.jpg  cat.915.jpg\n",
            "cat.164.jpg  cat.314.jpg  cat.465.jpg  cat.615.jpg  cat.766.jpg  cat.916.jpg\n",
            "cat.165.jpg  cat.315.jpg  cat.466.jpg  cat.616.jpg  cat.767.jpg  cat.917.jpg\n",
            "cat.166.jpg  cat.316.jpg  cat.467.jpg  cat.617.jpg  cat.768.jpg  cat.918.jpg\n",
            "cat.167.jpg  cat.317.jpg  cat.468.jpg  cat.618.jpg  cat.769.jpg  cat.919.jpg\n",
            "cat.168.jpg  cat.318.jpg  cat.469.jpg  cat.619.jpg  cat.76.jpg\t cat.91.jpg\n",
            "cat.169.jpg  cat.319.jpg  cat.46.jpg   cat.61.jpg   cat.770.jpg  cat.920.jpg\n",
            "cat.16.jpg   cat.31.jpg   cat.470.jpg  cat.620.jpg  cat.771.jpg  cat.921.jpg\n",
            "cat.170.jpg  cat.320.jpg  cat.471.jpg  cat.621.jpg  cat.772.jpg  cat.922.jpg\n",
            "cat.171.jpg  cat.321.jpg  cat.472.jpg  cat.622.jpg  cat.773.jpg  cat.923.jpg\n",
            "cat.172.jpg  cat.322.jpg  cat.473.jpg  cat.623.jpg  cat.774.jpg  cat.924.jpg\n",
            "cat.173.jpg  cat.323.jpg  cat.474.jpg  cat.624.jpg  cat.775.jpg  cat.925.jpg\n",
            "cat.174.jpg  cat.324.jpg  cat.475.jpg  cat.625.jpg  cat.776.jpg  cat.926.jpg\n",
            "cat.175.jpg  cat.325.jpg  cat.476.jpg  cat.626.jpg  cat.777.jpg  cat.927.jpg\n",
            "cat.176.jpg  cat.326.jpg  cat.477.jpg  cat.627.jpg  cat.778.jpg  cat.928.jpg\n",
            "cat.177.jpg  cat.327.jpg  cat.478.jpg  cat.628.jpg  cat.779.jpg  cat.929.jpg\n",
            "cat.178.jpg  cat.328.jpg  cat.479.jpg  cat.629.jpg  cat.77.jpg\t cat.92.jpg\n",
            "cat.179.jpg  cat.329.jpg  cat.47.jpg   cat.62.jpg   cat.780.jpg  cat.930.jpg\n",
            "cat.17.jpg   cat.32.jpg   cat.480.jpg  cat.630.jpg  cat.781.jpg  cat.931.jpg\n",
            "cat.180.jpg  cat.330.jpg  cat.481.jpg  cat.631.jpg  cat.782.jpg  cat.932.jpg\n",
            "cat.181.jpg  cat.331.jpg  cat.482.jpg  cat.632.jpg  cat.783.jpg  cat.933.jpg\n",
            "cat.182.jpg  cat.332.jpg  cat.483.jpg  cat.633.jpg  cat.784.jpg  cat.934.jpg\n",
            "cat.183.jpg  cat.333.jpg  cat.484.jpg  cat.634.jpg  cat.785.jpg  cat.935.jpg\n",
            "cat.184.jpg  cat.334.jpg  cat.485.jpg  cat.635.jpg  cat.786.jpg  cat.936.jpg\n",
            "cat.185.jpg  cat.335.jpg  cat.486.jpg  cat.636.jpg  cat.787.jpg  cat.937.jpg\n",
            "cat.186.jpg  cat.336.jpg  cat.487.jpg  cat.637.jpg  cat.788.jpg  cat.938.jpg\n",
            "cat.187.jpg  cat.337.jpg  cat.488.jpg  cat.638.jpg  cat.789.jpg  cat.939.jpg\n",
            "cat.188.jpg  cat.338.jpg  cat.489.jpg  cat.639.jpg  cat.78.jpg\t cat.93.jpg\n",
            "cat.189.jpg  cat.339.jpg  cat.48.jpg   cat.63.jpg   cat.790.jpg  cat.940.jpg\n",
            "cat.18.jpg   cat.33.jpg   cat.490.jpg  cat.640.jpg  cat.791.jpg  cat.941.jpg\n",
            "cat.190.jpg  cat.340.jpg  cat.491.jpg  cat.641.jpg  cat.792.jpg  cat.942.jpg\n",
            "cat.191.jpg  cat.341.jpg  cat.492.jpg  cat.642.jpg  cat.793.jpg  cat.943.jpg\n",
            "cat.192.jpg  cat.342.jpg  cat.493.jpg  cat.643.jpg  cat.794.jpg  cat.944.jpg\n",
            "cat.193.jpg  cat.343.jpg  cat.494.jpg  cat.644.jpg  cat.795.jpg  cat.945.jpg\n",
            "cat.194.jpg  cat.344.jpg  cat.495.jpg  cat.645.jpg  cat.796.jpg  cat.946.jpg\n",
            "cat.195.jpg  cat.345.jpg  cat.496.jpg  cat.646.jpg  cat.797.jpg  cat.947.jpg\n",
            "cat.196.jpg  cat.346.jpg  cat.497.jpg  cat.647.jpg  cat.798.jpg  cat.948.jpg\n",
            "cat.197.jpg  cat.347.jpg  cat.498.jpg  cat.648.jpg  cat.799.jpg  cat.949.jpg\n",
            "cat.198.jpg  cat.348.jpg  cat.499.jpg  cat.649.jpg  cat.79.jpg\t cat.94.jpg\n",
            "cat.199.jpg  cat.349.jpg  cat.49.jpg   cat.64.jpg   cat.7.jpg\t cat.950.jpg\n",
            "cat.19.jpg   cat.34.jpg   cat.4.jpg    cat.650.jpg  cat.800.jpg  cat.951.jpg\n",
            "cat.1.jpg    cat.350.jpg  cat.500.jpg  cat.651.jpg  cat.801.jpg  cat.952.jpg\n",
            "cat.200.jpg  cat.351.jpg  cat.501.jpg  cat.652.jpg  cat.802.jpg  cat.953.jpg\n",
            "cat.201.jpg  cat.352.jpg  cat.502.jpg  cat.653.jpg  cat.803.jpg  cat.954.jpg\n",
            "cat.202.jpg  cat.353.jpg  cat.503.jpg  cat.654.jpg  cat.804.jpg  cat.955.jpg\n",
            "cat.203.jpg  cat.354.jpg  cat.504.jpg  cat.655.jpg  cat.805.jpg  cat.956.jpg\n",
            "cat.204.jpg  cat.355.jpg  cat.505.jpg  cat.656.jpg  cat.806.jpg  cat.957.jpg\n",
            "cat.205.jpg  cat.356.jpg  cat.506.jpg  cat.657.jpg  cat.807.jpg  cat.958.jpg\n",
            "cat.206.jpg  cat.357.jpg  cat.507.jpg  cat.658.jpg  cat.808.jpg  cat.959.jpg\n",
            "cat.207.jpg  cat.358.jpg  cat.508.jpg  cat.659.jpg  cat.809.jpg  cat.95.jpg\n",
            "cat.208.jpg  cat.359.jpg  cat.509.jpg  cat.65.jpg   cat.80.jpg\t cat.960.jpg\n",
            "cat.209.jpg  cat.35.jpg   cat.50.jpg   cat.660.jpg  cat.810.jpg  cat.961.jpg\n",
            "cat.20.jpg   cat.360.jpg  cat.510.jpg  cat.661.jpg  cat.811.jpg  cat.962.jpg\n",
            "cat.210.jpg  cat.361.jpg  cat.511.jpg  cat.662.jpg  cat.812.jpg  cat.963.jpg\n",
            "cat.211.jpg  cat.362.jpg  cat.512.jpg  cat.663.jpg  cat.813.jpg  cat.964.jpg\n",
            "cat.212.jpg  cat.363.jpg  cat.513.jpg  cat.664.jpg  cat.814.jpg  cat.965.jpg\n",
            "cat.213.jpg  cat.364.jpg  cat.514.jpg  cat.665.jpg  cat.815.jpg  cat.966.jpg\n",
            "cat.214.jpg  cat.365.jpg  cat.515.jpg  cat.666.jpg  cat.816.jpg  cat.967.jpg\n",
            "cat.215.jpg  cat.366.jpg  cat.516.jpg  cat.667.jpg  cat.817.jpg  cat.968.jpg\n",
            "cat.216.jpg  cat.367.jpg  cat.517.jpg  cat.668.jpg  cat.818.jpg  cat.969.jpg\n",
            "cat.217.jpg  cat.368.jpg  cat.518.jpg  cat.669.jpg  cat.819.jpg  cat.96.jpg\n",
            "cat.218.jpg  cat.369.jpg  cat.519.jpg  cat.66.jpg   cat.81.jpg\t cat.970.jpg\n",
            "cat.219.jpg  cat.36.jpg   cat.51.jpg   cat.670.jpg  cat.820.jpg  cat.971.jpg\n",
            "cat.21.jpg   cat.370.jpg  cat.520.jpg  cat.671.jpg  cat.821.jpg  cat.972.jpg\n",
            "cat.220.jpg  cat.371.jpg  cat.521.jpg  cat.672.jpg  cat.822.jpg  cat.973.jpg\n",
            "cat.221.jpg  cat.372.jpg  cat.522.jpg  cat.673.jpg  cat.823.jpg  cat.974.jpg\n",
            "cat.222.jpg  cat.373.jpg  cat.523.jpg  cat.674.jpg  cat.824.jpg  cat.975.jpg\n",
            "cat.223.jpg  cat.374.jpg  cat.524.jpg  cat.675.jpg  cat.825.jpg  cat.976.jpg\n",
            "cat.224.jpg  cat.375.jpg  cat.525.jpg  cat.676.jpg  cat.826.jpg  cat.977.jpg\n",
            "cat.225.jpg  cat.376.jpg  cat.526.jpg  cat.677.jpg  cat.827.jpg  cat.978.jpg\n",
            "cat.226.jpg  cat.377.jpg  cat.527.jpg  cat.678.jpg  cat.828.jpg  cat.979.jpg\n",
            "cat.227.jpg  cat.378.jpg  cat.528.jpg  cat.679.jpg  cat.829.jpg  cat.97.jpg\n",
            "cat.228.jpg  cat.379.jpg  cat.529.jpg  cat.67.jpg   cat.82.jpg\t cat.980.jpg\n",
            "cat.229.jpg  cat.37.jpg   cat.52.jpg   cat.680.jpg  cat.830.jpg  cat.981.jpg\n",
            "cat.22.jpg   cat.380.jpg  cat.530.jpg  cat.681.jpg  cat.831.jpg  cat.982.jpg\n",
            "cat.230.jpg  cat.381.jpg  cat.531.jpg  cat.682.jpg  cat.832.jpg  cat.983.jpg\n",
            "cat.231.jpg  cat.382.jpg  cat.532.jpg  cat.683.jpg  cat.833.jpg  cat.984.jpg\n",
            "cat.232.jpg  cat.383.jpg  cat.533.jpg  cat.684.jpg  cat.834.jpg  cat.985.jpg\n",
            "cat.233.jpg  cat.384.jpg  cat.534.jpg  cat.685.jpg  cat.835.jpg  cat.986.jpg\n",
            "cat.234.jpg  cat.385.jpg  cat.535.jpg  cat.686.jpg  cat.836.jpg  cat.987.jpg\n",
            "cat.235.jpg  cat.386.jpg  cat.536.jpg  cat.687.jpg  cat.837.jpg  cat.988.jpg\n",
            "cat.236.jpg  cat.387.jpg  cat.537.jpg  cat.688.jpg  cat.838.jpg  cat.989.jpg\n",
            "cat.237.jpg  cat.388.jpg  cat.538.jpg  cat.689.jpg  cat.839.jpg  cat.98.jpg\n",
            "cat.238.jpg  cat.389.jpg  cat.539.jpg  cat.68.jpg   cat.83.jpg\t cat.990.jpg\n",
            "cat.239.jpg  cat.38.jpg   cat.53.jpg   cat.690.jpg  cat.840.jpg  cat.991.jpg\n",
            "cat.23.jpg   cat.390.jpg  cat.540.jpg  cat.691.jpg  cat.841.jpg  cat.992.jpg\n",
            "cat.240.jpg  cat.391.jpg  cat.541.jpg  cat.692.jpg  cat.842.jpg  cat.993.jpg\n",
            "cat.241.jpg  cat.392.jpg  cat.542.jpg  cat.693.jpg  cat.843.jpg  cat.994.jpg\n",
            "cat.242.jpg  cat.393.jpg  cat.543.jpg  cat.694.jpg  cat.844.jpg  cat.995.jpg\n",
            "cat.243.jpg  cat.394.jpg  cat.544.jpg  cat.695.jpg  cat.845.jpg  cat.996.jpg\n",
            "cat.244.jpg  cat.395.jpg  cat.545.jpg  cat.696.jpg  cat.846.jpg  cat.997.jpg\n",
            "cat.245.jpg  cat.396.jpg  cat.546.jpg  cat.697.jpg  cat.847.jpg  cat.998.jpg\n",
            "cat.246.jpg  cat.397.jpg  cat.547.jpg  cat.698.jpg  cat.848.jpg  cat.999.jpg\n",
            "cat.247.jpg  cat.398.jpg  cat.548.jpg  cat.699.jpg  cat.849.jpg  cat.99.jpg\n",
            "cat.248.jpg  cat.399.jpg  cat.549.jpg  cat.69.jpg   cat.84.jpg\t cat.9.jpg\n",
            "cat.249.jpg  cat.39.jpg   cat.54.jpg   cat.6.jpg    cat.850.jpg\n",
            "cat.24.jpg   cat.3.jpg\t  cat.550.jpg  cat.700.jpg  cat.851.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJ1xf6EVXdL-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a56d9eac-c615-4b02-af97-51ad306722d5"
      },
      "source": [
        "ficheros = glob(\"./small_data/train/cats/*\")\n",
        "ficheros[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./small_data/train/cats/cat.337.jpg'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ck_4gkiezfz"
      },
      "source": [
        "for fich in ficheros[:10]:\n",
        "    imagen = load_img(fich)\n",
        "    display(imagen)\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnGrnWfrIZlX"
      },
      "source": [
        "ficheros = glob(\"./small_data/train/dogs/*\")\n",
        "for fich in ficheros[:10]:\n",
        "    imagen = load_img(fich)\n",
        "    display(imagen)\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrluBG4VWa3S"
      },
      "source": [
        "train_data_dir = 'small_data/train'\n",
        "validation_data_dir = 'small_data/validation'\n",
        "test_data_dir = 'small_data/test0'\n",
        "\n",
        "batch_size = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-u9ZVoRWANS"
      },
      "source": [
        "A continuación vamos a definir un ImageDataGenerator que es lo que nos servirá para realizar data augmentation.\n",
        "\n",
        "Para ver opciones:\n",
        "\n",
        "https://keras.io/api/preprocessing/image/#imagedatagenerator-class\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6zY8pZ8haIS"
      },
      "source": [
        "preprocess_input = lambda x:x/255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb3RiGQPYM1a"
      },
      "source": [
        "# data augmentation:\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    dtype='float32',\n",
        "    preprocessing_function = preprocess_input,\n",
        "#    rotation_range=20,\n",
        "#    width_shift_range=0.1,\n",
        "#    height_shift_range=0.1,\n",
        "#    fill_mode='nearest',\n",
        "#    shear_range=0.1,\n",
        "#    zoom_range=0.2,\n",
        "#    horizontal_flip=True\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEgFiD9Kap84"
      },
      "source": [
        "imagen_num = np.expand_dims(np.array(imagen), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUtIwZ_-Y3T0"
      },
      "source": [
        "plt.imshow(train_datagen.flow(imagen_num)[0][0])\n",
        "plt.axis(\"off\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xN7yt9mWa3V"
      },
      "source": [
        "## **Red convolucional**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx5NIFyWdSf_"
      },
      "source": [
        "# dimensiones a las que vamos a llevar las imágenes\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "normed_dims = (img_height, img_width)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwd_tQQGw2em"
      },
      "source": [
        "normed_dims"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOxNUu8ZvlYO"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), activation='relu',\n",
        "                 input_shape=normed_dims+(3,)))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Conv2D(32, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Flatten())\n",
        "# aqui empieza la red neuronal 'standard'\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "#              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              optimizer=optimizers.RMSprop(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K658Z9NnX333"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju3YuClNWa3e"
      },
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "if COLAB:\n",
        "    display(SVG(model_to_dot(model, show_shapes=True,dpi=72).create(prog='dot', format='svg')))\n",
        "else:\n",
        "    display(SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WD-qj3yoyJDB"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    dtype='float32',\n",
        "    preprocessing_function = preprocess_input,\n",
        "#    rotation_range=40,\n",
        "#    width_shift_range=0.2,\n",
        "#    height_shift_range=0.2,\n",
        "#    fill_mode='nearest',\n",
        "#    shear_range=0.2,\n",
        "#    zoom_range=0.2,\n",
        "#    horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_datagen  = ImageDataGenerator(dtype='float32',\n",
        "                                  preprocessing_function = preprocess_input)\n",
        "\n",
        "test_datagen = ImageDataGenerator(dtype='float32',\n",
        "                                  preprocessing_function = preprocess_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As30eiA_awL-"
      },
      "source": [
        "validation_data_dir, normed_dims"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlmhVC-bYM_1"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=normed_dims,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    class_mode='categorical') # binary, categorical, sparse\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=normed_dims,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    class_mode='categorical') # binary, categorical, sparse\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=normed_dims,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    class_mode='categorical') # binary, categorical, sparse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u96-8fMjbIcx"
      },
      "source": [
        "train_generator.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smKSN-oycTL6"
      },
      "source": [
        "number_train_samples = train_generator.n\n",
        "number_val_samples   = validation_generator.n\n",
        "number_test_samples  = test_generator.n\n",
        "\n",
        "number_train_samples, number_val_samples, number_test_samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDSlstsKWa3i"
      },
      "source": [
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "def grafica_entrenamiento(tr_acc, val_acc, tr_loss, val_loss, best_i,\n",
        "                          figsize=(10,4)):\n",
        "    plt.figure(figsize=figsize)\n",
        "    ax = plt.subplot(1,2,1)\n",
        "    plt.plot(1+np.arange(len(tr_acc)),  100*np.array(tr_acc))\n",
        "    plt.plot(1+np.arange(len(val_acc)), 100*np.array(val_acc))\n",
        "    plt.plot(1+best_i, 100*val_acc[best_i], 'or')\n",
        "    plt.title('tasa de acierto del modelo (%)', fontsize=18)\n",
        "    plt.ylabel('tasa de acierto (%)', fontsize=18)\n",
        "    plt.xlabel('época', fontsize=18)\n",
        "    plt.legend(['entrenamiento', 'validación'], loc='upper left')\n",
        "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(1+np.arange(len(tr_acc)), np.array(tr_loss))\n",
        "    plt.plot(1+np.arange(len(val_acc)), np.array(val_loss))\n",
        "    plt.plot(1+best_i, val_loss[best_i], 'or')\n",
        "    plt.title('loss del modelo', fontsize=18)\n",
        "    plt.ylabel('loss', fontsize=18)\n",
        "    plt.xlabel('época', fontsize=18)\n",
        "    plt.legend(['entrenamiento', 'validación'], loc='upper left')\n",
        "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvUaztU0Wa3l"
      },
      "source": [
        "acum_tr_acc = []\n",
        "acum_val_acc = []\n",
        "best_val_acc = -1000\n",
        "acum_tr_loss  = []\n",
        "acum_val_loss = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nqta4BkIWa3n"
      },
      "source": [
        "epochs = 50\n",
        "\n",
        "modelpath=\"model_current_best_parte3.h5\"\n",
        "\n",
        "checkpoint = ModelCheckpoint(modelpath, monitor='val_accuracy', verbose=1,\n",
        "                             save_best_only=True,\n",
        "                             mode='max') # graba sólo los que mejoran en validación\n",
        "callbacks_list = [checkpoint]\n",
        "for e in range(epochs):\n",
        "    history = model.fit_generator(generator = train_generator, \n",
        "                                  steps_per_epoch=number_train_samples // batch_size,\n",
        "                                  epochs=1,\n",
        "                                  callbacks=callbacks_list,\n",
        "                                  verbose=1,\n",
        "                                  shuffle = False,\n",
        "                                  validation_data=validation_generator,\n",
        "                                  validation_steps=number_val_samples // batch_size\n",
        "                                  )\n",
        "    \n",
        "    if history.history['val_accuracy'][-1] > best_val_acc:\n",
        "        print(\"Validation accuracy improved from\",\n",
        "            best_val_acc, 'to', history.history['val_accuracy'])\n",
        "        print(\"saving weights\")\n",
        "        best_val_acc = history.history['val_accuracy'][-1]\n",
        "    \n",
        "    acum_tr_acc.append(history.history['accuracy'][0])\n",
        "    acum_val_acc.append(history.history['val_accuracy'][0])\n",
        "    acum_tr_loss.append(history.history['loss'][0])\n",
        "    acum_val_loss.append(history.history['val_loss'][0])\n",
        "    \n",
        "    if len(acum_tr_acc) > 1:\n",
        "        clear_output()\n",
        "        best_i = np.argmax(acum_val_acc)\n",
        "        grafica_entrenamiento(acum_tr_acc, acum_val_acc, acum_tr_loss, acum_val_loss, best_i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYGAMNyndDoM"
      },
      "source": [
        "model = load_model(modelpath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNI07vcLWa3q"
      },
      "source": [
        "## **Resultados obtenidos**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-g2AYJqWa3t"
      },
      "source": [
        "scores_tr = model.evaluate(train_generator)\n",
        "print('Train loss    :', scores_tr[0])\n",
        "print('Train accuracy:', scores_tr[1])\n",
        "print()\n",
        "\n",
        "scores_val = model.evaluate(validation_generator)\n",
        "print('Val loss    :', scores_val[0])\n",
        "print('Val accuracy:', scores_val[1])\n",
        "print()\n",
        "\n",
        "scores_te = model.evaluate(test_generator)\n",
        "print('Test loss     :', scores_te[0])\n",
        "print('Test accuracy :', scores_te[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maD61ufgWa3w"
      },
      "source": [
        "y_real = test_generator.classes\n",
        "y_pred_proba = model.predict(test_generator)\n",
        "y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "print('')\n",
        "print(classification_report(y_real, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x28VTWUvWa3y"
      },
      "source": [
        "clase_positiva = 1\n",
        "fpr, tpr, thresholds = roc_curve(y_real==clase_positiva, y_pred_proba[:,clase_positiva])\n",
        "fig, ax1 = plt.subplots(1,1)\n",
        "ax1.plot(fpr, tpr, 'r-.', label = 'CNN (%2.2f)' % auc(fpr, tpr))\n",
        "ax1.set_xlabel('False Positive Rate')\n",
        "ax1.set_ylabel('True Positive Rate')\n",
        "ax1.plot(fpr, fpr, 'b-', label = 'Random Guess')\n",
        "ax1.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASQl208vrWGX"
      },
      "source": [
        "## **Visualización de ejemplos de test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zt9vxEizseSE"
      },
      "source": [
        "test_datagen2 = ImageDataGenerator(dtype='float32',\n",
        "                                   preprocessing_function = preprocess_input)\n",
        "\n",
        "test_generator2 = test_datagen2.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=normed_dims,\n",
        "    batch_size=test_generator.n, # todas las imágnes del directorio test\n",
        "    shuffle=False,\n",
        "    class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq_wZK3DseUW"
      },
      "source": [
        "test_generator2.reset()\n",
        "X_te, y_te = test_generator2.next()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yY5BAP6jP87g"
      },
      "source": [
        "class_indices = test_generator2.class_indices\n",
        "class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3cXYEqFQyRl"
      },
      "source": [
        "X_te.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdfFcJzzRGq2"
      },
      "source": [
        "X_te.max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62rtQ4ERrric"
      },
      "source": [
        "ind_te1 = 1500\n",
        "\n",
        "image = X_te[ind_te1].copy()\n",
        "\n",
        "plt.imshow(image, cmap='jet')\n",
        "plt.axis(\"off\")\n",
        "p = model.predict(np.expand_dims(image, axis=0))[0][class_indices[\"dogs\"]]\n",
        "print(\"Probabilidad perro: {:2.1f}%\".format(100*p))\n",
        "p = model.predict(np.expand_dims(image, axis=0))[0][class_indices[\"cats\"]]\n",
        "print(\"Probabilidad gato : {:2.1f}%\".format(100*p))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yx0QJniRhu4_"
      },
      "source": [
        "## **Visualización del funcionamiento de la red**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eil-vNA76R8D"
      },
      "source": [
        "weights = model.get_weights()\n",
        "print(np.shape(weights))\n",
        "for i in range(len(weights)):\n",
        "    print('shape of weights[%d]: ' % i, np.shape(weights[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP7WnsQ1hxOo"
      },
      "source": [
        "# kernels de la primera capa convolucional\n",
        "ncapa = 0\n",
        "\n",
        "nfilters = weights[ncapa].shape[3]\n",
        "ncols = 7 # número de columnas en la figura\n",
        "\n",
        "\n",
        "ma = abs(weights[ncapa]).max()\n",
        "nrows = int(np.ceil(nfilters/ncols)) # número de filas en la figura\n",
        "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15,15*nrows/ncols))\n",
        "axes_r = axes.ravel()\n",
        "for i in range(nfilters):\n",
        "    kernel = weights[ncapa][:,:,2,i]\n",
        "    ax = axes_r[i]\n",
        "    ax.imshow(kernel, vmin=-ma, vmax=ma, cmap='bwr')\n",
        "    ax.set_xticks([]); ax.set_yticks([])\n",
        "    ax.set_title('pesos kernel %d' % i, fontsize=10)\n",
        "for i in range(nfilters,nrows*ncols):\n",
        "    fig.delaxes(axes_r[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9zJnqsWh2Wn"
      },
      "source": [
        "### **Visualización de las salidas de una sola capa**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DRJY257h2pD"
      },
      "source": [
        "# salida de una sola capa\n",
        "ncapa = 0\n",
        "intermediate_layer_model = Model(inputs=model.input,\n",
        "                                 outputs=model.layers[ncapa].output)\n",
        "intermediate_layer_model.summary()\n",
        "print(\"\\n\\n\")\n",
        "if COLAB:\n",
        "    display(SVG(model_to_dot(intermediate_layer_model,show_shapes=True,dpi=72).create(prog='dot', format='svg')))\n",
        "else:\n",
        "    display(SVG(model_to_dot(intermediate_layer_model,show_shapes=True).create(prog='dot', format='svg')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eAyuj_Rh6oX"
      },
      "source": [
        "imagen = X_te[1005]\n",
        "imagen.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9daH3ikFh8Tj"
      },
      "source": [
        "ejemplo = 10\n",
        "\n",
        "imagen = X_te[ejemplo]\n",
        "aux = np.expand_dims(imagen, axis=0)\n",
        "salida_capa = intermediate_layer_model.predict(aux)\n",
        "\n",
        "plt.figure(figsize=(3,3))\n",
        "plt.imshow(imagen, cmap='gray')\n",
        "plt.title('input image', size=12)\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "plt.show()\n",
        "\n",
        "print(\"Salidas capa \"+intermediate_layer_model.layers[-1].name, salida_capa.shape)\n",
        "\n",
        "nsalidas = salida_capa.shape[-1]\n",
        "ncols = 4\n",
        "nrows = int(np.ceil(nsalidas / ncols))\n",
        "\n",
        "ma = abs(salida_capa).max()\n",
        "\n",
        "plt.subplots(nrows,ncols,figsize = (12, 3*nrows))\n",
        "\n",
        "for i in range(nsalidas):\n",
        "    plt.subplot(nrows,ncols,i+1)\n",
        "#    plt.imshow(salida_capa[0,:,:,i], vmin=-ma, vmax=ma, cmap='bwr')\n",
        "    plt.imshow(salida_capa[0,:,:,i], cmap='viridis')\n",
        "    plt.xticks(())\n",
        "    plt.yticks(())\n",
        "    plt.title('salida kernel %d' % i, fontsize=10)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuIpGexwh-_A"
      },
      "source": [
        "### **Visualización de las salidas de varias capas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U5tljF5h_Xa"
      },
      "source": [
        "# Now we extract the outputs of the top 6 layers:\n",
        "layer_outputs = [layer.output for layer in model.layers[:6]]\n",
        "# Creates a model that will return these outputs, given the model input:\n",
        "activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
        "\n",
        "activations = activation_model.predict(X_te[ejemplo:(ejemplo+1)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4paKjpn4iCXT"
      },
      "source": [
        "# These are the names of the layers, so can have them as part of our plot\n",
        "layer_names = []\n",
        "for layer in model.layers[:8]:\n",
        "    layer_names.append(layer.name)\n",
        "\n",
        "images_per_row = 16\n",
        "\n",
        "# Now let's display our feature maps\n",
        "for layer_name, layer_activation in zip(layer_names, activations):\n",
        "    # This is the number of features in the feature map\n",
        "    n_features = layer_activation.shape[-1]\n",
        "\n",
        "    # The feature map has shape (1, size, size, n_features)\n",
        "    size = layer_activation.shape[1]\n",
        "\n",
        "    # We will tile the activation channels in this matrix\n",
        "    n_cols = n_features // images_per_row\n",
        "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
        "\n",
        "    # We'll tile each filter into this big horizontal grid\n",
        "    for col in range(n_cols):\n",
        "        for row in range(images_per_row):\n",
        "            channel_image = layer_activation[0,\n",
        "                                             :, :,\n",
        "                                             col * images_per_row + row]\n",
        "            # Post-process the feature to make it visually palatable\n",
        "            channel_image -= channel_image.mean()\n",
        "            channel_image /= channel_image.std()\n",
        "            channel_image *= 64\n",
        "            channel_image += 128\n",
        "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
        "            display_grid[col * size : (col + 1) * size,\n",
        "                         row * size : (row + 1) * size] = channel_image\n",
        "\n",
        "    # Display the grid\n",
        "    scale = 1. / size\n",
        "    plt.figure(figsize=(scale * display_grid.shape[1],\n",
        "                        scale * display_grid.shape[0]))\n",
        "    plt.title(layer_name)\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oqj63rDgiEoT"
      },
      "source": [
        "### **¿A qué partes de la imagen de entrada es más sensible la salida de la red?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ti4yONZpOzmF"
      },
      "source": [
        "### **GradCam:**\n",
        "\n",
        "(de https://medium.com/analytics-vidhya/visualizing-activation-heatmaps-using-tensorflow-5bdba018f759)\n",
        "\n",
        "1- Calcular para una imagen la salida del modelo y la salida de la última capa convolucional\n",
        "\n",
        "2- Encuentrar la neurona de salida más activa (que es la que determina la clase predicha)\n",
        "\n",
        "3- Calcular el gradiente de dicha neurona de salida con respecto a la última capa convolucional\n",
        "\n",
        "3- Promediar y pesar esto con la salida de la última capa convolucional\n",
        "\n",
        "4- Normalizar entre 0 y 1 para visualizar\n",
        "\n",
        "5- Convertir a RGB y superponerla a la imagen original"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmsmHXAtiHMo"
      },
      "source": [
        "**Funciones que calculan la sensibilidad de la salida a la entrada:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SSZ-ZLfiE26"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def find_ind_last_conv2D(model):\n",
        "    ind_last_conv2D_layer = None\n",
        "    for i,x in enumerate(model.layers):\n",
        "        if x.__class__.__name__ == \"Conv2D\":\n",
        "            ind_last_conv2D_layer = i\n",
        "    return ind_last_conv2D_layer\n",
        "\n",
        "\n",
        "def show_heatmap(model, im):\n",
        "    imag = np.expand_dims(im, axis=0) # de 1 imagen pasamos a 1 conjunto de 1 imagen\n",
        "        \n",
        "    # The is the output feature map of the last convolutional layer\n",
        "    last_conv_layer = model.layers[find_ind_last_conv2D(model)]\n",
        "    \n",
        "    # This is the gradient of the \"benign\" class with regard to\n",
        "    # the output feature map of last convolutional layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        aux = model.output\n",
        "        #aux = model.layers[-2].output # salida de la última capa densa antes de softmax\n",
        "\n",
        "        iterate = tf.keras.models.Model([model.inputs], [aux, last_conv_layer.output])\n",
        "        model_out, last_conv_layer = iterate(imag)\n",
        "        class_out = model_out[:, np.argmax(model_out[0])]\n",
        "        grads = tape.gradient(class_out, last_conv_layer)\n",
        "\n",
        "        # mean intensity of the gradient over a specific feature map channel:\n",
        "        pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "    \n",
        "    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, last_conv_layer), axis=-1)    \n",
        "    heatmap = np.maximum(heatmap, 0) # se quitan los negativos (se ponen a 0)\n",
        "    heatmap /= np.max(heatmap) # se normaliza entre 0 y 1\n",
        "    heatmap = heatmap[0] # pasamos de 1 conjunto de 1 heatmap a 1 heatmap\n",
        "    \n",
        "    # We use cv2 to load the original image\n",
        "    #img = cv2.imread(img_path)\n",
        "    img = imag[0]\n",
        "    \n",
        "    img = np.zeros((im.shape[0],im.shape[1],3))\n",
        "#    print(im.shape, imag.shape)\n",
        "    for i in range(3):\n",
        "        img[:,:,i] = imag[0,:,:,0]\n",
        "\n",
        "    \n",
        "    # We resize the heatmap to have the same size as the original image\n",
        "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "    \n",
        "    # We convert the heatmap to RGB\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    \n",
        "    # We apply the heatmap to the original image\n",
        "    #heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET) / 255\n",
        "    #heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_BONE) / 255\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_HOT) / 255\n",
        "    \n",
        "    \n",
        "    # 0.4 here is a heatmap intensity factor\n",
        "    superimposed_img = heatmap * 0.5 + 0.5*im\n",
        "    #print(heatmap.min(), heatmap.max(), heatmap.mean(), heatmap.std())\n",
        "    #print(img.min(), img.max(), img.mean(), img.std())\n",
        "    #print(superimposed_img.min(),  superimposed_img.max(),\n",
        "    #      superimposed_img.mean(), superimposed_img.std())\n",
        "    \n",
        "    plt.figure(figsize=(15,5))\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.imshow(im, vmin=0, vmax=1); plt.xticks([]); plt.yticks([])\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.imshow(heatmap, vmin=0, vmax=1); plt.xticks([]); plt.yticks([])\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.imshow(superimposed_img, vmin=0, vmax=1); plt.xticks([]); plt.yticks([])\n",
        "    plt.show()\n",
        "    #print(np.shape(imag))\n",
        "    prob = 100*model.predict(imag)[0][class_indices[\"cats\"]]\n",
        "    print(\"Probabilidad clase gato : {:2.1f}%\".format(prob))\n",
        "    prob = 100*model.predict(imag)[0][class_indices[\"dogs\"]]\n",
        "    print(\"Probabilidad clase perro: {:2.1f}%\".format(prob))\n",
        "    print(\"\\n\\n\")\n",
        "    return heatmap, superimposed_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDq5ex8ZiKVy"
      },
      "source": [
        "**Visualización de mapas de sensibilidades (heatmaps) en varios ejemplos:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVHJRWw6Qiym"
      },
      "source": [
        "X_te[i].max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeIOioqpQQKl"
      },
      "source": [
        "len(X_te)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWPyB9DjiKmJ"
      },
      "source": [
        "ind = 1041 # visualizamos 10 ejemplos de test a partir de este (en test hay 2002 ejemplos)\n",
        "ind = 200\n",
        "\n",
        "for i in range(ind, ind+10):\n",
        "    heat_map, superimposed_img = show_heatmap(model, X_te[i])\n",
        "    #print(heat_map.min(), heat_map.max(), superimposed_img.min(), superimposed_img.max())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw-Z7qcmiPFl"
      },
      "source": [
        "### **Ahora analizamos las mayores equivocaciones de la CNN en test cuando intentamos detectar gatos**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AMdUyweiRfB"
      },
      "source": [
        "- clase 1: perro\n",
        "- clase 0: gato"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTS_mN_0iUs_"
      },
      "source": [
        "**Gatos que la red está segura que son perros:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNkpIiHHiPTQ"
      },
      "source": [
        "inds = np.where(y_te==class_indices[\"cats\"])[0]\n",
        "inds = sorted(inds, key=lambda i:y_pred_proba[i,class_indices[\"cats\"]])\n",
        "for i in inds[:10]:\n",
        "    heat_map, superimposed_img = show_heatmap(model, X_te[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O2OUA86pt5P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}