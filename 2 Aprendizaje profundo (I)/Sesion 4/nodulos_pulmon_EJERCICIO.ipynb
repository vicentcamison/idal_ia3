{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "nodulos_pulmon_EJERCICIO.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vicentcamison/idal_ia3/blob/main/2%20Aprendizaje%20profundo%20(I)/Sesion%204/nodulos_pulmon_EJERCICIO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsU9SbEFmbUf"
      },
      "source": [
        "<font color=\"#CA0032\"><h1 align=\"left\">**Redes convolucionales (CNNs)**</h1></font>\n",
        "\n",
        "<font color=\"#6E6E6E\"><h1 align=\"left\">**Predicción de malignidad en nódulos pulmonares**</h1></font>\n",
        "\n",
        "<h2 align=\"left\">Manuel Sánchez-Montañés</h2>\n",
        "\n",
        "<font color=\"#6E6E6E\"><h2 align=\"left\">manuel.smontanes@gmail.com</h2></font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUvfb3ZvmvL1"
      },
      "source": [
        "COLAB = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "3b744bfd-8e36-439e-8399-2adb5709b967",
        "_uuid": "b1f37b3d76f670c6f90ee25c2643b8e3f6a0596e",
        "id": "XxJM_-5smQnu"
      },
      "source": [
        "# Base de datos y kernel de lectura y visualización de la base de datos obtenidos de:\n",
        "#\n",
        "# https://www.kaggle.com/kmader/lungnodemalignancy\n",
        "\n",
        "import cv2 # pip install opencv-python\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm # pip install tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "#from skimage.util.montage import montage2d # pip install scikit-image\n",
        "import h5py\n",
        "import urllib\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e0dVpjXmQn6"
      },
      "source": [
        "## **Carga de datos**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "ec465ae2-55e2-4469-adee-715638e8aa79",
        "_uuid": "98011364ae3e806899592f64fde65dc69c2a8b6c",
        "id": "wyAIouiNmQn-"
      },
      "source": [
        "if COLAB:\n",
        "    from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "    gdd.download_file_from_google_drive(file_id='1Ai3qxn-N-9T5wTblXNgVTIHlvwrvIXXg',\n",
        "                                        dest_path='./all_patches.hdf5')\n",
        "\n",
        "with h5py.File('all_patches.hdf5', 'r') as luna_h5:\n",
        "    all_slices  = luna_h5['ct_slices'].value\n",
        "    all_classes = luna_h5['slice_class'].value\n",
        "    print('shape of all_slices:', all_slices.shape)\n",
        "    print('shape of classes:   ', all_classes.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOQSXQriceZv"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jizbtpSTmQoE"
      },
      "source": [
        "np.unique(all_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM0HCw-xmQoL"
      },
      "source": [
        "def mi_montage2d(data):\n",
        "    n = len(data)\n",
        "    lado = int(np.ceil(np.sqrt(n)))\n",
        "    alto1, ancho1 = data.shape[1:]\n",
        "    aux = np.zeros((lado*alto1, lado*ancho1))\n",
        "    for i,image in enumerate(data):\n",
        "        row = i // lado\n",
        "        col = i % lado\n",
        "        aux[(row*alto1):((row+1)*alto1), (col*ancho1):((col+1)*ancho1)] = image\n",
        "    return aux"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v37okqFmQoP"
      },
      "source": [
        "def draw_borders(ax, ntiles, tile_width, tile_height, color='r'):\n",
        "    \n",
        "    aux1 = int(np.ceil(np.sqrt(ntiles)))\n",
        "    \n",
        "    npixels_y = tile_height*aux1\n",
        "    for i in range(aux1-1):\n",
        "        aux2 = (i+1)*tile_width - 0.5\n",
        "        ax.plot([aux2, aux2], [0, npixels_y - 1], color)\n",
        "        \n",
        "    npixels_x = tile_width*aux1\n",
        "    for i in range(aux1-1):\n",
        "        aux2 = (i+1)*tile_height - 0.5\n",
        "        ax.plot([0, npixels_x - 1], [aux2, aux2], color)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scNG7dEbmQoU"
      },
      "source": [
        "size = 9\n",
        "fig, (ax1, ax2) = plt.subplots(1,2,figsize = (16, 8))\n",
        "plt_args = dict(cmap = 'bone', vmin = -600, vmax = 300)\n",
        "#plt_args = dict(cmap = 'bwr', vmin = -600, vmax = 300)\n",
        "ax1.imshow(mi_montage2d(all_slices[np.random.choice(np.where(all_classes==1)[0],size=size)]), **plt_args)\n",
        "ax1.set_title('some malignant tiles (random sample)')\n",
        "draw_borders(ax1, size, all_slices.shape[1], all_slices.shape[2], 'r')\n",
        "\n",
        "ax2.imshow(mi_montage2d(all_slices[np.random.choice(np.where(all_classes==0)[0],size=size)]), **plt_args)\n",
        "ax2.set_title('some benign tiles (random sample)')\n",
        "draw_borders(ax2, size, all_slices.shape[1], all_slices.shape[2], 'r');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "5cb1cd2c-4f2d-4a05-8e82-f6dc2025f278",
        "_uuid": "c8d293899d545b47b88eeeadb952a5f54eb62005",
        "id": "u7j5zv86mQoY"
      },
      "source": [
        "## **Partición y reformateo de datos**\n",
        "\n",
        "Partiremos los datos en bases de datos de entrenamiento y validación. Recodificaremos la clase con la técnica one-hot.\n",
        "Se estandarizarán los datos de la imagen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7vDNvnJdO6Y"
      },
      "source": [
        "all_slices.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZPTzZZxmQoa"
      },
      "source": [
        "print(all_slices.min(), all_slices.max(), all_slices.mean(), all_slices.std())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP6v1HSHmQoh"
      },
      "source": [
        "plt.figure(figsize=(10,3))\n",
        "plt.hist(all_slices.reshape(-1), bins=100) #, density=True)\n",
        "plt.xlabel('Intensidades de los pixels', fontsize=14)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5ehDW01mQol"
      },
      "source": [
        "plt.hist(all_classes)\n",
        "plt.xlabel('Clases', fontsize=14)\n",
        "plt.show()\n",
        "\n",
        "unicos, counts = np.unique(all_classes, return_counts=True)\n",
        "print(unicos)\n",
        "print(counts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ3FmDkhoYex"
      },
      "source": [
        "prioris_clases = counts / sum(counts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eESCiOymQor"
      },
      "source": [
        "print(prioris_clases.round(2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M88QBIvEmQox"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "#X_vec = (np.expand_dims(all_slices,-1) - np.mean(all_slices))/np.std(all_slices)\n",
        "X_vec = np.expand_dims(all_slices,-1)\n",
        "print(all_slices.shape)\n",
        "X_vec.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLinNCmNmQo0"
      },
      "source": [
        "y_vec = to_categorical(all_classes)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vec, y_vec, \n",
        "                                                   train_size = 0.75,\n",
        "                                                   random_state = 1, \n",
        "                                                   stratify = all_classes)\n",
        "\n",
        "mean_train = np.mean(X_train)\n",
        "std_train  = np.std(X_train)\n",
        "\n",
        "X_train = (X_train - mean_train) / std_train\n",
        "X_test  = (X_test  - mean_train) / std_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "ca159b6a-66fd-4333-99d7-bc5942931b29",
        "_uuid": "434ec37a2e9246bc48ebbdc801c3e37edf3d62ea",
        "id": "Deu13LMPmQo5"
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open('mi_fichero.b', 'wb') as f:\n",
        "    pickle.dump(mean_train, f)\n",
        "    pickle.dump(std_train, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiuYfDHrmQo8"
      },
      "source": [
        "# En explotación:\n",
        "with open('mi_fichero.b', 'rb') as f:\n",
        "    a = pickle.load(f)\n",
        "    b = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_CeYJuqmQpB"
      },
      "source": [
        "print(mean_train, std_train)\n",
        "print(a,b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPCHh9QgmQpF"
      },
      "source": [
        "plt.figure(figsize=(10,3))\n",
        "plt.hist(X_train.reshape(-1), bins=100, density=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THb5Ta3Ho5Xc"
      },
      "source": [
        "## **Modelo Dummy (baseline)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST4fQzDEmQpJ"
      },
      "source": [
        "np.shape(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb51bdmAmQpO"
      },
      "source": [
        "X_tr = np.zeros((np.shape(X_train)[0], np.shape(X_train)[1]*np.shape(X_train)[2]))\n",
        "for i in range(np.shape(X_train)[0]):\n",
        "    X_tr[i] = X_train[i].flatten()\n",
        "X_te = np.zeros((np.shape(X_test)[0], np.shape(X_test)[1]*np.shape(X_test)[2]))\n",
        "for i in range(np.shape(X_test)[0]):\n",
        "    X_te[i] = X_test[i].flatten()\n",
        "\n",
        "print(\"X_train shape:\", np.shape(X_train))\n",
        "print(\"X_tr shape:   \", np.shape(X_tr))\n",
        "print(\"X_test shape: \", np.shape(X_test))\n",
        "print(\"X_te shape:   \", np.shape(X_te))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojU1uhJemQpT"
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "clf = DummyClassifier(strategy=\"most_frequent\")\n",
        "clf.fit(X_tr, np.argmax(y_train,1))\n",
        "print('Train accuracy:', clf.score(X_tr, np.argmax(y_train,1)))\n",
        "print('Test accuracy :', clf.score(X_te, np.argmax(y_test,1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le9GvSyqmQpY"
      },
      "source": [
        "try:\n",
        "    from scikitplot.metrics import plot_confusion_matrix\n",
        "except:\n",
        "    !pip install scikit-plot\n",
        "    from scikitplot.metrics import plot_confusion_matrix\n",
        "\n",
        "plot_confusion_matrix(y_test.argmax(1), clf.predict(X_te),\n",
        "                      x_tick_rotation=60, figsize=(5,5),\n",
        "                      text_fontsize='large');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4c2tgXAgVG6"
      },
      "source": [
        "from sklearn.metrics import classification_report, roc_curve, auc\n",
        "\n",
        "print('')\n",
        "print(classification_report(np.argmax(y_test,1),\n",
        "                            clf.predict(X_te)))\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(np.argmax(y_test, 1), clf.predict_proba(X_te)[:,1])\n",
        "fig, ax1 = plt.subplots(1,1)\n",
        "ax1.plot(fpr, tpr, 'r-.', label = 'Simple model (%2.2f)' % auc(fpr, tpr))\n",
        "ax1.set_xlabel('False Positive Rate')\n",
        "ax1.set_ylabel('True Positive Rate')\n",
        "ax1.plot(fpr, fpr, 'b-', label = 'Random Guess')\n",
        "ax1.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08tZAOwlmQpN"
      },
      "source": [
        "## **Modelo shallow: regresión logística**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DETbrLesmQpe"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzl-9gv5mQph"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model2 = LogisticRegression()\n",
        "model2.fit(X_tr, np.argmax(y_train,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L0KpOSbmQpm"
      },
      "source": [
        "print('Train accuracy:', model2.score(X_tr, np.argmax(y_train,1)))\n",
        "print('Test accuracy :', model2.score(X_te, np.argmax(y_test,1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeFXvmEzmQpp"
      },
      "source": [
        "np.argmax(y_test,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YIOu22UmQp0"
      },
      "source": [
        "plot_confusion_matrix(y_test.argmax(1), model2.predict(X_te),\n",
        "                      x_tick_rotation=60, figsize=(5,5),\n",
        "                      text_fontsize='large');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "if3Mc7gKmQp2"
      },
      "source": [
        "from sklearn.metrics import classification_report, roc_curve, auc\n",
        "\n",
        "print('')\n",
        "print(classification_report(np.argmax(y_test,1),\n",
        "                            model2.predict(X_te)))\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(np.argmax(y_test, 1), model2.predict_proba(X_te)[:,1])\n",
        "fig, ax1 = plt.subplots(1,1)\n",
        "ax1.plot(fpr, tpr, 'r-.', label = 'Simple model (%2.2f)' % auc(fpr, tpr))\n",
        "ax1.set_xlabel('False Positive Rate')\n",
        "ax1.set_ylabel('True Positive Rate')\n",
        "ax1.plot(fpr, fpr, 'b-', label = 'Random Guess')\n",
        "ax1.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "db05d806-063c-4ab4-b435-3573b39b9e46",
        "_uuid": "ad67302a9687e267ad4cf1078b46024633033356",
        "id": "c65qA_VgmQp5"
      },
      "source": [
        "# **Definición de la arquitectura CNN**\n",
        "\n",
        "Entrenaremos el modelo desde cero. Otra posibilidad es utilizar modelos pre entrenados (transfer learning)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xs1dlHovmQp6"
      },
      "source": [
        "from keras.models import Sequential, load_model, Model\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras import optimizers\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzE-Pxo5mQp9"
      },
      "source": [
        "print(\"X_train shape:\", np.shape(X_train))\n",
        "print(\"X_test shape: \", np.shape(X_test))\n",
        "print(\"y_train shape:\", np.shape(y_train))\n",
        "print(\"y_test shape: \", np.shape(y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iogitpgHgxe2"
      },
      "source": [
        "y_train[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keUuxWiLmQp_"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgzMi6XJmQqB"
      },
      "source": [
        "X_tr.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok93f4I-mQqF"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxETTVcurGpa"
      },
      "source": [
        "input_shape = X_train.shape[1:]\n",
        "input_shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKN5IBnymQqH"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjHwlwvKq1QR"
      },
      "source": [
        "num_classes = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddypxCmOagAY"
      },
      "source": [
        "from keras.layers import AveragePooling2D, Dropout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yF89prvcmQqJ"
      },
      "source": [
        "# Arquitectura de la red\n",
        "# Rellenar arquitectura:\n",
        "\n",
        "model = ...\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdBvuOPmmQqN"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWHh0y3umQqP"
      },
      "source": [
        "# graphviz\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "SVG(model_to_dot(model, show_shapes=True, dpi=72\n",
        "                 ).create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pp74Cvq1mQqS"
      },
      "source": [
        "# **Entrenamiento del modelo CNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iqxp3FymQqS"
      },
      "source": [
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "def grafica_entrenamiento(tr_acc, val_acc):\n",
        "    ax=plt.figure(figsize=(10,4)).gca()\n",
        "    plt.plot(1+np.arange(len(tr_acc)), 100*np.array(tr_acc))\n",
        "    plt.plot(1+np.arange(len(val_acc)), 100*np.array(val_acc))\n",
        "    plt.title('tasa de acierto del modelo (%)', fontsize=18)\n",
        "    plt.ylabel('tasa de acierto (%)', fontsize=18)\n",
        "    plt.xlabel('epoca', fontsize=18)\n",
        "    plt.legend(['entrenamiento', 'validacion'], loc='upper left')\n",
        "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyjGL4LQmQqV"
      },
      "source": [
        "acum_tr_acc = []\n",
        "acum_val_acc = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbjOGjHOgRn0"
      },
      "source": [
        "from IPython.display import clear_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fO9fYA-rmQqZ"
      },
      "source": [
        "LOAD_MODEL = False\n",
        "\n",
        "Ntr = 4000\n",
        "\n",
        "epochs = 100\n",
        "batch_size = 16\n",
        "\n",
        "X_tr  = X_train[:Ntr]\n",
        "y_tr  = y_train[:Ntr]\n",
        "X_val = X_train[Ntr:]\n",
        "y_val = y_train[Ntr:]\n",
        "\n",
        "if not LOAD_MODEL:\n",
        "    filepath=\"model_current_best_v2.h5\"\n",
        "    \n",
        "    checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,\n",
        "                                 save_best_only=True,\n",
        "                                 mode='max') # graba sólo los que mejoran en validación\n",
        "    callbacks_list = [checkpoint]\n",
        "    \n",
        "    for e in range(epochs):\n",
        "        history = model.fit(X_tr, y_tr,\n",
        "                            batch_size=batch_size,\n",
        "                            epochs=1,\n",
        "                            callbacks=callbacks_list,\n",
        "                            verbose=1,\n",
        "                            validation_data=(X_val, y_val))\n",
        "        \n",
        "        acum_tr_acc = acum_tr_acc + history.history['accuracy']\n",
        "        acum_val_acc = acum_val_acc + history.history['val_accuracy']\n",
        "        \n",
        "        if len(acum_tr_acc) > 1:\n",
        "            clear_output()\n",
        "            grafica_entrenamiento(acum_tr_acc, acum_val_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xwhk83sXmQqb"
      },
      "source": [
        "# **Resultados obtenidos por el modelo CNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MilVLfN3mQqc"
      },
      "source": [
        "if LOAD_MODEL:\n",
        "    if COLAB:\n",
        "        urllib.request.urlretrieve(\"https://drive.google.com/uc?export=download&id=1UKpxwZsfPAp0kHywBucwWBtkxYAXy0lq\",\n",
        "                                   \"modelo_entrenado.h5\")\n",
        "    model = load_model('./modelo_entrenado.h5')\n",
        "else:\n",
        "    model = load_model('model_current_best_v2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIzvIrN9mQqg"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_8JD7ndmQqi"
      },
      "source": [
        "score_tr = model.evaluate(X_tr, y_tr, verbose=0)\n",
        "print('Train loss    :', score_tr[0])\n",
        "print('Train accuracy:', score_tr[1])\n",
        "\n",
        "score_val = model.evaluate(X_val, y_val, verbose=0)\n",
        "print('Val loss    :', score_val[0])\n",
        "print('Val accuracy:', score_val[1])\n",
        "\n",
        "score_te = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss     :', score_te[0])\n",
        "print('Test accuracy :', score_te[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMveGUZbmH37"
      },
      "source": [
        "model.predict(X_test[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GWL-QHmmQql"
      },
      "source": [
        "umbral_decision_maligno = 0.5 # 0.4, 0.3, 0.2 ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eidqHDGKmQqm"
      },
      "source": [
        "alarmas = 1*(model.predict(X_test)[:,1]>umbral_decision_maligno)\n",
        "alarmas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8zdyj2Fs7J1"
      },
      "source": [
        "clases_test = y_test.argmax(1) # clase real test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0H7GsBtmQqo"
      },
      "source": [
        "confusion_matrix(clases_test, alarmas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1mG_6WumQqr"
      },
      "source": [
        "# en el siguiente cálculo y en adelante es equivalente\n",
        "# a asumir que umbral_decision_maligno = 0.5\n",
        "plot_confusion_matrix(y_test.argmax(1), model.predict(X_test).argmax(1),\n",
        "                      x_tick_rotation=60, figsize=(5,5),\n",
        "                      text_fontsize='large');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Rot6M7amQqu"
      },
      "source": [
        "y_pred_proba = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred_proba,1)\n",
        "print('')\n",
        "print(classification_report(clases_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "a2a4c7a7-d2dc-4169-accb-309810127db7",
        "_uuid": "ea38d77983dc6bee57ffa77a80b91b9401e02aaa",
        "id": "9xFqnUl5mQqw"
      },
      "source": [
        "fpr, tpr, thresholds = roc_curve(clases_test, y_pred_proba[:,1])\n",
        "fig, ax1 = plt.subplots(1,1)\n",
        "ax1.plot(fpr, tpr, 'r-.', label = 'CNN (%2.2f)' % auc(fpr, tpr))\n",
        "ax1.set_xlabel('False Positive Rate')\n",
        "ax1.set_ylabel('True Positive Rate')\n",
        "ax1.plot(fpr, fpr, 'b-', label = 'Random Guess')\n",
        "ax1.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stwaBSRimQqy"
      },
      "source": [
        "# **Análisis de los pesos de la primera capa**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OX9bSfjmmQqz"
      },
      "source": [
        "weights = model.get_weights()\n",
        "print(np.shape(weights))\n",
        "for i in range(len(weights)):\n",
        "    print('shape of weights[%d]: ' % i, np.shape(weights[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUWKwrWGmQq1"
      },
      "source": [
        "weights[0][:,:,0,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8zqb1J8mQq3"
      },
      "source": [
        "# kernels de la primera capa\n",
        "\n",
        "nfilters = weights[0].shape[3]\n",
        "lado = int(np.ceil(np.sqrt(nfilters)))\n",
        "plt.subplots(lado,lado,figsize = (12, 15))\n",
        "\n",
        "ma = abs(weights[0]).max()\n",
        "\n",
        "for i in range(nfilters):\n",
        "    kernel = weights[0][:,:,0,i]\n",
        "    plt.subplot(lado,lado,i+1)\n",
        "    plt.imshow(kernel, vmin=-ma, vmax=ma, cmap='bwr')\n",
        "    plt.title('kernel %d' % i)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gW6-BuKEmQq6"
      },
      "source": [
        "capa = 0 # 4\n",
        "intermediate_layer_model = Model(inputs=model.input,\n",
        "                                 outputs=model.layers[capa].output)\n",
        "intermediate_layer_model.summary()\n",
        "SVG(model_to_dot(intermediate_layer_model,show_shapes=True,dpi=72).create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "605NoM8WmQq7"
      },
      "source": [
        "id_imagen = 1\n",
        "imagen = X_test[id_imagen,:,:,0]\n",
        "salidas_capa0 = intermediate_layer_model.predict(imagen.reshape([1,imagen.shape[0],\n",
        "                                                                 imagen.shape[1],1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlotQEFDmQq9"
      },
      "source": [
        "salidas_capa0.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGYBJLs4mQrD"
      },
      "source": [
        "plt.figure(figsize=(2,2))\n",
        "plt.imshow(imagen, cmap='gray')\n",
        "plt.title('input image', size=12)\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "plt.show()\n",
        "\n",
        "plt.subplots(lado,lado,figsize = (12, 15))\n",
        "\n",
        "ma = abs(salidas_capa0).max()\n",
        "\n",
        "for i in range(salidas_capa0.shape[-1]):\n",
        "    plt.subplot(lado,lado,i+1)\n",
        "    plt.imshow(salidas_capa0[0,:,:,i], vmin=-ma, vmax=ma, cmap='bwr')\n",
        "    plt.title('salida kernel %d' % i, fontsize=10)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4Jl9tCVmQrF"
      },
      "source": [
        "### **¿A qué partes de la imagen de entrada es más sensible la salida de la red?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2pHfLAVDSic"
      },
      "source": [
        "### **GradCam:**\n",
        "\n",
        "(de https://medium.com/analytics-vidhya/visualizing-activation-heatmaps-using-tensorflow-5bdba018f759)\n",
        "\n",
        "1- Calcular para una imagen la salida del modelo y la salida de la última capa convolucional\n",
        "\n",
        "2- Encuentrar la neurona de salida más activa (que es la que determina la clase predicha)\n",
        "\n",
        "3- Calcular el gradiente de dicha neurona de salida con respecto a la última capa convolucional\n",
        "\n",
        "3- Promediar y pesar esto con la salida de la última capa convolucional\n",
        "\n",
        "4- Normalizar entre 0 y 1 para visualizar\n",
        "\n",
        "5- Convertir a RGB y superponerla a la imagen original"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL-NBp7QmQrF"
      },
      "source": [
        "def find_ind_last_conv2D(model):\n",
        "    ind_last_conv2D_layer = None\n",
        "    for i,x in enumerate(model.layers):\n",
        "        if x.__class__.__name__ == \"Conv2D\":\n",
        "            ind_last_conv2D_layer = i\n",
        "    return ind_last_conv2D_layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxhrkVJPmQrH"
      },
      "source": [
        "ind_last_conv2D_layer = find_ind_last_conv2D(model)\n",
        "ind_last_conv2D_layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvRL1oAWmQrJ"
      },
      "source": [
        "model.layers[ind_last_conv2D_layer]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNvdIM5dClgY"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVTON4LqmQrR"
      },
      "source": [
        "def show_heatmap(model, im, es_maligna):\n",
        "    imag = np.expand_dims(im, axis=0) # de 1 imagen pasamos a 1 conjunto de 1 imagen\n",
        "        \n",
        "    # The is the output feature map of the last convolutional layer\n",
        "    last_conv_layer = model.layers[find_ind_last_conv2D(model)]\n",
        "    \n",
        "    # This is the gradient of the \"benign\" class with regard to\n",
        "    # the output feature map of last convolutional layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        iterate = tf.keras.models.Model([model.inputs], [model.output, last_conv_layer.output])\n",
        "        model_out, last_conv_layer = iterate(imag)\n",
        "        class_out = model_out[:, np.argmax(model_out[0])]\n",
        "        grads = tape.gradient(class_out, last_conv_layer)\n",
        "\n",
        "        # mean intensity of the gradient over a specific feature map channel:\n",
        "        pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "    \n",
        "    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, last_conv_layer), axis=-1)    \n",
        "    heatmap = np.maximum(heatmap, 0) # se quitan los negativos (se ponen a 0)\n",
        "    heatmap /= np.max(heatmap) # se normaliza entre 0 y 1\n",
        "    heatmap = heatmap[0] # pasamos de 1 conjunto de 1 heatmap a 1 heatmap\n",
        "        \n",
        "    \n",
        "    # We use cv2 to load the original image\n",
        "    #img = cv2.imread(img_path)\n",
        "    img = imag[0]\n",
        "    \n",
        "    img = np.zeros((im.shape[0],im.shape[1],3))\n",
        "#    print(im.shape, imag.shape)\n",
        "    for i in range(3):\n",
        "        img[:,:,i] = imag[0,:,:,0]\n",
        "\n",
        "    \n",
        "    # We resize the heatmap to have the same size as the original image\n",
        "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "    \n",
        "    # We convert the heatmap to RGB\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    \n",
        "    # We apply the heatmap to the original image\n",
        "    #heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_HOT)\n",
        "    \n",
        "    img = np.maximum(img, -2)\n",
        "    img = np.minimum(img,  2)\n",
        "    img = (img+2)/4;\n",
        "    # 0.4 here is a heatmap intensity factor\n",
        "    superimposed_img = heatmap * 0.2 / 255 + 0.8*img\n",
        "    #print(heatmap.min(), heatmap.max(), heatmap.mean(), heatmap.std())\n",
        "    #print(img.min(), img.max(), img.mean(), img.std())\n",
        "    #print(superimposed_img.min(),  superimposed_img.max(),\n",
        "    #      superimposed_img.mean(), superimposed_img.std())\n",
        "    \n",
        "    plt.figure(figsize=(15,5))\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.imshow(img, vmin=0, vmax=1)\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.imshow(heatmap, vmin=0, vmax=1)\n",
        "    plt.colorbar()\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.imshow(superimposed_img, vmin=0, vmax=1)\n",
        "    plt.show()\n",
        "    #print(np.shape(imag))\n",
        "    print(\"- Probabilidad clase maligna:\", model.predict(imag)[0][1])\n",
        "    print(\"-\", \"Clase real:\", \"maligna\" if es_maligna else \"benigna\")\n",
        "    print(\"\\n\\n\\n\")\n",
        "    return heatmap, superimposed_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V220wACmQrT"
      },
      "source": [
        "ind = 0\n",
        "for i in range(ind, ind+10):\n",
        "    heat_map, superimposed_img = show_heatmap(model, X_test[i], y_test[i,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwIzlrr8mQrV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}