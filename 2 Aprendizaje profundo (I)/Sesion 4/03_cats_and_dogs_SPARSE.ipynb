{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03-cats_and_dogs_SPARSE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vicentcamison/idal_ia3/blob/main/2%20Aprendizaje%20profundo%20(I)/Sesion%204/03_cats_and_dogs_SPARSE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrIBQZFhdEf_"
      },
      "source": [
        "COLAB = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQ8QmTCQjfpW"
      },
      "source": [
        "Si se desea ejecutar en local:\n",
        "\n",
        "- Descargar el dataset de: https://drive.google.com/file/d/1CpfC-e5doyIQUXoaOUMDLeTL7EKR9UMu\n",
        "\n",
        "- Poner variable COLAB a False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CJTDGuDWa3M"
      },
      "source": [
        "# Basado en parte de:\n",
        "# https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W68hFjybWa3P"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from keras.models import Sequential, load_model, Model\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import regularizers\n",
        "from keras import optimizers\n",
        "from keras import models\n",
        "from glob import glob\n",
        "import cv2\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from IPython.display import SVG, display, clear_output\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GXDzz3bTLMV"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-8gOCujdP37"
      },
      "source": [
        "if COLAB:\n",
        "    from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "    gdd.download_file_from_google_drive(file_id='1CpfC-e5doyIQUXoaOUMDLeTL7EKR9UMu',\n",
        "                                        dest_path='./small_data.zip', unzip=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Tb3C1EgWz1r"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJlZPaYmW22d"
      },
      "source": [
        "!ls small_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "walL9rvWW6Lf"
      },
      "source": [
        "!ls small_data/train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl15faNNW88L"
      },
      "source": [
        "!ls small_data/train/cats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJ1xf6EVXdL-"
      },
      "source": [
        "ficheros = glob(\"./small_data/train/cats/*\")\n",
        "ficheros[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ck_4gkiezfz"
      },
      "source": [
        "for fich in ficheros[:10]:\n",
        "    imagen = load_img(fich)\n",
        "    display(imagen)\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnGrnWfrIZlX"
      },
      "source": [
        "ficheros = glob(\"./small_data/train/dogs/*\")\n",
        "for fich in ficheros[:10]:\n",
        "    imagen = load_img(fich)\n",
        "    display(imagen)\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrluBG4VWa3S"
      },
      "source": [
        "train_data_dir = 'small_data/train'\n",
        "validation_data_dir = 'small_data/validation'\n",
        "test_data_dir = 'small_data/test0'\n",
        "\n",
        "batch_size = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-u9ZVoRWANS"
      },
      "source": [
        "A continuación vamos a definir un ImageDataGenerator que es lo que nos servirá para realizar data augmentation.\n",
        "\n",
        "Para ver opciones:\n",
        "\n",
        "https://keras.io/api/preprocessing/image/#imagedatagenerator-class\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6zY8pZ8haIS"
      },
      "source": [
        "preprocess_input = lambda x:x/255."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb3RiGQPYM1a"
      },
      "source": [
        "# data augmentation:\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    dtype='float32',\n",
        "    preprocessing_function = preprocess_input,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    fill_mode='nearest',\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEgFiD9Kap84"
      },
      "source": [
        "imagen_num = np.expand_dims(np.array(imagen), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUtIwZ_-Y3T0"
      },
      "source": [
        "plt.imshow(train_datagen.flow(imagen_num)[0][0])\n",
        "plt.axis(\"off\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xN7yt9mWa3V"
      },
      "source": [
        "## **Red convolucional**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx5NIFyWdSf_"
      },
      "source": [
        "# dimensiones a las que vamos a llevar las imágenes\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "normed_dims = (img_height, img_width)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwd_tQQGw2em"
      },
      "source": [
        "normed_dims"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg26waqCjlZf"
      },
      "source": [
        "###**Loss del modelo por defecto en clasificación**\n",
        "\n",
        "El loss típico en redes neuronales y regresión logística (función de coste que minimiza el algoritmo de optimización) es el llamado **cross-entropy** (entropía cruzada) o **log-loss**:\n",
        "\n",
        "**log-loss = promedio( ln ( 1 / Pmodelo(clase real) ))**\n",
        "\n",
        "donde ln es el logaritmo neperiano y Pmodelo(clase real) es la probabilidad, según el modelo, de la clase real para un ejemplo concreto.\n",
        "\n",
        "El log-loss nunca puede ser negativo ya que (1 / Pmodelo) es mayor o igual que 1 y por tanto el logaritmo nunca es menor que cero.\n",
        "\n",
        "Por otra parte la única manera de que el log-loss sea cero es que Pmodelo(clase real) sea siempre 1, lo que equivale a decir que el modelo siempre acierta con la clase \"sin dudarlo\" (la probabilidad asignada es siempre 1).\n",
        "\n",
        "Algunos ejemplos con diferentes probabilidades:\n",
        "\n",
        "- Si Pmodelo(clase real) = 1 entonces ln( 1 / Pmodelo(clase real) ) = ln(1 / 1) = 0\n",
        "\n",
        "- Si Pmodelo(clase real) = 0.8 (el modelo \"acierta\" pero no está completamente seguro) entonces ln( 1 / Pmodelo (clase real) ) = ln(1 / 0.8) > 0\n",
        "\n",
        "- Si Pmodelo(clase real) = 0 (el modelo se equivoca completamente), ln( 1 / Pmodelo (clase real) ) = ln(1 / 0) = infinito"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJxrBPWsjleg"
      },
      "source": [
        "Una variante del log-loss es introducir pesos en las clases. En keras esto se introduce en el parámetro class_weight en el método **fit** para entrenar el modelo. La variante es entonces:\n",
        "\n",
        "**log-loss = promedio( peso clase real · ln ( 1 / Pmodelo(clase real) ))**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOxNUu8ZvlYO"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), activation='relu',\n",
        "                 input_shape=normed_dims+(3,)))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Conv2D(32, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Conv2D(64, (3,3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Flatten())\n",
        "# aqui empieza la red neuronal 'standard'\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2))\n",
        "model.add(Activation(\"softmax\")) # Separamos la función de activación del dense para el\n",
        "# cálculo posterior de los heatmaps\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "#              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              optimizer=optimizers.RMSprop(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K658Z9NnX333"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju3YuClNWa3e"
      },
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "if COLAB:\n",
        "    display(SVG(model_to_dot(model, show_shapes=True,dpi=72).create(prog='dot', format='svg')))\n",
        "else:\n",
        "    display(SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WD-qj3yoyJDB"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    dtype='float32',\n",
        "    preprocessing_function = preprocess_input,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    fill_mode='nearest',\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "val_datagen  = ImageDataGenerator(dtype='float32',\n",
        "                                  preprocessing_function = preprocess_input)\n",
        "\n",
        "test_datagen = ImageDataGenerator(dtype='float32',\n",
        "                                  preprocessing_function = preprocess_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As30eiA_awL-"
      },
      "source": [
        "validation_data_dir, normed_dims"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExBd0hJ_jwX5"
      },
      "source": [
        "**flow_from_directory (a continuación):**\n",
        "\n",
        "- Los datos están en la carpeta que indiquemos. De ella cuelgan tantas subcarpetas como clases. Si hay N subcarpetas habrá por tanto N clases. El índice asignado a cada clase es su posición en orden alfabético empezando por 0. **Ejemplo:** si las subcarpetas son 'birds', 'cats' y 'dogs', los índices son respectivamente 0, 1, 2\n",
        "\n",
        "- **shuffle=True**: los datos se recorren en orden aleatorio.\n",
        "\n",
        "- **class_mode='categorical'**: las clases se codifican con one-hot. En el caso de tres carpetas 'birds', 'cats' y 'dogs', a todos los ficheros en la carpeta 'birds' se les asigna la clase 1, 0, 0. A todos los ficheros de 'cats' se les asigna 0, 1, 0, y a todos los de 'dogs' 0, 0, 1. **Importante**: en la capa de salida debe haber activación **softmax** y el loss en el compile debe ser **categorical_crossentropy**.\n",
        "\n",
        "- **class_mode='binary'**: hay dos clases (0 y 1). En el caso de dos carpetas 'cats' y 'dogs', a todos los ficheros en la carpeta 'cats' se les asigna 0 y a todos los de 'dogs' 1. **Importante**: en la capa de salida debe haber activación **binary** y el loss en el compile debe ser **binary_crossentropy**.\n",
        "\n",
        "- **class_mode='sparse'**: las clases se codifican directamente con su índice. En el caso de tres carpetas 'birds', 'cats' y 'dogs', a todos los ficheros en la carpeta 'birds' se les asigna la clase 0, a todos los ficheros de 'cats' se les asigna 1, y a todos los de 'dogs' 2. **Importante**: en la capa de salida debe haber activación **softmax** y el loss en el compile debe ser **sparse_categorical_crossentropy**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlmhVC-bYM_1"
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=normed_dims,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    class_mode='sparse') # binary: 0/1. Sparse: entero a partir de 0\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=normed_dims,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    class_mode='sparse') # binary: 0/1. Sparse: entero a partir de 0\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=normed_dims,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    class_mode='sparse') # binary: 0/1. Sparse: entero a partir de 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u96-8fMjbIcx"
      },
      "source": [
        "train_generator.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smKSN-oycTL6"
      },
      "source": [
        "number_train_samples = train_generator.n\n",
        "number_val_samples   = validation_generator.n\n",
        "number_test_samples  = test_generator.n\n",
        "\n",
        "number_train_samples, number_val_samples, number_test_samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDSlstsKWa3i"
      },
      "source": [
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "def grafica_entrenamiento(tr_acc, val_acc, tr_loss, val_loss, best_i,\n",
        "                          figsize=(10,4)):\n",
        "    plt.figure(figsize=figsize)\n",
        "    ax = plt.subplot(1,2,1)\n",
        "    plt.plot(1+np.arange(len(tr_acc)),  100*np.array(tr_acc))\n",
        "    plt.plot(1+np.arange(len(val_acc)), 100*np.array(val_acc))\n",
        "    plt.plot(1+best_i, 100*val_acc[best_i], 'or')\n",
        "    plt.title('tasa de acierto del modelo (%)', fontsize=18)\n",
        "    plt.ylabel('tasa de acierto (%)', fontsize=18)\n",
        "    plt.xlabel('época', fontsize=18)\n",
        "    plt.legend(['entrenamiento', 'validación'], loc='upper left')\n",
        "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(1+np.arange(len(tr_acc)), np.array(tr_loss))\n",
        "    plt.plot(1+np.arange(len(val_acc)), np.array(val_loss))\n",
        "    plt.plot(1+best_i, val_loss[best_i], 'or')\n",
        "    plt.title('loss del modelo', fontsize=18)\n",
        "    plt.ylabel('loss', fontsize=18)\n",
        "    plt.xlabel('época', fontsize=18)\n",
        "    plt.legend(['entrenamiento', 'validación'], loc='upper left')\n",
        "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvUaztU0Wa3l"
      },
      "source": [
        "acum_tr_acc = []\n",
        "acum_val_acc = []\n",
        "best_val_acc = -1000\n",
        "acum_tr_loss  = []\n",
        "acum_val_loss = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nqta4BkIWa3n"
      },
      "source": [
        "epochs = 5\n",
        "\n",
        "modelpath=\"model_current_best_parte3.h5\"\n",
        "\n",
        "checkpoint = ModelCheckpoint(modelpath, monitor='val_accuracy', verbose=1,\n",
        "                             save_best_only=True,\n",
        "                             mode='max') # graba sólo los que mejoran en validación\n",
        "callbacks_list = [checkpoint]\n",
        "for e in range(epochs):\n",
        "    history = model.fit(train_generator, \n",
        "                        steps_per_epoch=number_train_samples // batch_size,\n",
        "                        epochs=1,\n",
        "                        callbacks=callbacks_list,\n",
        "                        verbose=1,\n",
        "                        shuffle = False,\n",
        "                        validation_data=validation_generator,\n",
        "                        validation_steps=number_val_samples // batch_size\n",
        "                       )\n",
        "    \n",
        "    if history.history['val_accuracy'][-1] > best_val_acc:\n",
        "        print(\"Validation accuracy improved from\",\n",
        "            best_val_acc, 'to', history.history['val_accuracy'])\n",
        "        print(\"saving weights\")\n",
        "        best_val_acc = history.history['val_accuracy'][-1]\n",
        "    \n",
        "    acum_tr_acc.append(history.history['accuracy'][0])\n",
        "    acum_val_acc.append(history.history['val_accuracy'][0])\n",
        "    acum_tr_loss.append(history.history['loss'][0])\n",
        "    acum_val_loss.append(history.history['val_loss'][0])\n",
        "    \n",
        "    if len(acum_tr_acc) > 1:\n",
        "        clear_output()\n",
        "        best_i = np.argmax(acum_val_acc)\n",
        "        grafica_entrenamiento(acum_tr_acc, acum_val_acc, acum_tr_loss, acum_val_loss, best_i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jO6oqz6ft_BF"
      },
      "source": [
        "!ls -la"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8UrXO9Sng_4"
      },
      "source": [
        "model = load_model(modelpath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNI07vcLWa3q"
      },
      "source": [
        "## **Resultados obtenidos**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-g2AYJqWa3t"
      },
      "source": [
        "scores_tr = model.evaluate(train_generator)\n",
        "print('Train loss    :', scores_tr[0])\n",
        "print('Train accuracy:', scores_tr[1])\n",
        "print()\n",
        "\n",
        "scores_val = model.evaluate(validation_generator)\n",
        "print('Val loss    :', scores_val[0])\n",
        "print('Val accuracy:', scores_val[1])\n",
        "print()\n",
        "\n",
        "scores_te = model.evaluate(test_generator)\n",
        "print('Test loss     :', scores_te[0])\n",
        "print('Test accuracy :', scores_te[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZWJgCLcvO6F"
      },
      "source": [
        "test_generator.classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maD61ufgWa3w"
      },
      "source": [
        "y_real = test_generator.classes\n",
        "y_pred_proba = model.predict(test_generator)\n",
        "y_pred = np.argmax(y_pred_proba, axis=1)\n",
        "print('')\n",
        "print(classification_report(y_real, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x28VTWUvWa3y"
      },
      "source": [
        "clase_positiva = 1\n",
        "fpr, tpr, thresholds = roc_curve(y_real==clase_positiva, y_pred_proba[:,clase_positiva])\n",
        "fig, ax1 = plt.subplots(1,1)\n",
        "ax1.plot(fpr, tpr, 'r-.', label = 'CNN (%2.2f)' % auc(fpr, tpr))\n",
        "ax1.set_xlabel('False Positive Rate')\n",
        "ax1.set_ylabel('True Positive Rate')\n",
        "ax1.plot(fpr, fpr, 'b-', label = 'Random Guess')\n",
        "ax1.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASQl208vrWGX"
      },
      "source": [
        "## **Visualización de ejemplos de test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zt9vxEizseSE"
      },
      "source": [
        "test_datagen2 = ImageDataGenerator(dtype='float32',\n",
        "                                   preprocessing_function = preprocess_input)\n",
        "\n",
        "test_generator2 = test_datagen2.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=normed_dims,\n",
        "    batch_size=test_generator.n, # todas las imágnes del directorio test\n",
        "    shuffle=False,\n",
        "    class_mode='sparse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq_wZK3DseUW"
      },
      "source": [
        "test_generator2.reset()\n",
        "X_te, y_te = test_generator2.next()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3cXYEqFQyRl"
      },
      "source": [
        "X_te.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdfFcJzzRGq2"
      },
      "source": [
        "X_te.max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeQRqjEUucGM"
      },
      "source": [
        "class_indices = test_generator2.class_indices\n",
        "class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62rtQ4ERrric"
      },
      "source": [
        "ind_te1 = 1500\n",
        "\n",
        "image = X_te[ind_te1].copy()\n",
        "\n",
        "plt.imshow(image, cmap='jet')\n",
        "plt.axis(\"off\")\n",
        "p = model.predict(np.expand_dims(image, axis=0))[0][class_indices[\"dogs\"]]\n",
        "print(\"Probabilidad perro: {:2.1f}%\".format(100*p))\n",
        "p = model.predict(np.expand_dims(image, axis=0))[0][class_indices[\"cats\"]]\n",
        "print(\"Probabilidad gato : {:2.1f}%\".format(100*p))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yx0QJniRhu4_"
      },
      "source": [
        "## **Visualización del funcionamiento de la red**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eil-vNA76R8D"
      },
      "source": [
        "weights = model.get_weights()\n",
        "print(np.shape(weights))\n",
        "for i in range(len(weights)):\n",
        "    print('shape of weights[%d]: ' % i, np.shape(weights[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP7WnsQ1hxOo"
      },
      "source": [
        "# kernels de la primera capa convolucional\n",
        "ncapa = 0\n",
        "\n",
        "nfilters = weights[ncapa].shape[3]\n",
        "ncols = 7 # número de columnas en la figura\n",
        "\n",
        "ma = abs(weights[ncapa]).max()\n",
        "nrows = int(np.ceil(nfilters/ncols)) # número de filas en la figura\n",
        "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15,15*nrows/ncols))\n",
        "axes_r = axes.ravel()\n",
        "for i in range(nfilters):\n",
        "    kernel = weights[ncapa][:,:,2,i]\n",
        "    ax = axes_r[i]\n",
        "    ax.imshow(kernel, vmin=-ma, vmax=ma, cmap='bwr')\n",
        "    ax.set_xticks([]); ax.set_yticks([])\n",
        "    ax.set_title('pesos kernel %d' % i, fontsize=10)\n",
        "for i in range(nfilters,nrows*ncols):\n",
        "    fig.delaxes(axes_r[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9zJnqsWh2Wn"
      },
      "source": [
        "### **Visualización de las salidas de una sola capa**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DRJY257h2pD"
      },
      "source": [
        "# salida de una sola capa\n",
        "ncapa = 0\n",
        "intermediate_layer_model = Model(inputs=model.input,\n",
        "                                 outputs=model.layers[ncapa].output)\n",
        "intermediate_layer_model.summary()\n",
        "print(\"\\n\\n\")\n",
        "if COLAB:\n",
        "    display(SVG(model_to_dot(intermediate_layer_model,show_shapes=True,dpi=72).create(prog='dot', format='svg')))\n",
        "else:\n",
        "    display(SVG(model_to_dot(intermediate_layer_model,show_shapes=True).create(prog='dot', format='svg')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eAyuj_Rh6oX"
      },
      "source": [
        "imagen = X_te[1005]\n",
        "imagen.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9daH3ikFh8Tj"
      },
      "source": [
        "ejemplo = 10\n",
        "\n",
        "imagen = X_te[ejemplo]\n",
        "aux = np.expand_dims(imagen, axis=0)\n",
        "salida_capa = intermediate_layer_model.predict(aux)\n",
        "\n",
        "plt.figure(figsize=(3,3))\n",
        "plt.imshow(imagen, cmap='gray')\n",
        "plt.title('input image', size=12)\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "plt.show()\n",
        "\n",
        "print(\"Salidas capa \"+intermediate_layer_model.layers[-1].name, salida_capa.shape)\n",
        "\n",
        "nsalidas = salida_capa.shape[-1]\n",
        "ncols = 4\n",
        "nrows = int(np.ceil(nsalidas / ncols))\n",
        "\n",
        "ma = abs(salida_capa).max()\n",
        "\n",
        "plt.subplots(nrows,ncols,figsize = (12, 3*nrows))\n",
        "\n",
        "for i in range(nsalidas):\n",
        "    plt.subplot(nrows,ncols,i+1)\n",
        "#    plt.imshow(salida_capa[0,:,:,i], vmin=-ma, vmax=ma, cmap='bwr')\n",
        "    plt.imshow(salida_capa[0,:,:,i], cmap='viridis')\n",
        "    plt.xticks(())\n",
        "    plt.yticks(())\n",
        "    plt.title('salida kernel %d' % i, fontsize=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuIpGexwh-_A"
      },
      "source": [
        "### **Visualización de las salidas de varias capas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U5tljF5h_Xa"
      },
      "source": [
        "# Now we extract the outputs of the top 6 layers:\n",
        "layer_outputs = [layer.output for layer in model.layers[:6]]\n",
        "# Creates a model that will return these outputs, given the model input:\n",
        "activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
        "\n",
        "activations = activation_model.predict(X_te[ejemplo:(ejemplo+1)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4paKjpn4iCXT"
      },
      "source": [
        "# These are the names of the layers, so can have them as part of our plot\n",
        "layer_names = []\n",
        "for layer in model.layers[:8]:\n",
        "    layer_names.append(layer.name)\n",
        "\n",
        "images_per_row = 16\n",
        "\n",
        "# Now let's display our feature maps\n",
        "for layer_name, layer_activation in zip(layer_names, activations):\n",
        "    # This is the number of features in the feature map\n",
        "    n_features = layer_activation.shape[-1]\n",
        "\n",
        "    # The feature map has shape (1, size, size, n_features)\n",
        "    size = layer_activation.shape[1]\n",
        "\n",
        "    # We will tile the activation channels in this matrix\n",
        "    n_cols = n_features // images_per_row\n",
        "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
        "\n",
        "    # We'll tile each filter into this big horizontal grid\n",
        "    for col in range(n_cols):\n",
        "        for row in range(images_per_row):\n",
        "            channel_image = layer_activation[0,\n",
        "                                             :, :,\n",
        "                                             col * images_per_row + row]\n",
        "            # Post-process the feature to make it visually palatable\n",
        "            channel_image -= channel_image.mean()\n",
        "            channel_image /= channel_image.std()\n",
        "            channel_image *= 64\n",
        "            channel_image += 128\n",
        "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
        "            display_grid[col * size : (col + 1) * size,\n",
        "                         row * size : (row + 1) * size] = channel_image\n",
        "\n",
        "    # Display the grid\n",
        "    scale = 1. / size\n",
        "    plt.figure(figsize=(scale * display_grid.shape[1],\n",
        "                        scale * display_grid.shape[0]))\n",
        "    plt.title(layer_name)\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(display_grid, aspect='auto', cmap='viridis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oqj63rDgiEoT"
      },
      "source": [
        "### **¿A qué partes de la imagen de entrada es más sensible la salida de la red?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ti4yONZpOzmF"
      },
      "source": [
        "### **GradCam:**\n",
        "\n",
        "(de https://medium.com/analytics-vidhya/visualizing-activation-heatmaps-using-tensorflow-5bdba018f759)\n",
        "\n",
        "1- Calcular para una imagen la salida del modelo y la salida de la última capa convolucional\n",
        "\n",
        "2- Encuentrar la neurona de salida más activa (que es la que determina la clase predicha)\n",
        "\n",
        "3- Calcular el gradiente de dicha neurona de salida con respecto a la última capa convolucional\n",
        "\n",
        "3- Promediar y pesar esto con la salida de la última capa convolucional\n",
        "\n",
        "4- Normalizar entre 0 y 1 para visualizar\n",
        "\n",
        "5- Convertir a RGB y superponerla a la imagen original"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmsmHXAtiHMo"
      },
      "source": [
        "**Funciones que calculan la sensibilidad de la salida a la entrada:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SSZ-ZLfiE26"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def find_ind_last_conv2D(model):\n",
        "    ind_last_conv2D_layer = None\n",
        "    for i,x in enumerate(model.layers):\n",
        "        if x.__class__.__name__ == \"Conv2D\":\n",
        "            ind_last_conv2D_layer = i\n",
        "    return ind_last_conv2D_layer\n",
        "\n",
        "\n",
        "def show_heatmap(model, im):\n",
        "    imag = np.expand_dims(im, axis=0) # de 1 imagen pasamos a 1 conjunto de 1 imagen\n",
        "        \n",
        "    # The is the output feature map of the last convolutional layer\n",
        "    last_conv_layer = model.layers[find_ind_last_conv2D(model)]\n",
        "    \n",
        "    # This is the gradient of the \"benign\" class with regard to\n",
        "    # the output feature map of last convolutional layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        aux = model.output\n",
        "        #aux = model.layers[-2].output # salida de la última capa densa antes de softmax\n",
        "\n",
        "        iterate = tf.keras.models.Model([model.inputs], [aux, last_conv_layer.output])\n",
        "        model_out, last_conv_layer = iterate(imag)\n",
        "        class_out = model_out[:, np.argmax(model_out[0])]\n",
        "        grads = tape.gradient(class_out, last_conv_layer)\n",
        "\n",
        "        # mean intensity of the gradient over a specific feature map channel:\n",
        "        pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "    \n",
        "    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, last_conv_layer), axis=-1)    \n",
        "    heatmap = np.maximum(heatmap, 0) # se quitan los negativos (se ponen a 0)\n",
        "    heatmap /= np.max(heatmap) # se normaliza entre 0 y 1\n",
        "    heatmap = heatmap[0] # pasamos de 1 conjunto de 1 heatmap a 1 heatmap\n",
        "    \n",
        "    # We use cv2 to load the original image\n",
        "    #img = cv2.imread(img_path)\n",
        "    img = imag[0]\n",
        "    \n",
        "    img = np.zeros((im.shape[0],im.shape[1],3))\n",
        "#    print(im.shape, imag.shape)\n",
        "    for i in range(3):\n",
        "        img[:,:,i] = imag[0,:,:,0]\n",
        "\n",
        "    \n",
        "    # We resize the heatmap to have the same size as the original image\n",
        "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "    \n",
        "    # We convert the heatmap to RGB\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    \n",
        "    # We apply the heatmap to the original image\n",
        "    #heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET) / 255\n",
        "    #heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_BONE) / 255\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_HOT) / 255\n",
        "    \n",
        "    \n",
        "    # 0.4 here is a heatmap intensity factor\n",
        "    superimposed_img = heatmap * 0.5 + 0.5*im\n",
        "    #print(heatmap.min(), heatmap.max(), heatmap.mean(), heatmap.std())\n",
        "    #print(img.min(), img.max(), img.mean(), img.std())\n",
        "    #print(superimposed_img.min(),  superimposed_img.max(),\n",
        "    #      superimposed_img.mean(), superimposed_img.std())\n",
        "    \n",
        "    plt.figure(figsize=(15,5))\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.imshow(im, vmin=0, vmax=1); plt.xticks([]); plt.yticks([])\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.imshow(heatmap, vmin=0, vmax=1); plt.xticks([]); plt.yticks([])\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.imshow(superimposed_img, vmin=0, vmax=1); plt.xticks([]); plt.yticks([])\n",
        "    plt.show()\n",
        "    #print(np.shape(imag))\n",
        "    prob = 100*model.predict(imag)[0][class_indices[\"cats\"]]\n",
        "    print(\"Probabilidad clase gato : {:2.1f}%\".format(prob))\n",
        "    prob = 100*model.predict(imag)[0][class_indices[\"dogs\"]]\n",
        "    print(\"Probabilidad clase perro: {:2.1f}%\".format(prob))\n",
        "    print(\"\\n\\n\")\n",
        "    return heatmap, superimposed_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDq5ex8ZiKVy"
      },
      "source": [
        "**Visualización de mapas de sensibilidades (heatmaps) en varios ejemplos:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVHJRWw6Qiym"
      },
      "source": [
        "X_te[i].max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWPyB9DjiKmJ"
      },
      "source": [
        "ind = 200 # visualizamos 10 ejemplos de test a partir de este (en test hay 2002 ejemplos)\n",
        "\n",
        "for i in range(ind, ind+10):\n",
        "    show_heatmap(model, X_te[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AP_6l0IBxGLA"
      },
      "source": [
        "ind = 1041 # visualizamos 10 ejemplos de test a partir de este (en test hay 2002 ejemplos)\n",
        "\n",
        "for i in range(ind, ind+10):\n",
        "    show_heatmap(model, X_te[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw-Z7qcmiPFl"
      },
      "source": [
        "### **Ahora analizamos las mayores equivocaciones de la CNN en test cuando intentamos detectar gatos**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AMdUyweiRfB"
      },
      "source": [
        "- clase 1: perro\n",
        "- clase 0: gato"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTS_mN_0iUs_"
      },
      "source": [
        "**Gatos que la red está segura que son perros:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNkpIiHHiPTQ"
      },
      "source": [
        "inds = np.where(y_te==class_indices[\"cats\"])[0]\n",
        "inds = sorted(inds, key=lambda i:y_pred_proba[i,class_indices[\"cats\"]])\n",
        "for i in inds[:10]:\n",
        "    show_heatmap(model, X_te[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O2OUA86pt5P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}